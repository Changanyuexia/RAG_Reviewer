public void testMissingPrimaryKeyLookupQuery() throws Exception { indexType2TweeterDocuments(); final Table table = dataContext.getDefaultSchema().getTableByName(DEFAULT_TABLE_NAME); final Column[] pks = table.getPrimaryKeys().toArray(new Column[0]); try (DataSet ds = dataContext.query().from(table).selectAll().where(pks[0]).eq("missing").execute()) { assertFalse(ds.next()); } }	Please use a better name (primaryKeys, primaryKeyColumns).
public void loadJavaRDD() throws Exception { doReturn(javaPairRDD).when(sparkContext).newAPIHadoopFile(any(), any(), any(), any(), any()); doReturn(javaRDD).when(javaPairRDD).map(any()); JavaRDD<Country> retJavaRDD = SparkAvroLoader.loadJavaRDD(sparkContext, "/avro/datastore", Country.class); assertTrue(javaRDD == retJavaRDD); verify(sparkContext).newAPIHadoopFile( eq("/avro/datastore"), eq(AvroKeyInputFormat.class), eq(Country.class), eq(NullWritable.class), configurationCaptor.capture()); assertEquals(Country.SCHEMA$.toString(), configurationCaptor.getValue().get("avro.schema.input.key")); verify(javaPairRDD).map(mapFunctionCaptor.capture()); assertMapFunction(mapFunctionCaptor.getValue()); verifyNoMoreInteractions(sparkContext, javaPairRDD); verifyZeroInteractions(javaRDD); }	Wouln't it be better to use the expected type instead of any()?
protected AuditMessageType getParticipantObjectIdentificationForRequest(PRPAIN201306UV02 request, AssertionType assertion, AuditMessageType auditMsg) { auditMsg = getPatientParticipantObjectIdentificationForResponse(request, auditMsg); try { auditMsg = getQueryParamsParticipantObjectIdentificationForResponse(request, auditMsg); } catch (JAXBException ex) { if (LOG.isDebugEnabled()) { LOG.error("Error while creating ParticipantObjectIdentificationQueryByParameters segment : " + ex.getLocalizedMessage(), ex); } } return auditMsg; }	Remove this "if" statement. That said, here are a few things for future reference: 1. You use "is[Level]Enabled" to check that specific level (e.g., if you're going to log trace, you'd check "isTraceEnabled()", not "isDebugEnabled"). 2. There is no "isErrorEnabled" -- unless you disable logging altogether, it's always enabled. I suppose you could use "isEnabledFor(Level.ERROR)", but you'd only be checking if logging is on at all. 3. As a rule of thumb, unless the logging operation is extremely heavy (e.g., transforming a large object for the trace logs), you don't want to check if "Info" level or lower are enabled, only higher (debug, trace).
private synchronized void addNode(DiscoveryDruidNode druidNode) { DiscoveryDruidNode prev = nodes.put(druidNode.getDruidNode().getHostAndPortToUse(), druidNode); if (prev == null) { for (DruidNodeDiscovery.Listener l : nodeListeners) { listenerExecutor.submit(() -> { try { l.nodeAdded(druidNode); } catch (Exception ex) { log.error(ex, "Exception occured in DiscoveryDruidNode.nodeAdded(node=[%s]) in listener [%s].", druidNode, l); } }); } } else { log.warn("Node[%s] discovered but existed already [%s].", druidNode, prev); } }	is it possible that getDruidNode() or getHostAndPortToUse() are null?
public Step variantsLoadStep() throws Exception { return stepBuilderFactory.get(LOAD_VARIANTS).<Variant, Variant>chunk(10) .reader(reader) .writer(variantMongoWriter) .faultTolerant().skipLimit(50).skip(FlatFileParseException.class) .listener(new SkippedItemListener()) .build(); }	We talked about setting a chunk size. Shall we make it 1000 and set it in JobOptions? I'm not very happy about that location but other things like includeSrc, compressGenotypes, etc, are placed there too.
public int hashCode() { int result = name != null ? name.hashCode() : 0; result = 31 * result + zScore.hashCode(); return result; }	Please implement equals() method either. This will remove the potential problem when working with collections.
public Object execute(final ExecutionEvent event) throws ExecutionException { final TaskData data = getTaskData(event); if (data == null) return null; Job job = new Job(MessageFormat.format( Messages.RebasePullRequestHandler_RebaseJob, data.getTaskId())) { @Override protected IStatus run(IProgressMonitor monitor) { PullRequestComposite prComp = PullRequestConnector .getPullRequest(data); if (prComp == null) return Status.CANCEL_STATUS; PullRequest request = prComp.getRequest(); Repository repo = PullRequestUtils.getRepository(request); if (repo == null) return Status.CANCEL_STATUS; String branchName = PullRequestUtils.getBranchName(request); try { String target = request.getBase().getRef(); Ref targetRef = repo.findRef(request.getBase().getRef()); if (targetRef != null) { SubMonitor progress = SubMonitor.convert(monitor, 2); if (!PullRequestUtils.isCurrentBranch(branchName, repo)) { monitor.setTaskName(MessageFormat .format(Messages.RebasePullRequestHandler_TaskCheckout, branchName)); BranchOperationUI.checkout(repo, branchName).run( progress.split(1)); } else { progress.setWorkRemaining(1); } monitor.setTaskName(MessageFormat.format( Messages.RebasePullRequestHandler_TaskRebase, branchName, target)); new RebaseOperation(repo, targetRef) .execute(progress.split(1)); executeCallback(event); } } catch (IOException e) { GitHubUi.logError(e); } catch (CoreException e) { GitHubUi.logError(e); } return Status.OK_STATUS; } }; schedule(job, event); return null; }	one more progress monitor change
public boolean process(Set<? extends TypeElement> annotations, RoundEnvironment roundEnv) { try { for (Element autoMountElement : roundEnv.getElementsAnnotatedWith(SecureAutoMount.class)) { final AutoMountContext context = getAutoMountContext(autoMountElement, SecureAutoMount.class); if (context == null) { continue; } for (Element elem : roundEnv.getElementsAnnotatedWith(AuthorizeInstantiation.class)) { final AuthorizeInstantiation mp = elem.getAnnotation(AuthorizeInstantiation.class); processMountPoint(context, elem, mp); } for (Element elem : roundEnv.getElementsAnnotatedWith(MountPath.class)) { final MountPath mp = elem.getAnnotation(MountPath.class); processMountPoint(context, elem, mp); } generateSource(context); } return true; } catch (IOException ex) { Logger.getLogger(SecureMountAnnotationProcessor.class.getName()).log(Level.SEVERE, null, ex); } return true; }	return false ?
public void testFrameworkProducerDelete() throws Exception { setupFrameworkProducer(false); Exchange mockExchangeCreate = mock(Exchange.class); Exchange mockExchangeDelete = mock(Exchange.class); Message message = mock(Message.class); Metacard metacard = mock(MetacardImpl.class); when(metacard.getId()).thenReturn("metacard1"); when(mockExchangeCreate.getIn()).thenReturn(message); when(mockExchangeCreate.getOut()).thenReturn(message); when(mockExchangeCreate.getIn().getHeader(OPERATION_HEADER_KEY)).thenReturn(CREATE_OPERATION); when(mockExchangeCreate.getIn().getHeader(TIMEOUT_HEADER_KEY)).thenReturn(1000L); when(mockExchangeCreate.getIn().getBody()).thenReturn(metacard); when(mockExchangeCreate.getIn().getBody(any())).thenReturn(metacard); frameworkProducer.process(mockExchangeCreate); when(mockExchangeDelete.getIn()).thenReturn(message); when(mockExchangeDelete.getOut()).thenReturn(message); when(mockExchangeDelete.getIn().getHeader(OPERATION_HEADER_KEY)).thenReturn(DELETE_OPERATION); when(mockExchangeDelete.getIn().getHeader(TIMEOUT_HEADER_KEY)).thenReturn(1000L); }	This test needs a verification.
protected void onCreate(Bundle savedInstanceState) { Log.d(TAG, "onCreate"); requestWindowFeature(Window.FEATURE_INDETERMINATE_PROGRESS); requestWindowFeature(Window.FEATURE_ACTIVITY_TRANSITIONS); super.onCreate(savedInstanceState); PreferencesState.getInstance().onCreateActivityPreferences(getResources(), getTheme()); if (EyeSeeTeaApplication.permissions == null) { EyeSeeTeaApplication.permissions = Permissions.getInstance(this); } if (!EyeSeeTeaApplication.permissions.areAllPermissionsGranted()) { EyeSeeTeaApplication.permissions.requestNextPermission(); } initView(savedInstanceState); PreferencesState.getInstance().setPushInProgress(false); List<SurveyDB> surveyDBs = SurveyDB.getAllSendingSurveys(); Log.d(TAG, "Surveys sending: " + surveyDBs.size()); for (SurveyDB surveyDB : surveyDBs) { surveyDB.setStatus(Constants.SURVEY_QUARANTINE); surveyDB.save(); } AlarmPushReceiver.setPushAlarm(this); AlarmPushReceiver.setPushAlarm(this); AlarmPushReceiver.setPushAlarm(this); AlarmPushReceiver.setPushAlarm(this); try { Thread.sleep(100); AlarmPushReceiver.setPushAlarm(this); AlarmPushReceiver.setPushAlarm(this); Thread.sleep(100); AlarmPushReceiver.setPushAlarm(this); AlarmPushReceiver.setPushAlarm(this); Thread.sleep(100); AlarmPushReceiver.setPushAlarm(this); AlarmPushReceiver.setPushAlarm(this); } catch (InterruptedException e) { e.printStackTrace(); } mBaseActivityStrategy.onCreate(); }	this code is very strange, can you explain to me because is necessary?
public void testProcessNonJavaFilesWithoutException() throws Exception { final TreeWalker treeWalker = new TreeWalker(); treeWalker.setTabWidth(1); treeWalker.configure(new DefaultConfiguration("default config")); final File file = new File("src/main/resources/checkstyle_packages.xml"); final FileText fileText = new FileText(file, StandardCharsets.ISO_8859_1.name()); try { treeWalker.processFiltered(file, fileText); } catch (CheckstyleException ex) { fail("Exception not expected"); } }	Like I mentioned to others, try-catch-fail is not a good option. JUnit automatically populates exception to user and fails the test. If exception occurs, user will now get a bland message and not the stack trace of the problem. There is nothing we can assert here?
protected void executeCommand() { final AuthenticationProfile profile = AuthenticationProfileRepository.getInstance() .getProfile(getParameters().getProfileName()); sourceIp = getParameters().getSourceIp(); if (profile == null) { setSucceeded(false); } else { final boolean externalSsoEnabled = EngineLocalConfig.getInstance().getBoolean("ENGINE_SSO_ENABLE_EXTERNAL_SSO"); final DbUser user = buildUser(externalSsoEnabled, getParameters(), profile.getAuthzName()); boolean isAdmin = !roleDao.getAnyAdminRoleForUserAndGroups(user.getId(), StringUtils.join(user.getGroupIds(), ",")).isEmpty(); user.setAdmin(isAdmin); setCurrentUser(user); setUserName(String.format("%s@%s", getCurrentUser().getLoginName(), getCurrentUser().getDomain())); if (getParameters().isAdminRequired() && !isAdmin) { setSucceeded(false); } else if (permissionDao.getEntityPermissionsForUserAndGroups(user.getId(), StringUtils.join(user.getGroupIds(), ","), ActionGroup.LOGIN, BOTTOM_OBJECT_ID, VdcObjectType.Bottom, true) == null) { setSucceeded(false); } else { String engineSessionId = sessionDataContainer.generateEngineSessionId(); sessionDataContainer.setSourceIp(engineSessionId, getParameters().getSourceIp()); sessionDataContainer.setUser(engineSessionId, user); sessionDataContainer.refresh(engineSessionId); sessionDataContainer.setProfile(engineSessionId, profile); sessionDataContainer.setPrincipalName(engineSessionId, getParameters().getPrincipalName()); sessionDataContainer.setSsoAccessToken(engineSessionId, getParameters().getSsoToken()); sessionDataContainer.setSsoOvirtAppApiScope(engineSessionId, getParameters().getAppScope()); getReturnValue().setActionReturnValue(engineSessionId); setSucceeded(true); sessionId = engineSessionId; } } }	Maybe having such method would be nicer: buildUser(T params, String authzName) { boolean externalSsoEnabled = EngineLocalConfig.getInstance().getBoolean("ENGINE_SSO_ENABLE_EXTERNAL_SSO"); buildUser(externalSsoEnabled , params, authzName) { }
private void closeConfirmationWindow() { if(getConfirmWindow() == null) { return; } else { setConfirmWindow(null); } }	you could just do setConfirmWindow(null); like above method
public void queryFile1Contributors() { final IFileHistory history = historyProvider.getFileHistoryFor(iFile1, IFileHistoryProvider.NONE, new NullProgressMonitor()); assertNotNull(history); final IFileRevision[] revisions = history.getFileRevisions(); IFileRevision branchFileRevision1 = null; IFileRevision masterFileRevision3 = null; IFileRevision masterFileRevision1 = null; for (IFileRevision revision : revisions) { final String revisionId = revision.getContentIdentifier(); if (branchCommit1.getName().equals(revisionId)) { branchFileRevision1 = revision; } else if (masterCommit3.getName().equals(revisionId)) { masterFileRevision3 = revision; } else if (masterCommit1.getName().equals(revisionId)) { masterFileRevision1 = revision; } } assertNotNull(branchFileRevision1); assertNotNull(masterFileRevision3); assertNotNull(masterFileRevision1); final IFileRevision[] branchCommit1Parents = history.getContributors(branchFileRevision1); assertEquals(1, branchCommit1Parents.length); assertRevisionMatchCommit(branchCommit1Parents[0], masterCommit1); final IFileRevision[] masterCommit3Parents = history .getContributors(masterFileRevision3); assertEquals(1, masterCommit3Parents.length); assertRevisionMatchCommit(masterCommit3Parents[0], masterCommit1); final IFileRevision[] masterCommit1Parents = history .getContributors(masterFileRevision1); assertEquals(0, masterCommit1Parents.length); }	we don't use braces around single line blocks, many more occurrences in this patch
protected void onCreate(Bundle savedInstanceState) { super.onCreate(savedInstanceState); finishIfNotRoot(); if (savedInstanceState != null) { wasExternal = savedInstanceState.getBoolean("was_external"); } ACRAUtil.registerAppData(); uiController = new HomeActivityUIController(this); uiController.setupUI(); }	this used to bail after this call if it wasn't the root, does returning v. not returning from onCreate() in that case affect anything?
public void testCheckoutExistingBranch() throws Exception { Git git = new Git(db); writeTrashFile("a", "Hello world a"); git.add().addFilepattern(".").call(); git.commit().setMessage("commit file a").call(); git.branchCreate().setName("branch_1").call(); git.rm().addFilepattern("a").call(); FileUtils.mkdirs(new File(db.getWorkTree(), "a")); writeTrashFile("a/b", "Hello world b"); git.add().addFilepattern("a").call(); git.commit().setMessage("commit folder a").call(); git.rm().addFilepattern("a").call(); writeTrashFile("a", "New Hello world a"); git.add().addFilepattern(".").call(); assertEquals( "error: Your local changes to the following files would be overwritten by checkout:", execute("git checkout branch_1")); }	don't you want to add a/b?
private String formRevertMessage(RevertResult revertResult) { StringBuilder message = new StringBuilder(); if (revertResult.getNewHead() != null) { message.append(constant.revertedNewHead(revertResult.getNewHead())); } List<String> commits = revertResult.getRevertedCommits(); if (commits != null && commits.size() > 0) { StringBuilder revertedCommits = new StringBuilder(); for (String commit : commits) { revertedCommits.append(" "); revertedCommits.append(commit); } message.append( revertedCommits.length() > 0 ? " " + constant.revertedCommits(revertedCommits.toString()) : "\n"); } return message.toString(); }	To me it would be a bit clearer to use append chain here.
public static void init(Context context, String appDefinedUserAgent) { String appId = "unknown"; try { PackageInfo pi = context.getPackageManager().getPackageInfo(context.getPackageName(), 0); appId = pi.packageName; } catch (Exception ignore) { } String userAgent = "Unknown"; try { StringBuilder sb = new StringBuilder(); sb.append("RealmJava/"); sb.append(BuildConfig.VERSION_NAME); sb.append(" ("); sb.append(Util.isEmptyString(Build.DEVICE) ? "unknown-device" : Build.DEVICE); sb.append(", "); sb.append(Util.isEmptyString(Build.MODEL) ? "unknown-model" : Build.MODEL); sb.append(", v"); sb.append(Build.VERSION.SDK_INT); sb.append(")"); if (!appDefinedUserAgent.isEmpty()) { sb.append(" "); sb.append(appDefinedUserAgent); } userAgent = sb.toString(); } catch (Exception e) { RealmLog.warn("Constructing User-Agent description failed.", e); } if (SyncManager.Debug.separatedDirForSyncManager) { try { File dir = File.createTempFile("remote_sync_", "_" + android.os.Process.myPid(), context.getFilesDir()); if (!dir.delete()) { throw new IllegalStateException(String.format(Locale.US, "Temp file '%s' cannot be deleted.", dir.getPath())); } if (!dir.mkdir()) { throw new IllegalStateException(String.format(Locale.US, "Directory '%s' for SyncManager cannot be created. ", dir.getPath())); } SyncManager.nativeInitializeSyncManager(dir.getPath(), userAgent); } catch (IOException e) { throw new IllegalStateException(e); } } else { SyncManager.nativeInitializeSyncManager(context.getFilesDir().getPath(), userAgent); } UserStore userStore = new RealmFileUserStore(); SyncManager.init(appId, userAgent, userStore); }	use an overload or varargs to make this parameter optional, so: 1- you don't break current API 2- don't force the user to think about this parameter (especially in the context of non sync)
private List<StoragePool> searchStoragePool() { Optional<Version> optionalVersion = Config.<HashSet<Version>> getValue(ConfigValues.SupportedClusterLevels).stream() .max(Comparator.naturalOrder()); List<StoragePool> dataCenters = genericSearch(storagePoolDao, true); optionalVersion.ifPresent( version -> dataCenters.forEach( dataCenter -> { dataCenter.setStoragePoolCompatibilityLevelUpgradeNeeded( version.compareTo(dataCenter.getCompatibilityVersion()) > 0); dataCenter.setMacPoolId(dcSingleMacPoolFinder.find(dataCenter.getId())); } )); return dataCenters; }	I believe it would be easier to do check !ifPresent and skip rest, instead of creating that first lambda. if you like 2 lambdas approach instead of one if and one lambda, then fine, but extract method to contain second lambda, because lambda in lambda ... that's like watching Inception again, and nobody should be forced to watch that...
public boolean save(final Tuple<String, LogicalPlan> tuple){ final LogicalPlan plan = tuple.getValue(); final String queryId = tuple.getKey(); final File storedPlanFile= new File(planFolderPath + queryId + ".plan"); if (!storedPlanFile.exists()) { final DataFileWriter<LogicalPlan> dataFileWriter = new DataFileWriter<LogicalPlan>(datumWriter); try { dataFileWriter.create(plan.getSchema(), storedPlanFile); dataFileWriter.append(plan); dataFileWriter.close(); return true; } catch (final Exception e) { e.printStackTrace(); } } return false; }	File(planStorePath, queryId + ".plan")
public void onMessage(NodeRegistrationContainerReport nodeRegistrationContainerReport, EventPublisher publisher) { if (chillModeManager.getInChillMode()) { if (validate()) { chillModeManager.validateChillModeExitRules(publisher); return; } } else { return; } process(nodeRegistrationContainerReport); if(chillModeManager.getInChillMode()) { SCMChillModeManager.getLogger().info( "SCM in chill mode. {} DataNodes registered, {} required.", registeredDns, requiredDns); } if (validate()) { chillModeManager.validateChillModeExitRules(publisher); return; } }	We should process data from this report before validating again.
protected int doWork() { initializeAggregationState(); IOUtil.assertFileIsReadable(INPUT); IOUtil.assertFilesAreReadable(INTERVALS); final int returnValue; if ( INTERVAL_ITERATOR ) { returnValue = processDataIntervalIteration(); } else { returnValue = processDataNormalIteration(); } if (returnValue != 0) { return returnValue; } log.info("Iteration complete, generating metric files"); aggregatorList.forEach(this::writeMetricsFileForAggregator); log.info(String.format("Examined %d loci, Processed %d loci, Skipped %d loci.\n" + "Computation took %d seconds.", nTotalLoci, nProcessedLoci, nSkippedLoci, progressLogger.getElapsedSeconds())); return returnValue; }	at this point returnValue==0, so why change?
private void setExecutionEnvironment(TargetPlatformConfiguration result, Xpp3Dom configuration) { String value = getStringValue(configuration.getChild("executionEnvironment")); if (value == null) { return; } if (value.startsWith("?")) { throw new RuntimeException( "The target-platform-configuration parameter <executionEnvironment> must not start with a '?'. Use <defaultExecutionEnvironment> without a leading '?' instead."); } try { ExecutionEnvironmentUtils.getExecutionEnvironment(value); } catch (UnknownEnvironmentException e) { throw new RuntimeException("Invalid execution environment profile name " + value); } result.setExecutionEnvironment(value); }	We don't need this check. Even if "?" is used somewhere, which I doubt, UnknownEnvironmentException be self-exlanatory enough for somebody to investigate and fix it.
public void onBindEvent(BindButtonEvent event) { if (event.getState().equals(ButtonState.DOWN) && !SortOrderSystem.containsConsole()) { if (event.getId().equals(new SimpleUri("engine:tabbingModifier"))) { shiftPressed = true; } if (event.getId().equals(new SimpleUri("engine:tabbingUI"))) { TabbingManager.focusSetThrough = true; if (shiftPressed) { TabbingManager.changeCurrentNum(false); } else { TabbingManager.changeCurrentNum(true); } for (WidgetWithOrder widget : TabbingManager.getWidgetsList()) { if (widget.getOrder() == TabbingManager.getCurrentNum()) { if (!widget.isEnabled()) { TabbingManager.changeCurrentNum(true); } else { widget.onGainFocus(); TabbingManager.focusedWidget = widget; TabbingManager.getOpenScreen().getManager().setFocus(widget); } } else { widget.onLoseFocus(); if (widget instanceof UIRadialSection) { ((UIRadialSection) widget).setSelected(false); } } } event.prepare(new SimpleUri("engine:tabbingUI"), ButtonState.UP, event.getDelta()); } else if (event.getId().equals(new SimpleUri("engine:activate"))) { if (TabbingManager.focusedWidget instanceof UIDropdown) { ((UIDropdown) TabbingManager.focusedWidget).setOpenedReverse(); } else if (TabbingManager.focusedWidget instanceof ActivateableWidget) { ((ActivateableWidget) TabbingManager.focusedWidget).activateWidget(); } event.prepare(new SimpleUri("engine:activate"), ButtonState.UP, event.getDelta()); } } if (event.getState().equals(ButtonState.UP) && !SortOrderSystem.containsConsole()) { if (event.getId().equals(new SimpleUri("engine:tabbingModifier"))) { shiftPressed = false; } } }	You can replace this if with: java TabbingManager.changeCurrentNum(!shiftPressed);
protected boolean corsRequest() { if (!deployment.isCors()) return false; KeycloakSecurityContext securityContext = facade.getSecurityContext(); String origin = facade.getRequest().getHeader(CorsHeaders.ORIGIN); String exposeHeaders = deployment.getCorsExposedHeaders(); String requestOrigin = UriUtils.getOrigin(facade.getRequest().getURI()); log.debugv("Origin: {0} uri: {1}", origin, facade.getRequest().getURI()); if (securityContext != null && origin != null && !origin.equals(requestOrigin)) { AccessToken token = securityContext.getToken(); Set<String> allowedOrigins = token.getAllowedOrigins(); if (log.isDebugEnabled()) { for (String a : allowedOrigins) log.debug(" " + a); } if (allowedOrigins == null || (!allowedOrigins.contains("*") && !allowedOrigins.contains(origin))) { if (allowedOrigins == null) { log.debugv("allowedOrigins was null in token"); } else { log.debugv("allowedOrigins did not contain origin"); } facade.getResponse().sendError(403); facade.getResponse().end(); return true; } log.debugv("returning origin: {0}", origin); facade.getResponse().setStatus(200); facade.getResponse().setHeader(CorsHeaders.ACCESS_CONTROL_ALLOW_ORIGIN, origin); facade.getResponse().setHeader(CorsHeaders.ACCESS_CONTROL_ALLOW_CREDENTIALS, "true"); facade.getResponse().setHeader(CorsHeaders.ACCESS_CONTROL_EXPOSE_HEADERS, exposeHeaders); } else { log.debugv("cors validation not needed as we're not a secure session or origin header was null: {0}", facade.getRequest().getURI()); } return false; }	Only set header if "deployment.getCorsExposedHeaders() != null"
public void beforeSend( ServerSession session, Transaction tx, Message message, boolean direct, boolean noAutoCreateQueue) { try { if (brokerMessageInterceptor == null) { BundleContext bundleContext = getBundleContext(); brokerMessageInterceptor = bundleContext.getService( ((List<ServiceReference<BrokerMessageInterceptor>>) bundleContext.getServiceReferences( BrokerMessageInterceptor.class, "(name=subjectInjectorPlugin)")) .get(0)); } brokerMessageInterceptor.handleMessage(session, tx, message, direct, noAutoCreateQueue); } catch (InvalidSyntaxException e) { LOGGER.error( "Could retrieve the Subject Injector Plugin, subject will not be correctly applied to the message.", e); } }	Is error the right log level here? Seems like warn or even info would be more appropriate.
public void delete() throws IOException, InterruptedException { checkPermission(DELETE); FolderComputation<I> computation = getComputation(); Executor executor = Executor.of(computation); if (executor != null) { LOGGER.log(Level.INFO, "Interrupting {0} in order to delete it", this); executor.interrupt(Result.ABORTED, new CauseOfInterruption.UserInterruption(User.current())); long expiration = System.nanoTime() + TimeUnit.SECONDS.toNanos(15); while (executor.isAlive() && executor.getCurrentExecutable() == computation && expiration - System.nanoTime() > 0L) { Thread.sleep(50L); } if (executor.isAlive() && executor.getCurrentExecutable() == computation) { LOGGER.log(Level.WARNING, "Interrupted {0} in order to delete it, but it has not stopped yet", this); } } super.delete(); }	Superfluous check I think-it has been a long time since Executors were reused.
private void refreshLocalMessageFlags(final Account account, final Folder remoteFolder, final LocalFolder localFolder, ArrayList<Message> syncFlagMessages, final AtomicInteger progress, final int todo ) throws MessagingException { final String folder = remoteFolder.getName(); if (remoteFolder.supportsFetchingFlags()) { if (K9.DEBUG) Log.d(K9.LOG_TAG, "SYNC: About to sync flags for " + syncFlagMessages.size() + " remote messages for folder " + folder); FetchProfile fp = new FetchProfile(); fp.add(FetchProfile.Item.FLAGS); List<Message> undeletedMessages = new LinkedList<Message>(); for (Message message : syncFlagMessages) { if (!message.isSet(Flag.DELETED)) { undeletedMessages.add(message); } } remoteFolder.fetch(undeletedMessages.toArray(EMPTY_MESSAGE_ARRAY), fp, null); for (Message remoteMessage : syncFlagMessages) { Message localMessage = localFolder.getMessage(remoteMessage.getUid()); boolean messageChanged = syncFlags(localMessage, remoteMessage); if (messageChanged) { boolean shouldBeNotifiedOf = false; if (localMessage.isSet(Flag.DELETED) || isMessageSuppressed(account, folder, localMessage)) { for (MessagingListener l : getListeners()) { l.synchronizeMailboxRemovedMessage(account, folder, localMessage); } } else { for (MessagingListener l : getListeners()) { l.synchronizeMailboxAddOrUpdateMessage(account, folder, localMessage); } if (shouldNotifyForMessage(account, localFolder, localMessage)) { shouldBeNotifiedOf = true; } } if (!shouldBeNotifiedOf) { NotificationData data = getNotificationData(account, -1); if (data != null) { synchronized (data) { MessageReference ref = localMessage.makeMessageReference(); if (data.removeMatchingMessage(mApplication, ref)) { notifyAccountWithDataLocked(mApplication, account, null, data); } } } } } progress.incrementAndGet(); for (MessagingListener l : getListeners()) { l.synchronizeMailboxProgress(account, folder, progress.get(), todo); } } } }	Can you create a constant for the -1? I'm not sure what that represents here.
public InputStream getObject(String bucketName, String objectName, long offset, Long length) throws InvalidBucketNameException, NoSuchAlgorithmException, InsufficientDataException, IOException, InvalidKeyException, NoResponseException, XmlPullParserException, ErrorResponseException, InternalException, InvalidArgumentException { if (offset < 0) { throw new InvalidArgumentException("offset should be zero or greater"); } if (length != null && length <= 0) { throw new InvalidArgumentException("length should be greater than zero"); } if ((bucketName == null) || (bucketName.isEmpty())) { throw new InvalidArgumentException("bucket name cannot be empty"); } if ((objectName == null) || (objectName.isEmpty())) { throw new InvalidArgumentException("object name cannot be empty"); } Map<String,String> headerMap = new HashMap<>(); if (offset > 0) { if (length != null) { headerMap.put("Range", "bytes=" + offset + "-" + (offset + length - 1)); } else { headerMap.put("Range", "bytes=" + offset + "-"); } } HttpResponse response = executeGet(bucketName, objectName, headerMap, null); return response.body().byteStream(); }	Do this validation first. See the order of method arguments.
public static FileUtils.FileCopyResult unzip( final ByteSource byteSource, final File outDir, boolean cacheLocally ) throws IOException { return unzip(byteSource, outDir, Predicates.<Throwable>alwaysTrue(), cacheLocally); }	I think that by default we should retry on Exceptions but not on other kinds of Throwables.
public PrologEnvironment newPrologEnvironment() throws CompileException { PrologEnvironment env; if(urlLoader != null) { env = envFactory.create(urlLoader); return env; } else { env = envFactory.create(getClass().getClassLoader()); } String rules = getConfig().getPrologRules(); if (rules != null) { PushbackReader in = new PushbackReader(new StringReader(rules), Prolog.PUSHBACK_SIZE); JavaObjectTerm streamObject = new JavaObjectTerm(in); if (!env.execute(Prolog.BUILTIN, "consult_stream", SymbolTerm.intern("rules.pl"), streamObject)) { throw new CompileException("Cannot consult rules.pl " + getProject().getName() + " " + getConfig().getRevision()); } } return env; }	Style-nit: Unnecessary blank line.
public void scheduleTask(TaskDefinition task) throws SchedulerException { if (!Context.getSchedulerService().getTaskByName(task.getName()).getStarted()) { Context.getSchedulerService().scheduleTask(task); } }	After taking a second look, i think we do not need this call at all. All those check of ensure that a service is not started before schedule, etc, belong to the service layer API. Your role is to simply call Context.getSchedulerService().scheduleTask(task) and that is all.
protected ImmutableList<PubsubMessage> sendBatch(final List<PubsubMessage> batch) throws InterruptedException { final int batchSize = batch.size(); final List<ApiFuture<String>> sendResults = batch.stream() .map(publisher::publish) .collect(Collectors.toCollection(() -> new ArrayList<>(batchSize))); final ImmutableList.Builder<PubsubMessage> remaining = ImmutableList.builder(); for (int i = 0; i < batchSize; ++i) { final ApiFuture<String> pendingResult = sendResults.get(i); try { final String messageId = pendingResult.get(); if (logger.isDebugEnabled()) { final PubsubMessage message = batch.get(i); logger.debug("Finished sending event (partyId={}, eventId={}) to Pub/Sub: messageId = {}", message.getAttributesOrThrow(MESSAGE_ATTRIBUTE_PARTYID), message.getAttributesOrThrow(MESSAGE_ATTRIBUTE_EVENTID), messageId); } } catch (final ExecutionException e) { final PubsubMessage message = batch.get(i); final Throwable cause = e.getCause(); if (cause instanceof ApiException) { final ApiException apiException = (ApiException) cause; if (apiException.isRetryable()) { logger.debug("Transient error sending event (partyId={}, eventId={}) to Pub/Sub; retrying.", message.getAttributesOrThrow(MESSAGE_ATTRIBUTE_PARTYID), message.getAttributesOrThrow(MESSAGE_ATTRIBUTE_EVENTID), cause); remaining.add(message); } else { logger.warn("Permanent error sending event (partyId={}, eventId={}) to Pub/Sub; abandoning.", message.getAttributesOrThrow(MESSAGE_ATTRIBUTE_PARTYID), message.getAttributesOrThrow(MESSAGE_ATTRIBUTE_EVENTID), cause); } } else { logger.error("Unknown error sending event (partyId={}, eventId={}) to Pub/Sub; abandoning.", message.getAttributesOrThrow(MESSAGE_ATTRIBUTE_PARTYID), message.getAttributesOrThrow(MESSAGE_ATTRIBUTE_EVENTID), cause); } } } return remaining.build(); }	debug logging should not change the applicationflow. getAttributesOrThrow would. getAttributesOrDefault is better I think
public String validate(String parameterValue, ModelValidatorContext context) throws ValidationException { try { if (!isValidJSON(parameterValue)) { throw new ValidationException("Expected value should match JSON format, received " + parameterValue); } } catch (ValidationException er) { throw new ValidationException("Validator error from JsonParser: Expected value should match JSON format, received " + parameterValue); } return parameterValue; }	I think this part should be improved. isValidJSON returns a boolean and also throws a ValidationException. You should rather decide on a single strategy, either return true false or return void and throw an exception. I prefer the latter, as an exception contains more meaningful error messages than true/false. In that case the method should be renamed checkValidJson
public void getVersion() throws Exception { String version = gApi.config().server().getVersion(); Truth.assertThat(version).is(Version.getVersion()); }	Can be inlined in the assertThat statement below.
public HttpRequest filter(HttpRequest request) throws HttpException { Credentials currentCreds = checkNotNull(creds.get(), "credential supplier returned null"); Signer signer = Signer.getSigner(); String signature; Multimap<String, String> decodedParams = queryParser().apply(request.getEndpoint().getRawQuery()); SimpleDateFormat df = new SimpleDateFormat("yyyy-MM-dd'T'HH:mm:ss'Z'"); df.setTimeZone(new SimpleTimeZone(0, "GMT")); String timestamp = df.format(new Date()); String signatureNonce = UUID.randomUUID().toString(); decodedParams.put("AccessKeyId", currentCreds.identity); decodedParams.put("Timestamp", timestamp); decodedParams.put("SignatureNonce", signatureNonce); String prefix; try { prefix = request.getMethod() + SEPARATOR + AcsURLEncoder.percentEncode("/") + SEPARATOR; } catch (UnsupportedEncodingException e) { throw Throwables.propagate(e); } String stringToSign = prefix; ImmutableSortedSet.Builder<String> builder = ImmutableSortedSet.naturalOrder(); for (Map.Entry<String, String> entry : decodedParams.entries()) builder.add(Strings2.urlEncode(entry.getKey()) + "=" + Strings2.urlEncode(entry.getValue())); stringToSign += Strings2.urlEncode(Joiner.on("&").join(builder.build())); signature = signer.signString(stringToSign, currentCreds.credential + "&"); decodedParams.put("Signature", signature); request = request.toBuilder().endpoint(uriBuilder(request.getEndpoint()).query(decodedParams).build()).build(); return request; }	If you use the jclouds Uris and UriBuilder classes I think you don't have to worry about manually encoding the parameters.
public void beforeDocumentChange(DocumentEvent event) { Document document = event.getDocument(); SPath path = editorManager.getEditorPool().getFile(document); if (path == null) { VirtualFile virtualFile = FileDocumentManager.getInstance() .getFile(document); if (virtualFile == null) { LOG.debug("Ignoring event for document " + document + " - document is not known to the editor pool and a " + "VirtualFile for the document could not be found"); return; } path = virtualFileConverter.convertToPath(virtualFile); if (path == null) { LOG.debug("Ignoring event for document " + document + " - document is not known to the editor pool and an " + "SPath for the document could not be found"); return; } else if (!editorManager.getSession() .isShared(path.getResource())) { LOG.debug("Ignoring Event for document " + document + " - document is not shared"); return; } } String newText = event.getNewFragment().toString(); String replacedText = event.getOldFragment().toString(); editorManager .generateTextEdit(event.getOffset(), newText, replacedText, path); }	Are you tracking all files in the IDE ? If yes this could flood the log file a little bit depending on your sharing setup, e.g you do a partial sharing with only a few files.
private void initialize() { Assert.isNotNull(scope, "Task scope should not be null."); events.addAll(manager.getEvents(scope)); try { ReviewTaskProvider reviewTaskProvider = new ReviewTaskProvider(); reviewTaskProvider.open(manager); reviewTaskProvider.query(scope, null); } catch (CoreException e) { System.out.println(e); } events.addAll(manager.getEvents(scope)); }	the constructor already asserts that
public void registerInterposedSynchronization(Synchronization sync) throws IllegalStateException { try { Transaction tx = transactionManager.getTransaction(); JCAOrderedLastSynchronizationList jcaOrderedLastSynchronization = interposedSyncs.get(tx); if (jcaOrderedLastSynchronization == null) { jcaOrderedLastSynchronization = new JCAOrderedLastSynchronizationList(tx, interposedSyncs); delegate.registerInterposedSynchronization(jcaOrderedLastSynchronization); } jcaOrderedLastSynchronization.add(sync); } catch (SystemException e) { throw new IllegalStateException(e); } }	putIfAbsent semantics is better
void setUp() { mockApplicationContext = mock(ApplicationContext.class); mockEventStore = mock(EventStore.class); mockRepositoryProvider = mock(RepositoryProvider.class); executor = spy(new MockExecutor()); testSubject = new SpringAggregateSnapshotterFactoryBean(); testSubject.setApplicationContext(mockApplicationContext); testSubject.setExecutor(executor); when(mockApplicationContext.getBeansOfType(AggregateFactory.class)).thenReturn( Collections.singletonMap("myFactory", new AbstractAggregateFactory<StubAggregate>(StubAggregate.class) { @Override public StubAggregate doCreateAggregate(String aggregateIdentifier, DomainEventMessage firstEvent) { return new StubAggregate(aggregateIdentifier); } })); testSubject.setEventStore(mockEventStore); testSubject.setRepositoryProvider(mockRepositoryProvider); mockTransactionManager = mock(PlatformTransactionManager.class); aggregateIdentifier = UUID.randomUUID().toString(); String type = "StubAggregate"; DomainEventMessage event1 = new GenericDomainEventMessage<>(type, aggregateIdentifier, 0L, "Mock contents", MetaData.emptyInstance()); DomainEventMessage event2 = new GenericDomainEventMessage<>(type, aggregateIdentifier, 1L, "Mock contents", MetaData.emptyInstance()); when(mockEventStore.readEvents(aggregateIdentifier)).thenReturn(DomainEventStream.of(event1, event2)); }	Would be nice for the test to pass without modifications, to show backwards compatibility.
public void run() { try (OpenShiftClient client = clouldClientHelper.get()) { logger.info("Watching ConfigMap in namespace {}", client.getNamespace()); try (Watch watchable = client.configMaps().watch(new Watcher<ConfigMap>() { @Override public void eventReceived(Action action, ConfigMap kieServerState) { logger.info("Event - Action: {}, {} on ConfigMap ", action, kieServerState.getMetadata().getName()); DeploymentConfig dc = client.deploymentConfigs().withName(kieServerId).get(); if (kieServerId.equals(kieServerState.getMetadata().getName()) && action.equals(Action.MODIFIED) && "True".equals(dc.getStatus().getConditions().get(0).getStatus()) && triggerRollout(client, kieServerId)) { ObjectMeta md = dc.getSpec().getTemplate().getMetadata(); Map<String, String> ann = md.getAnnotations() == null ? new HashMap<>() : md.getAnnotations(); md.setAnnotations(ann); ann.put(ROLLOUT_TRIGGER_TIMESTAMP, ZonedDateTime.now().format(DateTimeFormatter.ISO_INSTANT)); client.deploymentConfigs().createOrReplace(dc); logger.info("Update DeploymentConfig: {}", md.getName()); } else { logger.info("Event - Ignored"); } } @Override public void onClose(KubernetesClientException cause) { logger.info("Watcher closed."); if (cause != null) { logger.info(cause.getMessage()); } } })) { logger.info("Watcher created."); Runtime.getRuntime().addShutdownHook(new Thread(() -> { synchronized (this) { isWatchRunning = false; notifyAll(); logger.info("ShutdownHook sent notifyAll."); } })); synchronized (this) { while (isWatchRunning && !Thread.currentThread().isInterrupted()) { logger.info("WatchRunner thread starts."); try { wait(); } catch (InterruptedException e) { Thread.currentThread().interrupt(); logger.error("WatchRunner thread being interrupted", e); } logger.info("WatchRunner thread being notified."); } logger.info("WatchRunner thread exits."); } } } catch (KubernetesClientException e) { logger.error("Failed", e); } }	not sure how often this can be logged so maybe change the level to debug and also log the event that is being ignored?
private static Integer getPlatFormOffset() { String currentOs = System.getProperty("os.name").toLowerCase(Locale.ROOT); String currentJdk = System.getProperty("java.version").toLowerCase(Locale.ROOT); for (int i = 0; i < PLATFORM_LIST.size(); i++) { if (currentOs.toLowerCase(Locale.ROOT).contains(PLATFORM_LIST.get(i).split(",")[0].toLowerCase(Locale.ROOT)) && currentJdk.toLowerCase(Locale.ROOT).contains( PLATFORM_LIST.get(i).split(",")[1].toLowerCase(Locale.ROOT))) { return i; } } return null; }	Throw an exception here and log an error including the currentOs and currentJdk. Returning null will cause a NPE upstream and we'll not know which OS, JDK name caused it.
public void subscribeUnsubscribe() throws Exception { final Postman postman = Mockito.mock(Postman.class); final DyBase base = new DyBase(); final Alias alias = new EmAlias(this.randomAlias(base), postman); final Bout bout = alias.inbox().bout(alias.inbox().start()); final Alias friend = this.randomAlias(base); bout.friends().invite(friend.name()); final ArgumentCaptor<Envelope> captor = ArgumentCaptor.forClass(Envelope.class); friend.inbox().bout(bout.number()).subscribe(false); bout.messages().post(DON_T_SEND_IT); friend.inbox().bout(bout.number()).subscribe(true); bout.messages().post(SEND_IT); bout.messages().post(SEND_IT); friend.inbox().bout(bout.number()).subscribe(false); bout.messages().post(DON_T_SEND_IT); Mockito.verify(postman, Mockito.times(2)).send(captor.capture()); final List<Envelope> messages = captor.getAllValues(); for (final Envelope envelope : messages) { final ByteArrayOutputStream baos = new ByteArrayOutputStream(); MimeMultipart.class.cast(envelope.unwrap().getContent()) .writeTo(baos); MatcherAssert.assertThat( baos.toString(), Matchers.containsString( SEND_IT ) ); } }	@pecko let's also assert it does not contain the other string.
private void testCopyQuestion() throws Exception { ______TS("Success case: copy questions successfully"); feedbackEditPage.clickCopyButton(); feedbackEditPage.waitForCopyTableToLoad(); assertFalse("Unable to submit when there are no questions selected", feedbackEditPage.isCopySubmitButtonEnabled()); feedbackEditPage.verifyHtmlPart(By.id("copyModal"), "/instructorFeedbackCopyQuestionModal.html"); feedbackEditPage.clickCopyTableAtRow(0); assertTrue("Can click after selecting", feedbackEditPage.isCopySubmitButtonEnabled()); feedbackEditPage.clickCopySubmitButton(); feedbackEditPage.verifyHtmlMainContent("/instructorFeedbackCopyQuestionSuccess.html"); ______TS("Success case: copy multiple questions successfully"); int numQuestionEditForms = feedbackEditPage.getNumberOfQuestionEditForms(); feedbackEditPage.clickCopyButton(); feedbackEditPage.waitForCopyTableToLoad(); feedbackEditPage.clickCopyTableAtRow(0); feedbackEditPage.clickCopyTableAtRow(1); feedbackEditPage.clickCopySubmitButton(); assertEquals(numQuestionEditForms + 2, feedbackEditPage.getNumberOfQuestionEditForms()); ______TS("No copiable questions"); feedbackEditPage = getFeedbackEditPageOfCourseWithoutQuestions(); feedbackEditPage.clickCopyButton(); feedbackEditPage.waitForCopyErrorMessageToLoad(); assertEquals("There are no questions to be copied.", feedbackEditPage.getCopyErrorMessageText()); assertFalse("Should not be able to submit if there are no questions", feedbackEditPage.isCopySubmitButtonEnabled()); ______TS("Fails gracefully with an error message"); feedbackEditPage = getFeedbackEditPage(); feedbackEditPage.changeActionLinkOnCopyButton("invalid URL"); feedbackEditPage.clickCopyButton(); feedbackEditPage.waitForCopyErrorMessageToLoad(); assertEquals("Error retrieving questions. Please close the dialog window and try again.", feedbackEditPage.getCopyErrorMessageText()); assertFalse("Should not be able to submit if loading failed", feedbackEditPage.isCopySubmitButtonEnabled()); String questionId = getFeedbackQuestionWithRetry(courseId, feedbackSessionName, 4).getId(); BackDoor.deleteFeedbackQuestion(questionId); questionId = getFeedbackQuestionWithRetry(courseId, feedbackSessionName, 3).getId(); BackDoor.deleteFeedbackQuestion(questionId); }	Not related to gender type
public Ban.Builder profile(org.spongepowered.api.profile.GameProfile profile) { checkNotNull(profile, "Profile cannot be null!"); checkState(banType == BanTypes.PROFILE, "Cannot set a GameProfile if the BanType is not BanType.USER_BAN!"); this.profile = profile; return this; }	Message needs updating
public void removeListener() { View view = getView(); if (view != null) { getDiagramEventBroker().removeNotificationListener(view, this); if (hostSemanticElement != null) { for (EObject stereotypeApplication : hostSemanticElement.getStereotypeApplications()) { getDiagramEventBroker().removeNotificationListener(stereotypeApplication, this); } getDiagramEventBroker().removeNotificationListener(hostSemanticElement, this); hostSemanticElement = null; } } if (!stereotypeList.isEmpty()) { for (Stereotype stereotype : stereotypeList) { View label = helper.getStereotypeLabel(hostView, stereotype); if (null != label) { getDiagramEventBroker().removeNotificationListener(label, this); } BasicCompartment compartment = helper.getStereotypeBraceCompartment(hostView, stereotype); if (compartment != null) { getDiagramEventBroker().addNotificationListener(helper.getStereotypeBraceCompartment(hostView, stereotype), this); } if (compartment != null && stereotype != null) { EList<Property> properties = stereotype.allAttributes(); for (Property property : properties) { getDiagramEventBroker().removeNotificationListener(helper.getStereotypePropertyInBrace(hostView, stereotype, property), this); } } } } }	'null !=' is preferably used
protected void reinitAllDatabases() throws IOException { boolean acquired = false; try { semaphore.acquire(Integer.MAX_VALUE); acquired = true; try { db.close(); } catch (IOException e) { log.warnUnableToCloseDb(e); } try { expiredDb.close(); } catch (IOException e) { log.warnUnableToCloseExpiredDb(e); } } catch (InterruptedException e) { log.warnUnableToCloseDb(e); log.warnUnableToCloseExpiredDb(e); } db = reinitDatabase(getQualifiedLocation(), dataDbOptions()); expiredDb = reinitDatabase(getQualifiedExpiredLocation(), expiredDbOptions()); if (acquired) { semaphore.release(Integer.MAX_VALUE); } }	This should be done in a proper try finally block. If a reinitDatabase method threw an IOException the semaphore would be irreparably broken.
public MatchClause append(Filter filter) { if (clause == null) { clause = new StringBuilder("MATCH (n)"); if (filter.getRelationshipDirection().equals(Direction.INCOMING)) { clause.append("<"); } clause.append(String.format("-[%s:`%s`]-", relationshipIdentifier(), this.relationshipType)); if (filter.getRelationshipDirection().equals(Direction.OUTGOING)) { clause.append(">"); } clause.append(String.format("(%s) ", nodeIdentifier())); } clause.append(filter.toCypher(relationshipIdentifier(), clause.indexOf(" WHERE ") == -1)); return this; }	suggestion if (filter.getRelationshipDirection() == Direction.INCOMING) {
public static AdjustableSweepBatchConfigSource create( MetricsManager metricsManager, Supplier<SweepBatchConfig> rawSweepBatchConfig) { AdjustableSweepBatchConfigSource configSource = new AdjustableSweepBatchConfigSource(rawSweepBatchConfig); Gauge<Double> gauge = AdjustableSweepBatchConfigSource::getBatchSizeMultiplier; metricsManager.addMetricFilter(AdjustableSweepBatchConfigSource.class, "batchSizeMultiplier", ImmutableMap.of(), () -> gauge.getValue() != 1.0); metricsManager.registerMetric(AdjustableSweepBatchConfigSource.class, "batchSizeMultiplier", gauge); return configSource; }	I am confused b/w the description and implementation of filter here.
public void configure(Binder binder) { JsonConfigProvider.bind(binder, "druid.metadata.storage.tables", MetadataStorageTablesConfig.class); JsonConfigProvider.bind(binder, "druid.metadata.storage.connector", MetadataStorageConnectorConfig.class); JsonConfigProvider.bind(binder, "druid.manager.segments", MetadataSegmentManagerConfig.class); JsonConfigProvider.bind(binder, "druid.manager.rules", MetadataRuleManagerConfig.class); binder.bind(PasswordProvider.class).toProvider( new Provider<PasswordProvider>() { @Inject MetadataStorageConnectorConfig metadataStorageConnectorConfig; @Inject Injector injector; @Override public PasswordProvider get() { final PasswordProvider passwordProvider; if (metadataStorageConnectorConfig == null || metadataStorageConnectorConfig.getPasswordProvider() == null) { JsonConfigProvider<PasswordProvider> provider = JsonConfigProvider.of("druid.password", PasswordProvider.class); provider.inject(injector.getInstance(Properties.class), injector.getInstance(JsonConfigurator.class)); passwordProvider = provider.get().get(); } else { passwordProvider = metadataStorageConnectorConfig.getPasswordProvider(); } injector.injectMembers(passwordProvider); return passwordProvider; } } ); }	Logging might be helpful to warn users that this should not happen.
public void testMigrationTask() throws InterruptedException { MigrationTask migrationTask = new MigrationTask(project); migrationTask.start(); Assert.assertTrue(migrationTask.isAlive()); migrationTask.join(); Assert.assertFalse(migrationTask.isAlive()); Assert.assertEquals(100, migrationTask.getProgress()); }	test should test, if metadata is migrated ;-)
protected Object toNSCollection(ERXRestFormat.Delegate delegate, NSMutableDictionary<Object, Object> associatedObjects) { Object result = associatedObjects.get(_associatedObject); if (result == null) { if (delegate != null) { delegate.nodeWillWrite(this); } if (isArray()) { NSMutableArray<Object> array = new NSMutableArray<Object>(); for (ERXRestRequestNode child : _children) { array.add(child.toNSCollection(delegate, associatedObjects)); } result = array; } else if (isNull()) { result = NSKeyValueCoding.NullValue; } else if (_value != null) { result = _value; } else { NSMutableDictionary<Object, Object> dict = new NSMutableDictionary<Object, Object>(); for (Map.Entry<String, Object> attribute : _attributes.entrySet()) { String key = attribute.getKey(); Object value = attribute.getValue(); if (value == null) { value = NSKeyValueCoding.NullValue; } dict.put(key, value); } for (ERXRestRequestNode child : _children) { String name = child.name(); Object value = child.toNSCollection(delegate, associatedObjects); if (value != NSKeyValueCoding.NullValue || ERXProperties.booleanForKeyWithDefault("ERXRest.includeNullValues", true) == true) { dict.put(name, value); } } if (dict.isEmpty()) { result = NSKeyValueCoding.NullValue; } else { result = dict; } } if (_associatedObject != null) { associatedObjects.put(_associatedObject, result); } } return result; }	_== true_ part is not needed as booleanForKeyWithDefault already returns a boolean ;)
public User addUserToProject(final Project project, final Account account, final Role... userRoles) { notNull(project, "project"); notNull(account, "account"); notEmpty(account.getUri(), "account.uri"); notNull(userRoles, "userRoles"); validateRoleURIs(userRoles); noNullElements(Arrays.stream(userRoles).map(Role::getUri).collect(Collectors.toList()), "userRoles.uri"); notEmpty(project.getId(), "project.id"); final User user = new User(account, userRoles); doPostProjectUsersUpdate(project, user); return getUser(project, account); }	redundant check
public void testDeadlock() throws Exception { doTest(1000 * 30); boolean interrupted = Thread.interrupted(); if (interrupted) { fail("Thread was interrupted at end of test"); } }	Why not inline this variable?
public void makeSortable() { final Map<ImageResource, Integer> imageWeightMap = new HashMap<ImageResource, Integer>(); imageWeightMap.put(statusCell.upImage, 0); imageWeightMap.put(statusCell.volumeSomeBricksDownImage, 1); imageWeightMap.put(statusCell.allBricksDownImage, 2); imageWeightMap.put(statusCell.downImage, 3); makeSortable(new Comparator<GlusterVolumeEntity>() { private final CustomStatusImageComaparator imageComparator = new CustomStatusImageComaparator(imageWeightMap); @Override public int compare(GlusterVolumeEntity o1, GlusterVolumeEntity o2) { return imageComparator.compare(statusCell.getStatusImage(statusCell.getVolumeStatus(o1)), statusCell.getStatusImage(statusCell.getVolumeStatus(o2))); } }); }	Are we recalculating the volume status here?
public GoldenEgg(UUID ownerId, CardSetInfo setInfo) { super(ownerId, setInfo, new CardType[]{CardType.ARTIFACT}, "{2}"); this.subtype.add(SubType.FOOD); this.addAbility(new EntersBattlefieldTriggeredAbility(new DrawCardSourceControllerEffect(1))); Ability ability = new AnyColorManaAbility(new GenericManaCost(1)); ability.addCost(new TapSourceCost()); ability.addCost(new SacrificeSourceCost()); this.addAbility(ability); Ability ability1 = new SimpleActivatedAbility(Zone.BATTLEFIELD, new GainLifeEffect(3), new ManaCostsImpl("{1}")); ability1.addCost(new TapSourceCost()); ability1.addCost(new SacrificeSourceCost()); this.addAbility(ability1); }	Costs 2.
public void unparse(SqlWriter writer, int leftPrec, int rightPrec) { writer.keyword("CREATE"); if (isTemporary()) { writer.keyword("TEMPORARY"); } if (getReplace()) { writer.keyword("OR REPLACE"); } writer.keyword("VIEW"); if (isIfNotExists()) { writer.keyword("IF NOT EXISTS"); } viewName.unparse(writer, leftPrec, rightPrec); if (fieldList.size() > 0) { fieldList.unparse(writer, 1, rightPrec); } if (comment != null) { writer.newlineAndIndent(); writer.keyword("COMMENT"); comment.unparse(writer, leftPrec, rightPrec); } writer.newlineAndIndent(); writer.keyword("AS"); writer.newlineAndIndent(); query.unparse(writer, leftPrec, rightPrec); }	remove this ?
public void testValidCRAMFileWithoutSeqDict() throws Exception { final SamReader samReader = SamReaderFactory. makeDefault(). validationStringency(ValidationStringency.SILENT). referenceSequence(new File(TEST_DATA_DIR, "nm_tag_validation.fa")). open(new File(TEST_DATA_DIR, "nm_tag_validation.cram")); final ReferenceSequenceFile reference = new FastaSequenceFile(new File(TEST_DATA_DIR, "nm_tag_validation.fa"), true); final Histogram<String> results = executeValidation(samReader, reference, IndexValidationStringency.EXHAUSTIVE); Assert.assertTrue(!results.isEmpty()); }	just to be sure there is no index/dictionary involved: final ReferenceSequenceFile reference = new FastaSequenceFile(new File(TEST_DATA_DIR, "nm_tag_validation.fa"), true); final SamReader samReader = SamReaderFactory. makeDefault(). validationStringency(ValidationStringency.SILENT). referenceSource(new ReferenceSource(reference)). ...
public void cleanup() { if (model != null) { model.cleanup(); model = null; } if (modelItems != null) { for (T model: modelItems) { if (model instanceof HasCleanup) { ((HasCleanup)model).cleanup(); } } } for (Pair<T, V> item : items) { T value = item.getFirst(); if (!isGhost(value)) { if (item instanceof HasCleanup) { ((HasCleanup)value).cleanup(); } } } cleanContentPanel(); }	Yes had that on my to do list, but missed it.
public String get(String name) { return (isSet(name)) ? myRecord.get(name) : new String(); }	just return "" instead of new String()
private void updateMutePreviewOverlayVisibility() { mutePreviewOverlay.setVisibility( showMuteOverlayOnVideoCall() && muteButton.isChecked() && !isInGreenScreenMode ? View.VISIBLE : View.GONE); }	Just a tiny thing, I guess we can move the condition to an assign statement, it could be easier to read since the conditional expression is quite complex now. int mutePreviewOverlayVisibility = showMuteOverlayOnVideoCall() && muteButton.isChecked() && !isInGreenScreenMode ? View.VISIBLE : View.GONE; mutePreviewOverlay.setVisibility(mutePreviewOverlayVisibility);
public void resetAllResponses() { for (FeedbackQuestionAttributes question : questionResponseBundle.keySet()) { questionResponseBundle.putIfAbsent(question, new ArrayList<>()); } }	emmmm i dont feel this replacement is necessary...and it might change what the code intends to do, as put will replace the value corresponding to the question even if the question is already associated with a value, but putIfAbsent only associate question with the new ArrayList<>() if the question is not associated to anything.
protected URLConnection getExternalGraphic(AjaxRequestTarget target, Form<?> form) { onlineResource.processInput(); if (onlineResource.getModelObject() != null) { URL url = null; try { String baseUrl = baseURL(form); String external = onlineResource.getModelObject().toString(); URI uri = new URI( external ); if( uri.isAbsolute() ){ url = uri.toURL(); if( !external.startsWith(baseUrl)){ form.warn( "Recommend use of styles directory at "+baseUrl); } } else { url = new URL( baseUrl + "styles/"+external ); } URLConnection conn = url.openConnection(); if("text/html".equals(conn.getContentType())){ form.error("Unable to access url"); return null; } return conn; } catch (FileNotFoundException notFound ){ form.error( "Unable to access "+url); } catch (Exception e) { e.printStackTrace(); form.error( "Recommend use of styles directory at "+e); } } return null; }	This logic changes a bit due to <LINK_0>
private void loadButtonAction(ActionEvent e) { progressDialog = new ProgressDialog(list.getParent()); if (dbpath == SELECT_OPTION) { File dir = selectDirectory(); if (dir == null) { return; } } dbload.restart(); }	If dir is not to be used anywhere, you might as well do if (selectDirectory() == null)
public Single<String> getP18ForItem(String entityId) { return depictsInterface.getLabelForEntity(entityId) .map(response -> { String name; try { JsonObject claims = response.getAsJsonObject("claims").getAsJsonObject(); JsonObject P18 = claims.get("P18").getAsJsonArray().get(0).getAsJsonObject(); JsonObject mainsnak = P18.get("mainsnak").getAsJsonObject(); JsonObject datavalue = mainsnak.get("datavalue").getAsJsonObject(); JsonPrimitive value = datavalue.get("value").getAsJsonPrimitive(); name = value.toString(); name = name.substring(1, name.length() - 1); } catch (Exception e) { name=""; } if (!name.isEmpty()){ return getImageUrl(name); } else return "No Image for Depiction"; }) .singleOrError(); }	Java convention for a variable says it should be p18 lowercase.
public String getServerState() { this.officeServer.refreshState(); return contextualLocalizationManager.getTranslationPlain( TRANSLATION_KEY_SERVER_STATE_PREFIX + this.officeServer.getState().name().toLowerCase()); }	Small detail: missing this.. See the line you replaced for ex.
public void visitToken(DetailAST token) { switch (token.getType()) { case TokenTypes.INTERFACE_DEF: checkServiceInterface(token); break; default: break; } }	There is just one case here. We can replace this switch statement with if.
public DeCoupleMBusDeviceCommandExecutor() { super(MbusChannelElementsDto.class); }	The class passed on to the super constructor shouldn't be MbusChannelElementsDto. I think the cleanest would be to pass DecoupleMbusDto.class (and make DecoupleMbusDto implement ActionRequestDto).
public ServerWebSocketInitializer(final ServerInfo serverInfo) { LOG.info("Currently time out time is not used " + serverInfo.getTimeOut()); this.serverInfo = serverInfo; connectionServer = createServerSocket(); manager = createConnectionManager(getServerInfo()); }	Colon after "used"
public ArrayList<OncoTreeNode> getOncoTree(Version version) throws TopBraidException { ArrayList<OncoTreeNode> list = new ArrayList<OncoTreeNode>(super.query(String.format(query, version.getGraphURI()), new ParameterizedTypeReference<List<OncoTreeNode>>(){})); return list; }	I guess getOncoTree() returns List<OncoTreeNode> and we must return ArrayList<OncoTreeNode> ? Still, we don't really need to create a named variable here .. we could do: return new ArrayList<OncoTreeNode>(super.query ....
public void doSample() { sendData(pm.isScreenOn()?"on":"off"); }	@orhan89 while you're add it, could you do a API version check and use isInteractive() if available?<LINK_0>
public Configuration setDefaults(Configuration defaults) { this.defaults = defaults; return this; }	I suggest to check defaults != this before setting.
public void refreshMetadata(String username) { if (mNosaraClient == null) { return; } if (!TextUtils.isEmpty(username)) { mUserName = username; if (getAnonID() != null) { mNosaraClient.trackAliasUser(mUserName, getAnonID()); clearAnonID(); } } else { mUserName = null; if (getAnonID() == null) { generateNewAnonID(); } } }	There is a problem here :cry: :disappointed: We need to change the library since trackaliasUser uses TracksClient.NosaraUserType.WPCOM (wpcom:user_id) internally. We should add another trackaliasUser method that takes the userType parameter....
private void removeHiddenInstructors(FeedbackQuestionAttributes question, List<FeedbackResponseAttributes> responses, Map<String, String> recipients, Set<String> hiddenInstructorEmails) { boolean noChangeRequired = hiddenInstructorEmails == null || hiddenInstructorEmails.isEmpty() || question.getRecipientType() != FeedbackParticipantType.INSTRUCTORS; if (noChangeRequired) { return; } for (String instructorEmail : hiddenInstructorEmails) { if (recipients.containsKey(instructorEmail)) { recipients.remove(instructorEmail); } Iterator<FeedbackResponseAttributes> iterResponse = responses.iterator(); while (iterResponse.hasNext()) { FeedbackResponseAttributes response = iterResponse.next(); if (response.recipientEmail.equals(instructorEmail)) { iterResponse.remove(); } } } }	@unyoungwax, oops missed this, but consider prefixing this boolean with <code>is...</code>
private void cancelUpload(int localMediaId) { if (mCurrentUpload != null && mCurrentUpload.getId() == localMediaId) { cancelCurrentUpload(); } for(Iterator<MediaModel> i = mQueue.iterator(); i.hasNext();) { MediaModel mediaModel = i.next(); if (mediaModel.getId() == localMediaId) { i.remove(); } } }	nitpicking: would be nice to break from the loop here
MergingUpdater(AbstractTripleStore database) { this.database = database; String property = System.getProperty("outputDumps"); outputDumps = Boolean.TRUE.toString().equals(property); id = UUID.randomUUID().toString().replaceAll("-", ""); }	configuration should be injected, not read from system properties in the constructor.
protected org.spine3.server.storage.EventStorage createStorage(StorageFactory factory) { final RecordStorage<EventId> recordStorage = super.createStorage(factory); final org.spine3.server.storage.EventStorage storage = factory.createEventStorage(recordStorage); return storage; }	Let's avoid FQNs as much as we can.
public int getLength() { Widget widget = getWidget(); int childCount = 0; if (widget instanceof Composite) { childCount = ((Composite) widget).getChildren().length; if (widget instanceof CTabFolder) { for (CTabItem tabItem : ((CTabFolder) widget).getItems()) { if (tabItem.isDisposed()) { System.err.println("CTabItem was disposed"); break; } else { childCount++; } } } } return childCount; }	The syserr should come out.
static org.ovirt.engine.core.common.businessentities.VM setUpEntityExpectations( org.ovirt.engine.core.common.businessentities.VM entity, VmStatistics statistics, int index) { expect(entity.getId()).andReturn(GUIDS[index]).anyTimes(); expect(entity.getvds_group_id()).andReturn(GUIDS[2]).anyTimes(); expect(entity.getvm_name()).andReturn(NAMES[index]).anyTimes(); expect(entity.getvm_description()).andReturn(DESCRIPTIONS[index]).anyTimes(); expect(entity.getnum_of_cpus()).andReturn(8).anyTimes(); expect(entity.getnum_of_sockets()).andReturn(2).anyTimes(); expect(entity.getusage_mem_percent()).andReturn(Integer.valueOf(20)).anyTimes(); expect(entity.getdisplay_type()).andReturn(DisplayType.vnc).anyTimes(); expect(entity.getdisplay_secure_port()).andReturn(5900).anyTimes(); expect(entity.getnum_of_monitors()).andReturn(2).anyTimes(); expect(entity.getvm_type()).andReturn(VmType.Server).anyTimes(); expect(entity.getrun_on_vds_name()).andReturn(NAMES[NAMES.length - 1]).anyTimes(); Map<String, DiskImage> diskImageMap = new HashMap<String, DiskImage>(); diskImageMap.put("1", new DiskImage()); expect(entity.getDiskMap()).andReturn(diskImageMap).anyTimes(); VmStatic vmStatic = new VmStatic(); vmStatic.setId(GUIDS[index]); vmStatic.setvm_name(NAMES[index]); expect(entity.getStaticData()).andReturn(vmStatic).anyTimes(); setUpStatisticalEntityExpectations(entity, statistics); return entity; }	this expectations relevant for your use-case only, no need for all tests to see them, please move them to your method which will extend expectations for setUpEntityExpectations()
public List<String> getDirectory() throws OwException { List<String> directory = new ArrayList<String>(); OwserverPacket requestPacket = new OwserverPacket(OwserverMessageType.DIR, "/"); write(requestPacket); OwserverPacket returnPacket = null; do { try { returnPacket = read(false); } catch (OwException e) { logger.info("getDirectory may have returned incomplete result: {}", e.getMessage()); closeOnError(); return directory; } if (returnPacket.hasPayload()) { directory.add(returnPacket.getPayloadString()); } } while ((returnPacket.isPingPacket() || returnPacket.hasPayload())); if (!returnPacket.hasControlFlag(OwserverControlFlag.PERSISTENCE)) { logger.trace("closing connection because persistence was denied"); close(); } connectionErrorCounter = 0; return directory; }	Is that a software issue? Then better do WARN and include the exception as a last param.
public void start() throws Exception { synchronized (lock) { if (childrenCache != null) { return; } childrenCache = cacheFactory.make(curatorFramework, config.getContainerPath()); } ContainerCacheListener containerCacheListener = new ContainerCacheListener(); childrenCache.getListenable().addListener(containerCacheListener); try { childrenCache.start(PathChildrenCache.StartMode.POST_INITIALIZED_EVENT); } catch (Exception e) { synchronized (lock) { try { stop(); } catch (IOException e1) { log.error(e1, "Exception when stopping InventoryManager that couldn't start."); } } throw e; } while (!containerCacheListener.doneInitializing) { Thread.sleep(2000); log.info("Waiting for PathChildrenCache to be completely loaded."); } }	can we use a CountDownLatch.await(1 minute) here instead? that way not too many logs will be printed and also it wouldn't wait any more than necessary ?
public void testDoubletonFlatbush() { List<Rectangle> items = new ArrayList<>(); Rectangle rect0 = new Rectangle(1, 1, 1, 1); items.add(rect0); Rectangle rect1 = new Rectangle(-1, -2, -1, -1); items.add(rect1); items.sort(RECTANGLE_COMPARATOR); Flatbush<Rectangle> rtree = new Flatbush<>(items.toArray(new Rectangle[] {})); List<Rectangle> allResults = findIntersections(rtree, EVERYTHING); allResults.sort(RECTANGLE_COMPARATOR); assertEquals(allResults, items); Rectangle hit0 = new Rectangle(1, 1, 2, 2); assertEquals(findIntersections(rtree, hit0), ImmutableList.of(rect0)); Rectangle hit1 = new Rectangle(-2, -2, -1, -2); assertEquals(findIntersections(rtree, hit1), ImmutableList.of(rect1)); Rectangle totalMiss = new Rectangle(10, 10, 12, 12); assertEquals(findIntersections(rtree, totalMiss), ImmutableList.of()); Rectangle marginalMiss = new Rectangle(0, 0, 0, 0); assertEquals(findIntersections(rtree, marginalMiss), ImmutableList.of()); }	use ImmutableList.of() and assertEqualsNoOrder  Rectangle rect0 = new Rectangle(1, 1, 1, 1); Rectangle rect1 = new Rectangle(-1, -2, -1, -1); List<Rectangle> items = ImmutableList.of(rect0, rect1); Flatbush<Rectangle> rtree = new Flatbush<>(items.toArray(new Rectangle[] {})); List<Rectangle> allResults = findIntersections(rtree, EVERYTHING); assertEqualsNoOrder(allResults.toArray(), items.toArray());  ditto testTwoLevelFlatbush
public void onDeniedPendingLockNotification() { synchronized (ZKDistributedNonblockingLock.this) { _isLocked = false; _isPreempted = true; _isPending = false; ZKDistributedNonblockingLock.this.notify(); } }	Looks like a lock can only be in one state at a time. I suggest merging these 2 booleans into an enum for the cleanness of the code and the logic.
public void generateExperimentalCoordinates(Vector2d firstBondVector) throws CDKException { IMolecule original = molecule; IMolecule shallowCopy = molecule.getBuilder().newInstance(IMolecule.class,molecule); for (IAtom curAtom : shallowCopy.atoms()) { if (curAtom.getSymbol().equals("H")) { int bondsFromCurAtom=0; for (IBond bond : shallowCopy.bonds()) if(bond.contains (curAtom)) ++bondsFromCurAtom; if (bondsFromCurAtom < 2) { shallowCopy.removeAtomAndConnectedElectronContainers(curAtom); curAtom.setPoint2d(null); } } } molecule = shallowCopy; generateCoordinates(firstBondVector); double bondLength = GeometryTools.getBondLengthAverage(molecule); HydrogenPlacer hPlacer = new HydrogenPlacer(); molecule = original; hPlacer.placeHydrogens2D(molecule, bondLength); }	IAtomContainer.getConnectedBondsCount()? or IAtomContainer.getConnectedAtomsCount()? <LINK_0>
private String createBuildsStats(MemoryImprint memoryImprint, TaskListener listener, Map<String, String> parameters) { StringBuilder str = new StringBuilder(""); final String rootUrl = hudson.getRootUrl(); String unsuccessfulMessage = null; Entry[] entries = memoryImprint.getEntries(); if (entries.length > 0) { str.append("\n"); for (Entry entry : entries) { AbstractBuild build = entry.getBuild(); if (build != null) { GerritTrigger trigger = GerritTrigger.getTrigger(build.getProject()); Result res = build.getResult(); String customMessage = null; str.append("\n\n"); if (trigger.getCustomUrl() == null || trigger.getCustomUrl().isEmpty()) { str.append(rootUrl).append(entry.getBuild().getUrl()); } else { str.append(expandParameters(trigger.getCustomUrl(), build, listener, parameters)); } str.append(MESSAGE_DELIMITER); if (res == Result.SUCCESS) { customMessage = trigger.getBuildSuccessfulMessage(); } else if (res == Result.FAILURE || res == Result.ABORTED) { customMessage = trigger.getBuildFailureMessage(); } else if (res == Result.UNSTABLE) { customMessage = trigger.getBuildUnstableMessage(); } else { customMessage = trigger.getBuildFailureMessage(); } if (customMessage == null || customMessage.equals("")) { str.append(res.toString()); } else { str.append(customMessage); } if (res != Result.SUCCESS) { unsuccessfulMessage = entry.getUnsuccessfulMessage(); if (null != unsuccessfulMessage && !unsuccessfulMessage.isEmpty()) { logger.trace("Using unsuccessful message from file."); str.append(" <<<\n"); str.append(unsuccessfulMessage.trim()); str.append("\n>>> "); } } } } } else { logger.error("I got a request to create build statistics, but no entries where found!"); } return str.toString(); }	you should use res.isWorseThan(Result.SUCCESS) instead. <LINK_0>
public void visitNode(Tree tree) { if (tree.is(Kind.METHOD) && isServletInit((MethodTree) tree)) { tree.accept(new AssignmentVisitor()); } else if (tree.is(Kind.VARIABLE)) { VariableTree variable = (VariableTree) tree; if (hasSemantic() && isOwnedByAServlet(variable) && !isStaticOrFinal(variable)) { issuableVariables.add(variable); } } }	checking for the semantic should be done before checking the type of the tree, as semantic is used to get the parameter type of the method.
public void shouldNotExpireChargesWhenAwaitingCaptureDelayIsLessThan48Hours() { String extChargeId1 = addCharge(CREATED, "ref", ZonedDateTime.now().minusMinutes(90), RandomIdGenerator.newId()); String extChargeId2 = addCharge(AWAITING_CAPTURE_REQUEST, "ref", ZonedDateTime.now().minusHours(48L).plusMinutes(1L), RandomIdGenerator.newId()); worldpayMockClient.mockCancelSuccess(); connectorRestApiClient .postChargeExpiryTask() .statusCode(OK.getStatusCode()) .contentType(JSON) .body("expiry-success", is(1)) .body("expiry-failed", is(0)); connectorRestApiClient .withAccountId(accountId) .withChargeId(extChargeId1) .getCharge() .statusCode(OK.getStatusCode()) .contentType(JSON) .body(JSON_CHARGE_KEY, is(extChargeId1)) .body(JSON_STATE_KEY, is(EXPIRED.toExternal().getStatus())); connectorRestApiClient .withAccountId(accountId) .withChargeId(extChargeId2) .getCharge() .statusCode(OK.getStatusCode()) .contentType(JSON) .body(JSON_CHARGE_KEY, is(extChargeId2)) .body(JSON_STATE_KEY, is(AWAITING_CAPTURE_REQUEST.toExternal().getStatus())); List<String> events1 = databaseTestHelper.getInternalEvents(extChargeId1); List<String> events2 = databaseTestHelper.getInternalEvents(extChargeId2); assertTrue(isEqualCollection(events1, asList(CREATED.getValue(), EXPIRED.getValue()))); assertTrue(isEqualCollection(events2, asList(AWAITING_CAPTURE_REQUEST.getValue()))); }	not sure what role this charge is playing in the test
public void updateSource(TaskSource sourceUpdate) { checkLockNotHeld("Can not update sources while holding the driver lock"); checkArgument(sourceOperator.isPresent() && sourceOperator.get().getSourceId().equals(sourceUpdate.getPlanNodeId())); pendingTaskSourceUpdates.updateAndGet(current -> current == null ? sourceUpdate : current.update(sourceUpdate)); tryWithLock(() -> TRUE); }	Add a message to the checkArgument call.
protected int persistHydrant( FireHydrant indexToPersist, DataSchema schema, Interval interval, Map<String, Object> metadataElems ) { synchronized (indexToPersist) { if (indexToPersist.hasSwapped()) { log.info( "DataSource[%s], Interval[%s], Hydrant[%s] already swapped. Ignoring request to persist.", schema.getDataSource(), interval, indexToPersist ); return 0; } log.info( "DataSource[%s], Interval[%s], Metadata [%s] persisting Hydrant[%s]", schema.getDataSource(), interval, metadataElems, indexToPersist ); try { int numRows = indexToPersist.getIndex().size(); final IndexSpec indexSpec = config.getIndexSpec(); indexToPersist.getIndex().getMetadata().putAll(metadataElems); final File persistedFile = indexMerger.persist( indexToPersist.getIndex(), interval, new File(computePersistDir(schema, interval), String.valueOf(indexToPersist.getCount())), indexSpec, config.getSegmentWriteOutMediumFactory() ); indexToPersist.swapSegment( new QueryableIndexSegment(indexIO.loadIndex(persistedFile), indexToPersist.getSegmentId()) ); return numRows; } catch (IOException e) { log.makeAlert("dataSource[%s] -- incremental persist failed", schema.getDataSource()) .addData("interval", interval) .addData("count", indexToPersist.getCount()) .emit(); throw new RuntimeException(e); } } }	Change doesn't belong to this PR
private void doBuildProject(File projectLocation, IProgressMonitor monitor) throws CoreException { if (monitor.isCanceled()) { return; } try { monitor.beginTask(Messages.MSBuild_BuildProjectTask, 10); String msBuild = getMSBuildPath(); if (msBuild != null) { File csprojFile = WPProjectUtils.getCsrojFile(projectLocation); Assert.isNotNull(csprojFile); StringBuilder cmdString = new StringBuilder(msBuild); cmdString.append(" "); if (isRelease()) { cmdString.append("/p:Configuration=Release "); } cmdString.append(csprojFile.getAbsolutePath()); ExternalProcessUtility processUtility = new ExternalProcessUtility(); if (monitor.isCanceled()) { return; } monitor.worked(1); TextDetectingStreamListener listener = new TextDetectingStreamListener( "Build succeeded."); processUtility.execSync(cmdString.toString(), projectLocation, listener, listener, monitor, null, getLaunchConfiguration()); if (!listener.isTextDetected()) { throw new CoreException(new Status(IStatus.ERROR, WPCore.PLUGIN_ID, Messages.MSBuild_MSBuildError)); } } } finally { monitor.done(); } }	Needs quotes around the msbuild command
private void initializeServices() { logger().debug("Initializing couchbase services on host: " + enabledServices); final String services = enabledServices.stream().map(s -> { switch (s) { case KV: return "kv"; case QUERY: return "n1ql"; case INDEX: return "index"; case SEARCH: return "fts"; default: throw new IllegalStateException("Unknown service!"); } }).collect(Collectors.joining(",")); Response response = doHttpRequest(MGMT_PORT, "/node/controller/setupServices", "POST", new FormBody.Builder() .add("services", services) .build(), false ); checkSuccessfulResponse(response, "Could not enable couchbase services"); }	suggestion logger().debug("Initializing couchbase services on host: {}", enabledServices);
public Mono<HttpResponse> process(HttpPipelineCallContext context, HttpPipelineNextPolicy next) { Optional<Object> customHttpHeadersObject = context.getData(AZURE_REQUEST_HTTP_HEADERS_KEY); if (customHttpHeadersObject.isPresent() && customHttpHeadersObject.get() instanceof HttpHeaders) { HttpHeaders customHttpHeaders = (HttpHeaders) customHttpHeadersObject.get(); for (HttpHeader httpHeader : customHttpHeaders) { if (!Objects.isNull(httpHeader.getName()) && !Objects.isNull(httpHeader.getValue())) { context.getHttpRequest().getHeaders().put(httpHeader.getName(), httpHeader.getValue()); } } } return next.process(); }	This could be replaced with java context.getData(AZURE_REQUEST_HTTP_HEADERS_KEY).ifPresent(headers -> { // for loop over headers });
public ExpressionAnalysis( Map<NodeRef<Expression>, Type> expressionTypes, Map<NodeRef<Expression>, Type> expressionCoercions, Set<NodeRef<InPredicate>> subqueryInPredicates, Set<NodeRef<SubqueryExpression>> scalarSubqueries, Set<NodeRef<ExistsPredicate>> existsSubqueries, Map<NodeRef<Expression>, FieldId> columnReferences, Set<NodeRef<Expression>> typeOnlyCoercions, Set<NodeRef<QuantifiedComparisonExpression>> quantifiedComparisons, Map<NodeRef<Identifier>, LambdaArgumentDeclaration> lambdaArgumentReferences) { this.expressionTypes = new LinkedHashMap<>(requireNonNull(expressionTypes, "expressionTypes is null")); this.expressionCoercions = new LinkedHashMap<>(requireNonNull(expressionCoercions, "expressionCoercions is null")); this.typeOnlyCoercions = new LinkedHashSet<>(requireNonNull(typeOnlyCoercions, "typeOnlyCoercions is null")); this.columnReferences = new LinkedHashMap<>(requireNonNull(columnReferences, "columnReferences is null")); this.subqueryInPredicates = new LinkedHashSet<>(requireNonNull(subqueryInPredicates, "subqueryInPredicates is null")); this.scalarSubqueries = new LinkedHashSet<>(requireNonNull(scalarSubqueries, "subqueryInPredicates is null")); this.existsSubqueries = new LinkedHashSet<>(requireNonNull(existsSubqueries, "existsSubqueries is null")); this.quantifiedComparisons = new LinkedHashSet<>(requireNonNull(quantifiedComparisons, "quantifiedComparisons is null")); this.lambdaArgumentReferences = new LinkedHashMap<>(requireNonNull(lambdaArgumentReferences, "lambdaArgumentReferences is null")); }	wrap with unmodifiableSet in constructor and then just return field reference from get* methods.
public FreeStyleProject newInstance(Branch branch) { FreeStyleProject job = new FreeStyleProject(getOwner(), branch.getEncodedName()); setBranch(job, branch); try { job.setQuietPeriod(0); } catch(IOException e) { e.printStackTrace(); } return job; }	For test stability we maintain the previous quiet period of 0. But live behavior will change.
public void init(final GlusterVolumeGeoRepCreateModel model) { super.init(model); model.getPropertyChangedEvent().addListener(new IEventListener<PropertyChangedEventArgs>() { @Override public void eventRaised(Event<? extends PropertyChangedEventArgs> ev, Object sender, PropertyChangedEventArgs args) { if(args.propertyName.equalsIgnoreCase("RecommendationViolations")) { getView().setSuggestedConfigViolations(model.getRecommendationViolations()); } else if (args.propertyName.equalsIgnoreCase("QueryFailed")) { getView().setFailureMessage(model.getQueryFailureMessage()); } } }); model.getSlaveUserName().getEntityChangedEvent().addListener(new IEventListener<EventArgs>() { @Override public void eventRaised(Event<? extends EventArgs> ev, Object sender, EventArgs args) { String slaveUser = model.getSlaveUserName() .getEntity(); getView().setUserGroupVisibility(slaveUser != null && !slaveUser .equalsIgnoreCase(ConstantsManager.getInstance().getConstants().rootUser())); } }); }	You could do this in the model itself because userGroup is already represented in model. getSlaveUserGroupName().setIsChangeable() can be used to make the ui-editor to enable or disable.
public Scheduler cleanupResponseUrlDataScheduler() throws SchedulerException { return this.constructScheduler(ResponseDataCleanupJob.class, KEY_CLEANUP_JOB_THREAD_COUNT, KEY_CLEANUP_JOB_CRON_EXPRESSION, this.getDatabaseUrl(), this.databaseUsername, this.databasePassword, this.databaseDriver); }	My guess is that ResponseUrlDataCleanupJob.class should be used here in stead of ResponseDataCleanupJob.class?
public void generateType(final Ds3Type typeEntry) throws IOException { final Template typeTemplate = config.getTemplate("TypeEnumConstant.tmplt"); final Type type = TypeConverter.toType(typeEntry); final Path outputPath = getTypeOutputPath(type); final OutputStream outStream = fileUtils.getOutputFile(outputPath); final Writer writer = new OutputStreamWriter(outStream); try { typeTemplate.process(type, writer); } catch (final NullPointerException e) { LOG.error("Encountered NullPointerException while processing template " + typeTemplate.getName(), e); e.printStackTrace(); } catch (final TemplateException e) { LOG.error("Encountered TemplateException while processing template " + typeTemplate.getName(), e); e.printStackTrace(); } }	Since you are appending the exception in the logging statement, you do not have to then print the stack trace. This will actually result in the stack being printing twice, depending on how the logger is configured.
private Map<Long, ISegmentAspect> getAspectsFromColumnsId(List<Long> desiredColumns) { Map<Long, ISegmentAspect> aspects = new LinkedHashMap<>(); if (!desiredColumns.isEmpty()) { for (Long columnsId : desiredColumns) { ISegmentAspect segmentAspect = fAspectMap.get(columnsId); if (segmentAspect != null) { aspects.put(columnsId, segmentAspect); } } return aspects; } return fAspectMap; }	return before instantiating the map?
public String toString() { return "KubernetesCloud '" + name + "' serverUrl :" + serverUrl; }	more of a personal taste question, but why don't you like Guava MoreObjects ?
public int getOptimalTileWidth() { FormatTools.assertId(currentId, true, 1); RandomAccessInputStream plane = getPlane(getSeries(), 0); if (plane == null) return super.getOptimalTileWidth(); try { TiffParser tp = new TiffParser(plane); IFD ifd = tp.getFirstIFD(); return (int) ifd.getTileWidth(); } catch (FormatException e) { LOGGER.debug("Could not retrieve tile width", e); } catch (IOException e) { LOGGER.debug("Could not retrieve tile width", e); } finally { try { plane.close(); } catch (IOException e2) { LOGGER.debug("Could not close stream", e2); } } return super.getOptimalTileWidth(); }	You can use RAIS plane2 = plane here, e.g.:  import java.io.Closeable; class C implements Closeable { public void close() { System.out.println("closed"); } } public class M { public static void main(String[] args) { C c = new C(); try (C c2 = c) { System.out.println("done"); } } }
public void createOrLoadKey() { String keyLocation = env.getProperty("keyLocation"); if (rsaJsonWebKey == null) { try { loadSavedKey(keyLocation); } catch (ClassNotFoundException | IOException e1) { logger.error("Key not found or error loading key. Creating new key. ", e1); try { RsaKeyUtil keyUtil = new RsaKeyUtil(); KeyPair keyPair; keyPair = keyUtil.generateKeyPair(2048); rsaJsonWebKey = (RsaJsonWebKey) PublicJsonWebKey.Factory.newPublicJwk(keyPair.getPublic()); rsaJsonWebKey.setPrivateKey(keyPair.getPrivate()); saveKey(keyLocation); } catch (JoseException e) { logger.error("Error creating key: ", e1); throw new RuntimeException(e); } } } }	2048 looks like a magic number
public synchronized void onJobArrival(final JobEntity jobEntity) { final int numResourcesToUse = jobEntity.getNumWorkers() + jobEntity.getNumServers(); if (numAvailableResources >= numResourcesToUse) { LOG.log(Level.INFO, "Start job {0} with {1} resources. Remaining free resources: {2}", new Object[]{jobEntity.getJobId(), numAvailableResources, numAvailableResources - numResourcesToUse}); numAvailableResources -= numResourcesToUse; jobServerDriverFuture.get().executeJob(jobEntity); } else { LOG.log(Level.INFO, "Put job {0} into queue", jobEntity.getJobId()); jobWaitingQueue.add(jobEntity); } }	this code block (if in L54-L59) can be encapsulated into a method to avoid duplicate in onJobFinished(), something like boolean tryExecute() that returns whether the job execution was successful
AuthenticatingHttpConnector(final String user, final Optional<AgentProxy> agentProxyOpt, final Optional<Path> clientCertificatePath, final Optional<Path> clientKeyPath, final EndpointIterator endpointIterator, final DefaultHttpConnector delegate, final List<Identity> identities) { if (clientCertificatePath.isPresent() ^ clientKeyPath.isPresent()) { throw new IllegalArgumentException( "both or neither of clientCertificatePath and clientKeyPath must be specified"); } this.user = user; this.agentProxy = agentProxyOpt; this.clientCertificatePath = clientCertificatePath; this.clientKeyPath = clientKeyPath; this.endpointIterator = endpointIterator; this.delegate = delegate; this.identities = identities; }	u fancy
public Set<List<JavaFileScannerContext.Location>> flow(List<Integer> parameterIndices, List<Class<? extends Constraint>> domains) { Preconditions.checkArgument(!parameterIndices.isEmpty(), "computing flow on empty symbolic value list should never happen"); if(node == null || behavior == null) { return Collections.emptySet(); } String key = parameterIndices.stream().sorted().map(Object::toString).reduce("", String::concat); String domainKey = domains.stream().map(Class::getName).sorted().reduce("", String::concat); Map<String, Set<List<JavaFileScannerContext.Location>>> flowByDomain = cachedFlows.computeIfAbsent(key, k -> new HashMap<>()); return flowByDomain.computeIfAbsent(domainKey, k -> FlowComputation.flow(node, getSymbolicValues(parameterIndices), c -> true, c -> false, domains, node.programState.getLastEvaluated())); }	I'm not sure about that generating the key like this will be unique: from how I see it, if we call the method with [1,2], we will end up with the same key ("12") as asking for the 12th parameter with the list [12]. (I know this is pretty unlikely, but still...)
public synchronized void handleMessageLayoutPrepare( @NonNull CorfuPayloadMsg<LayoutPrepareRequest> msg, ChannelHandlerContext ctx, @NonNull IServerRouter r) { if (!isBootstrapped(msg, ctx, r)) { return; } final long msgEpoch = msg.getPayload().getEpoch(); final long serverEpoch = getServerEpoch(); final Rank prepareRank = new Rank(msg.getPayload().getRank(), msg.getClientID()); final Rank phase1Rank = getPhase1Rank(msgEpoch); if (msgEpoch != serverEpoch) { r.sendResponse(ctx, msg, new CorfuPayloadMsg<>(CorfuMsgType.WRONG_EPOCH, serverEpoch)); log.trace("handleMessageLayoutPrepare: Incoming message with wrong epoch, got {}, " + "expected {}, message was: {}", msg.getPayload().getEpoch(), serverEpoch, msg); return; } Layout proposedLayout = getProposedLayout(msgEpoch); if (phase1Rank != null && prepareRank.lessThanEqualTo(phase1Rank)) { log.debug("handleMessageLayoutPrepare: Rejected phase 1 prepare of rank={}, " + "phase1Rank={}", prepareRank, phase1Rank); r.sendResponse(ctx, msg, CorfuMsgType.LAYOUT_PREPARE_REJECT.payloadMsg(new LayoutPrepareResponse(phase1Rank.getRank(), proposedLayout))); } else { Rank highestProposedRank = proposedLayout == null ? new Rank(-1L, msg.getClientID()) : getPhase2Rank(msgEpoch); setPhase1Rank(prepareRank, msgEpoch); log.debug("handleMessageLayoutPrepare: New phase 1 rank={}", getPhase1Rank(msgEpoch)); r.sendResponse(ctx, msg, CorfuMsgType.LAYOUT_PREPARE_ACK.payloadMsg(new LayoutPrepareResponse(highestProposedRank.getRank(), proposedLayout))); } }	Are these checks really necessary ? Its possible that this condition is false, at the time of the check, but becomes true immediately after the evaluation.
public void setSpeed(Double degreesPerSecond) { if (maxSpeed != -1 && degreesPerSecond > maxSpeed) { speed = maxSpeed; log.info("Trying to set speed to a value greater than max speed"); } this.speed = degreesPerSecond; for (String controller : controllers) { ServiceInterface si = Runtime.getService(controller); if (si.isLocal()) { ((ServoController) Runtime.getService(controller)).servoSetVelocity(this); } else { send(controller, "servoSetVelocity", this); } } broadcastState(); }	I think we need to maintain the backwards compatibility for the old skewl setSpeed . our new proper method is setVelocity which takes a double that specifies the angular velocity of the servo that we will try to achieve.
private String getMemberName(String topic) { String[] topicElements = getTopicElements(topic); if (topicElements.length != 5) throw new IllegalArgumentException("Event creation failed, invalid topic: " + topic); return topicElements[5]; }	Shouldn't a check for "lower then" not be sufficient?
private int countOccurrencesInTopology(final String topologyString, final String searchPattern) { final Matcher matcher = Pattern.compile(searchPattern).matcher(topologyString); final List<String> repartitionTopicsFound = new ArrayList<>(); while (matcher.find()) { repartitionTopicsFound.add(matcher.group()); } return repartitionTopicsFound.size(); }	likewise, this one can be static
public void run() { if (StringUtils.isNotBlank(id)) { boolean hasParent; if (vocabularyAndHasParent.get(name) == null) { String dirSchema = directoryService.getDirectorySchema(name); Schema schema = schemaManager.getSchema(dirSchema); hasParent = schema.hasField("parent"); vocabularyAndHasParent.put(name, hasParent); } else { hasParent = vocabularyAndHasParent.get(name); } Session directorySession = directoryService.open(name); if (!directorySession.hasEntry(id)) { Map<String, Object> entry = new HashMap<>(); entry.put("id", id); if (StringUtils.isEmpty(label)) { label = id; } entry.put("label", label); if (hasParent) { entry.put("parent", parent); } entry.put("obsolete", obsolete); entry.put("ordering", ordering); directorySession.createEntry(entry); } directorySession.close(); } }	can just do if (StringUtils.isBlank(id)) { return; } to reduce nesting level
private EntitySpec<? extends Entity> build(Topology topology, String node, Set<String> visited) { final Map<String, NodeTemplate> nodeTemplates = topology.getNodeTemplates(); final NodeTemplate nodeTemplate = nodeTemplates.get(node); visited.add(node); EntitySpec<?> spec = createSpec(node, nodeTemplate, topology); LOG.info("applying spec modifiers {}", specModifiers); for (EntitySpecModifier builder : specModifiers) { builder.apply(spec, nodeTemplate, topology); } for (String child : children.get(node)) { if (!visited.contains(child)) { final EntitySpec<? extends Entity> childSpec = build(topology, child, visited); spec.child(childSpec) .configure(SoftwareProcess.CHILDREN_STARTABLE_MODE, SoftwareProcess.ChildStartableMode.BACKGROUND_LATE); } } return spec; }	This is debug at best, probably trace, and should include the spec/nodeTemplate in question. One to tweak subsequently.
public static ReviewCompareAnnotationSupport getAnnotationSupport(Viewer contentViewer) { ReviewCompareAnnotationSupport support = (ReviewCompareAnnotationSupport) contentViewer.getData(KEY_ANNOTAION_SUPPORT); if (support == null) { if (support == null) { support = new ReviewCompareAnnotationSupport(contentViewer); contentViewer.setData(KEY_ANNOTAION_SUPPORT, support); } } return support; }	Making *really* sure it's null? ;)
private static Type getComponentOrElementType(Type arrayOrListType, ClientLogger logger) { if (arrayOrListType.getClass().isArray()) { return arrayOrListType.getClass().getComponentType(); } if (isList(arrayOrListType)) { ParameterizedType pt = (ParameterizedType) arrayOrListType; return pt.getActualTypeArguments()[0]; } throw logger.logExceptionAsError(new RuntimeException("Should not be there")); }	Can we add an actual exception message if we ever run into this issue in production.
private ThriftType convertEnumTypeField(Class enumClass, String fieldName){ List<ThriftType.EnumValue> enumValues = new ArrayList<ThriftType.EnumValue>(); String enumName = enumClass.getName(); try { List enumCollection = getEnumList(enumName); for (Object enumObj : enumCollection) { ScroogeEnumDesc enumDesc = ScroogeEnumDesc.fromEnum(enumObj); enumValues.add(new ThriftType.EnumValue(enumDesc.id, enumDesc.originalName)); } return new ThriftType.EnumType(enumValues); } catch (Exception e) { throw new ScroogeSchemaConversionException("Can not convert enum field " + fieldName, e); } }	are there Exceptions other than RuntimeExceptions?
public static Map<String, DbmsType> all() { Map<String, DbmsType> types = new HashMap<>(); types.put("ARRAY", ARRAY); types.put("BIGINT", BIGINT); types.put("BINARY", BINARY); types.put("BOOLEAN", BOOLEAN); types.put("CHARACTER", CHARACTER); types.put("DATE", DATE); types.put("DATETIME", DATETIME); types.put("DECIMAL", DECIMAL); types.put("DOUBLE", DOUBLE); types.put("DOUBLE PRECISION", DOUBLE_PRECISION); types.put("FLOAT", FLOAT); types.put("FLOAT4", FLOAT4); types.put("FLOAT8", FLOAT8); types.put("INT", INT); types.put("INTEGER", INTEGER); types.put("NUMBER", NUMBER); types.put("NUMERIC", NUMERIC); types.put("OBJECT", OBJECT); types.put("REAL", REAL); types.put("SMALLINT", SMALLINT); types.put("STRING", STRING); types.put("TEXT", TEXT); types.put("TIME", TIME); types.put("TIMESTAMP", TIMESTAMP); types.put("TIMESTAMP_LTZ", TIMESTAMP_LTZ); types.put("TIMESTAMP_NTZ", TIMESTAMP_NTZ); types.put("TIMESTAMP_TZ", TIMESTAMP_TZ); types.put("VARBINARY", VARBINARY); types.put("VARCHAR", VARCHAR); types.put("VARIANT", VARIANT); return types; }	It generates the map everytime you call all() method ? Why this map is not in a static{...} bloc code ?
private void restoreState(Bundle savedInstanceState) { if (savedInstanceState == null) return; boolean isInMultiSelectMode = savedInstanceState.getBoolean(BUNDLE_IN_MULTI_SELECT_MODE); if (isInMultiSelectMode) { mGridAdapter.setInMultiSelect(true); if (savedInstanceState.containsKey(BUNDLE_SELECTED_STATES)) { ArrayList<Integer> selectedItems = ListUtils.fromIntArray(savedInstanceState.getIntArray(BUNDLE_SELECTED_STATES)); mGridAdapter.setSelectedItems(selectedItems); setFilterSpinnerVisible(mGridAdapter.getSelectedItems().size() == 0); mSwipeToRefreshHelper.setEnabled(false); } } mHasRetrievedAllMedia = savedInstanceState.getBoolean(BUNDLE_HAS_RETRIEVED_ALL_MEDIA, false); mFilter = Filter.getFilter(savedInstanceState.getInt(BUNDLE_FILTER)); mEmptyViewMessageType = EmptyViewMessageType.getEnumFromString(savedInstanceState. getString(BUNDLE_EMPTY_VIEW_MESSAGE)); mIsDateFilterSet = savedInstanceState.getBoolean(BUNDLE_DATE_FILTER_SET, false); mStartDay = savedInstanceState.getInt(BUNDLE_DATE_FILTER_START_DAY); mStartMonth = savedInstanceState.getInt(BUNDLE_DATE_FILTER_START_MONTH); mStartYear = savedInstanceState.getInt(BUNDLE_DATE_FILTER_START_YEAR); mEndDay = savedInstanceState.getInt(BUNDLE_DATE_FILTER_END_DAY); mEndMonth = savedInstanceState.getInt(BUNDLE_DATE_FILTER_END_MONTH); mEndYear = savedInstanceState.getInt(BUNDLE_DATE_FILTER_END_YEAR); boolean datePickerShowing = savedInstanceState.getBoolean(BUNDLE_DATE_FILTER_VISIBLE); if (datePickerShowing) showDatePicker(); }	This leaves ActivityLauncher.newGalleryPost() unused - I think we should probably clean that up too.
public ClusterFeature get() { Cluster cluster = parent.getClusterEntity(); SupportedAdditionalClusterFeature feature = cluster.getAddtionalFeaturesSupported() .stream() .filter(f -> f.getFeature().getId().equals(asGuid(id))) .findFirst() .orElseThrow(() -> new WebApplicationException(Response.Status.NOT_FOUND)); return ClusterFeaturesMapper.map(feature.getFeature(), null); }	This code to get the feature is used here and in the remove method. I'd suggest to create a new BackendClusterFeatureHelper class and put this code there. Then you can call it from these methos. Look at BackendDataCenterHelper for example.
public Iterator getLocations() { return ORDERING.sortedCopy(this.storageLocations).iterator(); }	Please Specify the type properly here like Iterator<StorageLocation>.
public JarSet process() { JarSet newJars = new JarSet(); for (String p: syncProcessedPaths()) { synchronized (removedPaths) { removedPaths.add(new Path(p)); } project.getExtensionManager().pathRemoved(p); } boolean newRuntimeDetected = false; Set<String> processed = new HashSet<String>(); synchronized(this) { processed.addAll(processedPaths); } for (int i = 0; i < paths.size(); i++) { String p = paths.get(i); if(!requestForLoad(p)) continue; removedPaths.add(new Path(p)); String fileName = new File(p).getName(); if(EclipseResourceUtil.SYSTEM_JAR_SET.contains(fileName)) continue; XModelObject o = FileSystemsHelper.getLibs(model).getLibrary(p); if(o == null) continue; boolean nrd = project.getExtensionManager().setRuntimes(p, readRuntimes(o)); if(nrd) newRuntimeDetected = true; detectBeanModule(p, o, newJars); } for (FileAnyImpl s: servicesInSrc.keySet()) { IResource r = (IResource)s.getAdapter(IResource.class); if(r != null && r.exists()) { boolean nrd = project.getExtensionManager().setRuntimes(r.getFullPath().toString(), readRuntimesInService(s)); if(nrd) newRuntimeDetected = true; } } IJavaProject javaProject = EclipseResourceUtil.getJavaProject(project.getProject()); Set<String> recognizedRuntimes = CDIExtensionFactory.getInstance().getRecognizedRuntimes(javaProject); boolean nrd = project.getExtensionManager().setRuntimes("_recognized_", recognizedRuntimes); if(nrd) newRuntimeDetected = true; if(newRuntimeDetected) { for (String p: processed) { String fileName = new File(p).getName(); if(EclipseResourceUtil.SYSTEM_JAR_SET.contains(fileName)) continue; XModelObject o = FileSystemsHelper.getLibs(model).getLibrary(p); if(o != null) { detectBeanModule(p, o, newJars); } } } validateProjectDependencies(); return newJars; }	Let's move "_recognized_" to final static variable
public CoprocessorRpcChannel coprocessorService(ServerName serverName) { return null; }	Should these throw UnsupportedExceptions?
public static String getGatewayAliasDefaultTo(String overrideAlias) { if (StringUtils.isNotBlank(overrideAlias)) { return overrideAlias; } String alias = System.getProperty(NhincConstants.CLIENT_KEY_ALIAS); return StringUtils.isBlank(alias) ? NhincConstants.DEFAULT_CLIENT_KEY_ALIAS : alias; }	duplicate logic in getPrivateKeyAlias method().
public String toString() { return "exceededCount=" + m_exceededCount + "\nm_armed=" + m_armed; }	suggestion "\narmed=" + m_armed;
private void updateFileCacheSizeLimit() { boolean isAvailableSpaceLowerThanHighLimit; if(mDiskCacheIsExternal){ isAvailableSpaceLowerThanHighLimit = mStatFsHelper.testLowDiskSpace( StatFsHelper.StorageType.EXTERNAL, mDefaultCacheSizeLimit - mCacheStats.getSize()); } else{ isAvailableSpaceLowerThanHighLimit = mStatFsHelper.testLowDiskSpace( StatFsHelper.StorageType.INTERNAL, mDefaultCacheSizeLimit - mCacheStats.getSize()); } if (isAvailableSpaceLowerThanHighLimit) { mCacheSizeLimit = mLowDiskSpaceCacheSizeLimit; } else { mCacheSizeLimit = mDefaultCacheSizeLimit; } }	No need for code duplication. We can do something like:  StorageType storageType = mStorage.isExternal() ? StatFsHelper.StorageType.EXTERNAL : StatFsHelper.StorageType.INTERNAL;
BufferAndBacklog pollBuffer() { synchronized (buffers) { if (isBlocked) { return null; } Buffer buffer = null; if (buffers.isEmpty()) { flushRequested = false; } while (!buffers.isEmpty()) { BufferConsumer bufferConsumer = buffers.peek().getBufferConsumer(); buffer = bufferConsumer.build(); checkState(bufferConsumer.isFinished() || buffers.size() == 1 || (buffers.size() == 2 && buffers.peekLast().getBufferConsumer().getDataType() == Buffer.DataType.RECOVERY_COMPLETION), "When there are multiple buffers, an unfinished bufferConsumer can not be at the head of the buffers queue."); if (buffers.size() == 1) { flushRequested = false; } if (bufferConsumer.isFinished()) { buffers.poll().getBufferConsumer().close(); decreaseBuffersInBacklogUnsafe(bufferConsumer.isBuffer()); } if (buffer.readableBytes() > 0) { break; } buffer.recycleBuffer(); buffer = null; if (!bufferConsumer.isFinished()) { break; } } if (buffer == null) { return null; } if (buffer.getDataType().isBlockingUpstream()) { isBlocked = true; } updateStatistics(buffer); return new BufferAndBacklog( buffer, getBuffersInBacklog(), isDataAvailableUnsafe() ? getNextBufferTypeUnsafe() : Buffer.DataType.NONE, sequenceNumber++); } }	Why do we need that change here and not for aligned barriers?
public InMemoryMessageExchangeStore(final NetworkConfig config, TokenProvider tokenProvider) { if (config == null) { throw new NullPointerException("Configuration must not be null"); } if (tokenProvider == null) { throw new NullPointerException("TokenProvider must not be null"); } this.tokenProvider = tokenProvider; this.config = config; this.tokenLength = config.getInt(NetworkConfig.Keys.TOKEN_SIZE_LIMIT, MAX_TOKEN_LENGTH); LOGGER.log(Level.CONFIG, "using tokens of {0} bytes in length", tokenLength); }	Do we still need the token length here? It seems that the TokenProvider retrieves it from the config itself, doesn't it?
public ChangeInfo format(RevisionResource rsrc) throws OrmException { ChangeData cd = changeDataFactory.create(db.get(), rsrc.getControl()); Optional<PatchSet.Id> ps = Optional.of(rsrc.getPatchSet().getId()); return format(cd, ps); }	Why should format(RevisionResource) return a ChangeInfo and not (at the very least) a RevisionInfo? Though ideally it would return a Map<String, ActionInfo>
private String putBlob(Router router, BlobProperties blobProperties, byte[] usermetadata, byte[] content, RouterOperationCallback<String> putBlobCallback) throws Exception { byte[] buf = new byte[content.length]; Utils.readBytesFromStream(new ByteArrayInputStream(content), buf, 0, content.length); ReadableStreamChannel blobDataChannel = new ByteBufferReadableStreamChannel(ByteBuffer.wrap(buf)); Future<String> putBlobFuture; if (putBlobCallback == null) { putBlobFuture = router.putBlob(blobProperties, usermetadata, blobDataChannel); } else { putBlobFuture = router.putBlob(blobProperties, usermetadata, blobDataChannel, putBlobCallback); if (!putBlobCallback.awaitCallback(1, TimeUnit.SECONDS)) { throw new IllegalStateException("putBlob() timed out"); } else if (putBlobCallback.getException() != null) { verifyExceptionMatch(putBlobCallback, putBlobFuture); throw putBlobCallback.getException(); } assertTrue("PutBlob: Future is not done but callback has been received", putBlobFuture.isDone()); assertEquals("PutBlob: Future BlobId and callback BlobId do not match", putBlobFuture.get(), putBlobCallback.getResult()); } return putBlobFuture.get(); }	verifyExceptionMatch() blocks on future.get(), so isDone() will always be true when you're here, no? Also, if the callback was received, then we should ensure that future.get() returns immediately as well, so shouldn't it be a timed get within verifyExceptionMatch()?
public Patient createFHIRPatient(Patient patient) { List<String> errors = new ArrayList<String>(); org.openmrs.Patient omrsPatient = FHIRPatientUtil.generateOmrsPatient(patient, errors); if (!errors.isEmpty()) { StringBuilder errorMessage = new StringBuilder("The request cannot be processed due to the following issues \n"); for (int i = 0; i < errors.size(); i++) { errorMessage.append((i + 1) + " : " + errors.get(i) + "\n"); } throw new UnprocessableEntityException(errorMessage.toString()); } org.openmrs.api.PatientService patientService = Context.getPatientService(); omrsPatient = patientService.savePatient(omrsPatient); return FHIRPatientUtil.generatePatient(omrsPatient); }	This string should go into the messages.properties file.
private static void enforceTaskCountLimit(int size) { if (size > Limits.maxWorkflowTasks()) { throw new ConfigException("Too many for_range subtasks. Limit: " + Limits.maxWorkflowTasks()); } }	Showing size here would help users to understand what's wrong since it's likely users don't know an actual number of tasks with step.
public void testAllCases() throws IOException { boolean crNewline = true; test("", new String[]{}, 5); test("1234\n", new String[]{"1234", "\n"}, 10); test("1234", new String[]{"1234", ""}, 10); test("123\r\n123\r\nabc\n", new String[]{"123", "\r\n", "123", "\r\n", "abc", "\n"}, 20); test("123\r123\r\nabc\n", new String[]{"123", "\r", "123", "\r\n", "abc", "\n"}, 20); test("1234\r", new String[]{"1234", "\r"}, 5); test("1234\r\nabc\r\n", new String[]{"1234", "\r\n", "abc", "\r\n"}, 5); test( "123456", new String[]{"123456", ""}, 5); test( "12345", new String[]{"12345", ""}, 5); test( "1234\rA", new String[]{"1234", "\r", "A", ""}, 5); }	Can you repeat this same case with sizes 4 and 6 (buffer ending just before the carriage return, and just after the line feed)?
public void stop() { log.info("Stopping task"); try { writer.closeQuietly(); } finally { try { dialect.close(); } finally { dialect = null; } } }	Should we use org.apache.kafka.common.utils.Utils.closeQuietly ?
public void run() { SmppSession smppSession = smppClient.getSession(); if (smppSession != null && smppSession.isBound()) { try { smppSession.enquireLink(new EnquireLink(), enquireLinkTimeout); } catch (SmppTimeoutException | SmppChannelException | RecoverablePduException | UnrecoverablePduException error) { Log.warning("Enquire link failed, executing reconnect: " + error); smppClient.reconnect(); } catch (InterruptedException error) { Log.info("Enquire link interrupted, probably killed by reconnecting"); } } else { Log.error("Enquire link running while session is not connected"); } }	Exception can be included as a separate parameter.
protected void postProcessing(boolean closeEarly) { if (sortGraph) { if (ghStorage.isCHPossible() && isCHPrepared()) throw new IllegalArgumentException("Sorting a prepared CHGraph is not possible yet. See #12"); GraphHopperStorage newGraph = GHUtility.newStorage(ghStorage); GHUtility.sortDFS(ghStorage, newGraph); logger.info("graph sorted (" + getMemInfo() + ")"); ghStorage = newGraph; } if (!hasInterpolated() && hasElevation()) { interpolateBridgesAndOrTunnels(); } initLocationIndex(); importPublicTransit(); if (lmPreparationHandler.isEnabled()) lmPreparationHandler.createPreparations(ghStorage, locationIndex); loadOrPrepareLM(closeEarly); if (chPreparationHandler.isEnabled()) chPreparationHandler.createPreparations(ghStorage); if (isCHPrepared()) { for (CHProfile profile : chPreparationHandler.getCHProfiles()) { if (!getProfileHash(profile.getProfile()).isEmpty() && !getProfileHash(profile.getProfile()).equals("" + profilesByName.get(profile.getProfile()).getVersion())) throw new IllegalArgumentException("CH preparation of " + profile.getProfile() + " already exists in storage and doesn't match configuration"); } } else { prepareCH(closeEarly); } }	Why is isEmpty() treated special here? Why is it possible for the hash to be empty?
private Long getFirstValidPrivateId(List<InstanceGroup> instanceGroups) { LOGGER.debug("Get first valid PrivateId of instanceGroups"); long highest = instanceGroups.stream() .flatMap(ig -> ig.getAllInstanceMetaData().stream()) .filter(im -> im.getPrivateId() != null) .map(InstanceMetaData::getPrivateId) .max(Long::compare) .orElse(0L); LOGGER.debug("Highest privateId: {}", highest); return highest == 0 ? 0 : highest + 1; }	so this will produce invalid output. if we have highest ID 0 then we will return 0 as first valid id. this should be an Optional<Long> and the return look like:  return highest.isPresent() ? highest.get() + 1 : 0;  also we might have a test for this method to be sure we don't break it in the future
private void applyChanges(Sample target, Sample source) throws IOException { target.setDescription(source.getDescription()); target.setSampleType(source.getSampleType()); target.setReceivedDate(source.getReceivedDate()); target.setQcPassed(source.getQcPassed()); target.setScientificName(source.getScientificName()); target.setTaxonIdentifier(source.getTaxonIdentifier()); if (!target.getAlias().equals(source.getAlias()) && (!isDetailedSample(target) || (isDetailedSample(target) && !((SampleAdditionalInfo) target).hasNonStandardAlias()))) { validateAliasUniqueness(source.getAlias()); } target.setAlias(source.getAlias()); target.setDescription(source.getDescription()); target.setEmpty(source.isEmpty()); target.setVolume(source.getVolume()); if (!isStringBlankOrNull(source.getIdentificationBarcode())) { target.setIdentificationBarcode(source.getIdentificationBarcode()); } if (isDetailedSample(target)) { sampleAdditionalInfoService.applyChanges((SampleAdditionalInfo) target, (SampleAdditionalInfo) source); if (isIdentitySample(target)) { Identity iTarget = (Identity) target; Identity iSource = (Identity) source; iTarget.setInternalName(iSource.getInternalName()); iTarget.setExternalName(iSource.getExternalName()); } if (isTissueSample(target)) { sampleTissueService.applyChanges((SampleTissue) target, (SampleTissue) source); } if (isTissueProcessingSample(target)) { applyChanges((SampleTissueProcessing) target, (SampleTissueProcessing) source); } if (isAliquotSample(target)) { SampleAliquot saTarget = (SampleAliquot) target; SampleAliquot saSource = (SampleAliquot) source; saTarget.setSamplePurpose(saSource.getSamplePurpose()); } if (isStockSample(target)) { SampleStock ssTarget = (SampleStock) target; SampleStock ssSource = (SampleStock) source; ssTarget.setStrStatus(ssSource.getStrStatus()); ssTarget.setConcentration(ssSource.getConcentration()); ssTarget.setDNAseTreated(ssSource.getDNAseTreated()); } } }	This will prevent changing to null, which should be allowed
public Node(String name, Id id) throws NodeException { Objects.requireNonNull(name); Objects.requireNonNull(id); this.mName = name; this.mId = id; }	Or even better, this.mName = Objects.requireNonNull(name);. To be check everywhere else.
public boolean Validate() { boolean isNew = getModel().getIsNew(); int maxAllowedVms = configurator.getMaxVmsInPool(); int assignedVms = getModel().getAssignedVms().AsConvertible().Integer(); getModel().getNumOfDesktops().ValidateEntity( new IValidation[] { new NotEmptyValidation(), new LengthValidation(4), new IntegerValidation(isNew ? 1 : 0, isNew ? maxAllowedVms : maxAllowedVms - assignedVms) }); getModel().getPrestartedVms().ValidateEntity( new IValidation[] { new NotEmptyValidation(), new IntegerValidation(0, assignedVms) }); getModel().setIsGeneralTabValid(getModel().getIsGeneralTabValid() && getModel().getName().getIsValid() && getModel().getNumOfDesktops().getIsValid() && getModel().getPrestartedVms().getIsValid()); getModel().setIsPoolTabValid(true); return super.Validate() && getModel().getName().getIsValid() && getModel().getNumOfDesktops().getIsValid() && getModel().getPrestartedVms().getIsValid(); }	Do we have to use the configurator for fetching 'MaxVmsInPool' value? A lot of configuration values are fetched in 'VmModelBehaviorBase' (e.g. GetMaxNumOfVmSockets) - try to retrieve it once 'PoolModelBehaviorBase' if it's not too cumbersome.
synchronized void flush() { if (_kafkaProducer != null) { try { CompletableFutureUtils.within(CompletableFuture.runAsync(() -> _kafkaProducer.flush()), Duration.ofMillis(_flushTimeout)).join(); } catch (CompletionException e) { Throwable cause = e.getCause(); if (cause instanceof InterruptException) { _log.warn("Kafka producer flush interrupted, closing producer {}.", _kafkaProducer); shutdownProducer(); throw (InterruptException) cause; } else if (cause instanceof java.util.concurrent.TimeoutException) { _log.warn("Kafka producer flush timed out after {}ms. Destination topic may be unavailable.", _flushTimeout); } throw e; } } }	CompletableFuture.runAsync() uses the common pool which isn't the best option for a potentially long blocking call like Producer.flush(). Even if we provide our own thread pool to runAsync(), the CompletableFuture we'll get won't give us a way to interrupt a Producer.flush() call that exceeds the allowed timeout, which is necessary to free up the thread-pool thread in question. This is because calling cancel(true) on a CompletableFuture returned by runAsync() only causes a cancellation exception to be propagated without interrupting the blocked thread pool. I'm afraid our only option here seems to be using an ExecutorService directly java // It's okay to use a single thread executor since flush() is synchronized ExecutorService executor = Executors.newSingleThreadExecutor(); Future<?> future = executor.submit(() -> super.flush()); try { // Block until timeout elapses future.get(_flushTimeout, TimeUnit.MILLISECONDS); } catch (TimeoutException e) { ... // Interrupt the Producer.flush() call to free up the blocked thread future.cancel(true); ... }
public void testPropertyNameOnMethodName() throws NoSuchMethodException { class Hotel { String hotelName; public String getHotelName() { return hotelName; } } Method m = Hotel.class.getDeclaredMethod("getHotelName"); assertMemberValue(m, "getHotelName"); }	Does GSON maintain full method names or does it drop Java bean notation? I know in Jackson's case this would serialize as hotelName (possibly HotelName as I'm not completely certain about how it handles casing).
void oneParameterAndStatementUtilityConstructor() { LambdaExpr expr = new LambdaExpr(new Parameter(new UnknownType(), "a"), parseStatement("return 5;")); assertEquals("a -> return 5;", expr.toString()); }	I don't think this is valid Java code...
public void useDefaultKeyPair() throws KeyStoreException { String alias = Config.<String>GetValue(ConfigValues.CertAlias); String p12 = Config.<String>GetValue(ConfigValues.keystoreUrl); char[] password = Config.<String>GetValue(ConfigValues.keystorePass).toCharArray(); KeyStore.PrivateKeyEntry entry; InputStream in = null; try { in = new FileInputStream(p12); KeyStore ks = KeyStore.getInstance("PKCS12"); ks.load(in, password); entry = (KeyStore.PrivateKeyEntry)ks.getEntry( alias, new KeyStore.PasswordProtection(password) ); } catch (Exception e) { throw new KeyStoreException( String.format( "Failed to get certificate entry from key store: %1$s/%2$s", p12, alias ), e ); } finally { Arrays.fill(password, '*'); if (in != null) { try { in.close(); } catch(IOException e) { log.error("Cannot close key store", e); } } } if (entry == null) { throw new KeyStoreException( String.format( "Bad key store: %1$s/%2$s", p12, alias ) ); } setKeyPair( new KeyPair( entry.getCertificate().getPublicKey(), entry.getPrivateKey() ) ); }	These ^ could be final.
protected void endVmCommand() { Snapshot createdSnapshot = getSnapshotDao().get(getVmId(), getParameters().getSnapshotType(), SnapshotStatus.LOCKED); boolean taskGroupSucceeded = createdSnapshot != null && getParameters().getTaskGroupSuccess(); boolean liveSnapshotRequired = isLiveSnapshotApplicable(); boolean liveSnapshotSucceeded = false; if (taskGroupSucceeded) { getSnapshotDao().updateStatus(createdSnapshot.getId(), SnapshotStatus.OK); if (liveSnapshotRequired) { liveSnapshotSucceeded = performLiveSnapshot(createdSnapshot); } else { if (getParameters().isSaveMemory() && createdSnapshot.containsMemory()) { logMemorySavingFailed(); getSnapshotDao().removeMemoryFromSnapshot(createdSnapshot.getId()); removeMemoryVolumesOfSnapshot(createdSnapshot); } } } else { if (createdSnapshot != null) { revertToActiveSnapshot(createdSnapshot.getId()); if (getParameters().isSaveMemory() && createdSnapshot.containsMemory()) { removeMemoryVolumesOfSnapshot(createdSnapshot); } } else { log.warnFormat("No snapshot was created for VM {0} which is in LOCKED status", getVmId()); } } boolean archSupportSnapshot = isSnapshotSupportedByArchitecture(getVm().getClusterArch(), getVm().getVdsGroupCompatibilityVersion()); if (getParameters().isSaveMemory() && (archSupportSnapshot || !FeatureSupported.memorySnapshot(getVm().getVdsGroupCompatibilityVersion()))) { log.warnFormat("A memory snapshot was required but not created, since VM architecture does not support it.", getVmId()); } incrementVmGeneration(); endActionOnDisks(); setSucceeded(taskGroupSucceeded && (!liveSnapshotRequired || liveSnapshotSucceeded)); getReturnValue().setEndActionTryAgain(false); }	same here (!archSupportSnapshot) ? how about extract this check to separate method like 'isMemorySnapshotSupported' that checks the cluster compatibility version and the architecture (because I see that is appears multiple times here) ?
public static void main(String[] args) throws Exception { Optional.ofNullable(System.getProperty("logback.configurationFile")) .stream() .forEach(file -> System.err.println("Load logging config from " + file)); Configuration configuration = Configuration.builder() .useWorkingDirectoryEnvProperty() .build(); LOGGER.info("Loading configuration {}", configuration); GuiceJamesServer server = createServer(configuration) .combineWith(new JMXServerModule()); JamesServerMain.main(server); }	Can't we rely on System.out here because as far as I know we are not printing an error but an expected behavior.
public String createNewProcess() { try { createProcessHierarchy(); if (Objects.nonNull(PrimeFaces.current())) { PrimeFaces.current().executeScript("PF('sticky-notifications').renderMessage({'summary':'" + Helper.getTranslation("processSaving") + "','detail':'" + Helper.getTranslation( "youWillBeRedirected") + "','severity':'info'});"); } return processListPath; } catch (DataException e) { Helper.setErrorMessage("errorSaving", new Object[] {ObjectType.PROCESS.getTranslationSingular() }, logger, e); } catch (IOException | ProcessGenerationException e) { logger.error(e.getLocalizedMessage()); } return this.stayOnCurrentPage; }	suggestion if (Objects.nonNull(PrimeFaces.current()) && Objects.nonNull(FacesContext.getCurrentInstance()) {
private static void appendLib(StringBuilder classpath, String libDirName, boolean useLibJarsFormat) { File libDir = new File(libDirName); if (!libDir.exists()) { System.err.println("ERROR - Directory needed for classpath does not exist: " + libDirName); System.exit(-1); } if (useLibJarsFormat) { File[] files = libDir.listFiles(); Arrays.sort(files); for (File f : files) { if (f.isFile() && f.getName().endsWith(".jar")) { if (classpath.length() != 0) { classpath.append(","); } classpath.append(f.getAbsolutePath()); } } } else { if (classpath.length() != 0) { classpath.append(":"); } classpath.append(libDir + "/*"); } }	Should this be libDir.getAbsolutePath() like f..getAbsolutePath() above?
public boolean close() { synchronized (startStopLock) { if (!started.get() || executorService.isShutdown()) { LOG.info("Already shutdown, ignoring"); return false; } started.set(false); executorService.shutdownNow(); final ListenableFuture<?> future = this.future; if (future != null) { if (!future.isDone() && !future.cancel(true) && !future.isDone()) { LOG.error("Error cancelling future for topic [%s]", getKafkaTopic()); return false; } } if (!cacheManager.delete(factoryId)) { LOG.error("Error removing [%s] for topic [%s] from cache", factoryId, getKafkaTopic()); return false; } if (consumerConnector != null) { consumerConnector.shutdown(); } return true; } }	calling stop multiple times should return true thought
public Metadata(Map<String, String[]> metadata) { md = metadata; }	I would check for null and make a copy of the map
private void evaluateXPath() { Document document = getWebSourceCode().getDocument(expression.contains(":")); try { NodeList nodes = (NodeList) getXPathExpressionForDocument(document).evaluate(document, XPathConstants.NODESET); for (int i = 0; i < nodes.getLength(); i++) { int lineNumber = getWebSourceCode().getLineForNode(nodes.item(i)); createViolation(lineNumber); } } catch (XPathExpressionException exceptionNodeSet) { try { Boolean result = (Boolean) getXPathExpressionForDocument(document).evaluate(document, XPathConstants.BOOLEAN); if (result) { createViolation(0); } } catch (XPathExpressionException exceptionBoolean) { throw new IllegalStateException(String.format("Can't evaluate expression \"%s\"", expression), exceptionBoolean); } } }	![CRITICAL](<LINK_1> Either log or rethrow this exception. [![rule](<LINK_2>](<LINK_0>
protected PageableResult doGetAll(RequestContext context) throws ResponseException { return new AlreadyPaged<AutoGenerationOption>(Context.getService(IdentifierSourceService.class).getAutoGenerationOption(3), context); }	What does the 3 parameter mean?
protected BinaryLogicalFilterPredicate(FilterPredicate left, FilterPredicate right) { Preconditions.checkNotNull(left, "left"); Preconditions.checkNotNull(right, "right"); this.left = left; this.right = right; String name = getClass().getSimpleName().toLowerCase(); this.toString = name + "(" + left + ", " + right + ")"; }	same here:  this.left = checkNotNull(left, "left");
public boolean setAlwaysOnVpnPackage(int userId, String packageName, boolean lockdown) { enforceConnectivityInternalPermission(); enforceCrossUserPermission(userId); if (LockdownVpnTracker.isEnabled()) { return false; } synchronized (mVpns) { Vpn vpn = mVpns.get(userId); if (vpn == null) { Slog.w(TAG, "User " + userId + " has no Vpn configuration"); return false; } if (!vpn.setAlwaysOnPackage(packageName, lockdown)) { return false; } if (!startAlwaysOnVpn(userId)) { vpn.setAlwaysOnPackage(null, false); return false; } } return true; }	Shouldn't this be inside the synchronized{} block ? Also, can't this be simplified to if (!mLockdownEnabled) ?
private FilterExpression parseQualifierContent(QualifierType type) { if (type == QualifierType.SORT) { return parseSortKeys(); } else if (isCompoundId(type, lookAhead())) { return parseCompoundId(); } else if (isRangeOperatorToken(lookAhead())) { return parseRangeOperator(type, lookAhead()); } else if (isDateToken(lookAhead())) { return parseDateOrDateRange(type); } else if (isNumberToken(lookAhead())) { return parseNumberOrNumberRange(type); } else if (isQuotedContentToken(lookAhead())) { Token quotedContent = consume(); return parseQuotedContent(type, quotedContent); } else if (isKeywordToken(lookAhead())) { return new Qualifier(type, consume().getValue()); } else { throw new ParseException(String.format("Invalid content for qualifier %s: %s", type, lookAhead())); } }	Checking for failure here leads to a non-id qualifier being used with a compound id being a parse error. Could we follow the other parse* functions and let it fail later, as a semantic error? If for some reason we want to use compound ids with other qualifiers, it would be easier.
protected Optional<DominantHandProperty> getForEntity(Entity entity) { if(!(entity instanceof EntityPlayer)) return Optional.empty(); EnumHandSide hand = ((EntityPlayer) entity).getPrimaryHand(); HandType type = (HandType) (Object) hand; return Optional.of(new DominantHandProperty(type)); }	if (, and if statements require braces.
private boolean isUnregisteredDisk() { DiskImage unregisteredDisk; storagePoolId = BackendDataCenterHelper.lookupByStorageDomainId(this, storageDomainId); try { GetUnregisteredDiskQueryParameters getDiskParams = new GetUnregisteredDiskQueryParameters(guid, storageDomainId, storagePoolId); unregisteredDisk = getEntity(DiskImage.class, QueryType.GetUnregisteredDisk, getDiskParams, guid.toString()); } catch (WebApplicationException e) { if (e.getResponse().getStatus() == Response.Status.NOT_FOUND.getStatusCode()) { return false; } throw e; } return unregisteredDisk != null; }	BTW: if "getEntity()" either returns the result or throws a WebApplicationException exception with "NOT_FOUND" status, the code can be simplified to always "return true" at the end and no need in "unregisteredDisk" local variable at all.
public long getFileSize(String ext) { Long size = sizeMap.get(ext); return (size == null) ? 0 : size.longValue(); }	No parens on condition.
public boolean tryAdvance(Consumer<? super BytesHandle> action) { try { FormatEntry nextEntry = getNextEntry(); if (nextEntry == null) { return false; } BytesHandle nextBytesHandle = readEntry(nextEntry); action.accept(nextBytesHandle); splitter.count++; } catch (IOException e) { e.printStackTrace(); } return true; }	The IDEs tend to generate boilerplate code that suppresses exceptions. Unless we know it is safe to suppress an exception, the best practice is to throw the exception. In this case, if we encounter an IOException, something must be wrong with the zipfile. Where the exception is a checked exception (like IOException) that's not allowed by the signature (as with the tryAdvance() method), we can rethrow it with something like throw new RuntimeException("Could not read ZipEntry", e); To be clear, the same issue affects the other tryAdvance() method.
public static ViewGroup.OnHierarchyChangeListener tryGetOnHierarchyChangeListenerHack( ViewGroup viewGroup) { if (sOnHierarchyChangeListenerField == null) { return null; } try { return (ViewGroup.OnHierarchyChangeListener)sOnHierarchyChangeListenerField.get(viewGroup); } catch (IllegalAccessException e) { throw new RuntimeException(e); } }	This too, possibly
private HullConfig read(String shipName) { final HullConfig.Data configData = new HullConfig.Data(); configData.internalName = shipName; Json json = Assets.getJson(shipName); try { readProperties(json.getJsonValue(), configData); } catch (IllegalArgumentException e) { throw new IllegalArgumentException("The JSON of ship " + shipName + " is missing, or has malformed, a required parameter" + e.getMessage().split(":")[1]); } catch (SerializationException e) { throw new SerializationException("The JSON of ship " + shipName + " has invalid syntax" + e.getMessage().split(":")[1]); } configData.tex = Assets.getAtlasRegion(shipName); configData.icon = Assets.getAtlasRegion(shipName + "Icon"); validateEngineConfig(configData); json.dispose(); return new HullConfig(configData); }	Take a look at what the error message you're splitting is :wink: (hint: it's the entire JSON file)
public ImmutableValue<Entity> leashHolder() { return new ImmutableSpongeEntityValue<>(Keys.LEASH_HOLDER, getValue()); }	This should be stored in a field.
public int onStartCommand(@Nullable Intent intent, int flags, int startId) { if (intent != null) { if (intent.getAction() != null) { restoreQueuesAndPositionIfNecessary(); String action = intent.getAction(); switch (action) { case ACTION_TOGGLE_PAUSE: if (isPlaying()) { pause(); } else { play(); } break; case ACTION_PAUSE: pause(); break; case ACTION_PLAY: play(); break; case ACTION_PLAY_PLAYLIST: Playlist playlist = intent.getParcelableExtra(INTENT_EXTRA_PLAYLIST); int shuffleMode = intent.getIntExtra(INTENT_EXTRA_SHUFFLE_MODE, getShuffleMode()); if (playlist != null) { List<Song> playlistSongs; if (playlist instanceof AbsCustomPlaylist) { playlistSongs = ((AbsCustomPlaylist) playlist).getSongs(getApplicationContext()); } else { playlistSongs = (List<Song>) (List) PlaylistSongLoader.getPlaylistSongList(getApplicationContext(), playlist.id); } if (!playlistSongs.isEmpty()) { if (shuffleMode == SHUFFLE_MODE_SHUFFLE) { int startPosition = 0; if (!playlistSongs.isEmpty()) { startPosition = new Random().nextInt(playlistSongs.size()); } openQueue(playlistSongs, startPosition, true); setShuffleMode(shuffleMode); } else { openQueue(playlistSongs, 0, true); } } else { Toast.makeText(getApplicationContext(), R.string.playlist_is_empty, Toast.LENGTH_LONG).show(); } } else { Toast.makeText(getApplicationContext(), R.string.playlist_is_empty, Toast.LENGTH_LONG).show(); } break; case ACTION_REWIND: back(true); break; case ACTION_SKIP: playNextSong(true); break; case ACTION_STOP: case ACTION_QUIT: pendingQuit = false; quit(); break; case ACTION_PENDING_QUIT: pendingQuit = true; break; } } } return START_NOT_STICKY; }	This seems redundant.
public void configurePipeline(PipelineConfigurer configurer) throws IllegalArgumentException { super.configurePipeline(configurer); if (this.config.format == null || this.config.format.isEmpty()) { throw new IllegalArgumentException("Format is not specified. Allowed values are DEFAULT, EXCEL, MYSQL," + " RFC4180, PDL & TDF"); } if (!this.config.format.equalsIgnoreCase("DEFAULT") && !this.config.format.equalsIgnoreCase("EXCEL") && !this.config.format.equalsIgnoreCase("MYSQL") && !this.config.format.equalsIgnoreCase("RFC4180") && !this.config.format.equalsIgnoreCase("TDF") && !this.config.format.equalsIgnoreCase("PDL")) { throw new IllegalArgumentException("Format specified is not one of the allowed values. Allowed values are " + "DEFAULT, EXCEL, MYSQL, RFC4180, PDL & TDF"); } if (configurer.getStageConfigurer().getInputSchema() != null) { Schema.Field inputSchemaField = configurer.getStageConfigurer().getInputSchema().getField(config.field); if (inputSchemaField == null) { throw new IllegalArgumentException( "Field " + config.field + " is not present in the input schema, it is expected"); } else { if (!inputSchemaField.getSchema().getType().equals(Schema.Type.STRING)) { throw new IllegalArgumentException( "Field Type " + config.field + " should be String"); } } } try { Schema outputSchema = Schema.parseJson(this.config.schema); configurer.getStageConfigurer().setOutputSchema(outputSchema); } catch (IOException e) { throw new IllegalArgumentException("Format of schema specified is invalid. Please check the format."); } }	Type for Field + config.field + must be String
private void applyProperties(AssociationKey associationKey, RowKey rowKey, Relationship relationship) { String[] rowKeyIndexColumnNames = associationKey.getRowKeyIndexColumnNames(); for ( int i = 0; i < rowKeyIndexColumnNames.length; i++ ) { for ( int j = 0; j < rowKey.getColumnNames().length; j++ ) { if ( rowKeyIndexColumnNames[i].equals( rowKey.getColumnNames()[j] ) ) { relationship.setProperty( rowKeyIndexColumnNames[i], rowKey.getColumnValues()[j] ); break; } } } }	Should there be RowKey#getColumnValue(String name)? This would make this code here a bit easier to grasp.
private Diagnostic handleMigrationOptions() { Diagnostic migrationMismatchDiagnostic = null; VSMVersionSAXParser parser = new VSMVersionSAXParser(uri); String loadedVersion = parser.getVersion(new NullProgressMonitor()); boolean migrationIsNeeded = true; if (loadedVersion != null) { Version parsedLoadedVersion = Version.parseVersion(loadedVersion); Version lastMigrationVersion = VSMMigrationService.getInstance().getLastMigrationVersion(); boolean attemptToLoadMoreRecentVSM = lastMigrationVersion.compareTo(parsedLoadedVersion) < 0; if (attemptToLoadMoreRecentVSM) { migrationMismatchDiagnostic = new XMIException(MessageFormat.format(Messages.DescriptionResourceImpl_versionMismatchMessage, uri, parsedLoadedVersion, lastMigrationVersion)); } migrationIsNeeded = VSMMigrationService.getInstance().isMigrationNeeded(parsedLoadedVersion); } Object versionOption = this.getDefaultLoadOptions().get(AbstractSiriusMigrationService.OPTION_RESOURCE_MIGRATION_LOADEDVERSION); if (!migrationIsNeeded && versionOption != null) { removeMigrationMechanism(); } else if (migrationIsNeeded && (versionOption == null || !versionOption.equals(loadedVersion))) { DescriptionResourceImpl.addMigrationOptions(loadedVersion, this.getDefaultLoadOptions(), this.getDefaultSaveOptions()); } return migrationMismatchDiagnostic; }	Strange to use an XMIException here, which would imply something is corrupted at the XMI level, which is not the case. Especially since there is a AirdResourceVersionMismatchException defined in the same patch which implements Resource.Diagnostic.
public <T> T get(String key, String field) { RedisConnection<byte[], byte[]> redisCommands = null; try { redisCommands = getRedisConnection(); byte[] serializedData = redisCommands.hget(key.getBytes(), field.getBytes()); T deserializeObject = new JavaSerializer().deserializeObject(serializedData); return deserializeObject; } catch (Exception e) { logger.error("Exception Occurred while getting a value from redis", e); } finally { closeConnection(redisCommands); } return null; }	Catching the exception hides network- and classpath/structural problems and returns null to the caller.
public void testScaffoldSetup() throws Exception { Project project = projectHelper.createWebProject(); try (CommandController c = testHarness.createWizardController(ScaffoldSetupWizard.class, project.getRoot())) { c.initialize(); c.setValueFor("provider", "Mock Scaffold Provider"); c.setValueFor("webRoot", ""); Assert.assertTrue(c.isValid()); Result result = c.execute(); Assert.assertNotNull(result); } }	Is this test really testing much? It doesn't assert that the result is not a failure: !(result instanceof Failed) for instance.
private Set<Integer> getTimeseriesLayerIds(int layerId) throws ActionException { Set<Integer> timeseriesLayerIds = new HashSet<>(); for (OskariLayer layer : mapLayerService.findAll()) { JSONObject options = layer.getOptions(); try { if (options != null && options.has("timeseries")) { JSONObject timeseriesOptions = options.getJSONObject("timeseries"); Integer metadataLayerId = timeseriesOptions.getJSONObject("metadata").getInt("layer"); if (metadataLayerId == layerId) { timeseriesLayerIds.add(layer.getId()); } } } catch (JSONException e) { throw new ActionException("Cannot parse layer metadata options for layer: " + layer.getName() + ", id: " + layer.getId()); } } return timeseriesLayerIds; }	This could throw a NPE if options has timeseries but not metadata under it.
public void testSignInSucceeded() { Activity mockActivty = mock(Activity.class); ActivityHelper mockActivityHelper = mock(ActivityHelper.class); FirebaseUser mockFirebaseUser = TestHelper.makeMockFirebaseUser(); IDPResponse mockIdpResponse = mock(IDPResponse.class); CredentialSignInHandler credentialSignInHandler = new CredentialSignInHandler( mockActivty, mockActivityHelper, RC_ACCOUNT_LINK, RC_SAVE_CREDENTIALS, mockIdpResponse); Context mockContext = mock(Context.class); FlowParameters mockFlowParams = mock(FlowParameters.class); Task mockTask = mock(Task.class); when(mockTask.isSuccessful()).thenReturn(true); when(mockTask.getResult()).thenReturn(new FakeAuthResult(mockFirebaseUser)); when(mockActivityHelper.getApplicationContext()).thenReturn(mockContext); when(mockActivityHelper.getFlowParams()).thenReturn(mockFlowParams); credentialSignInHandler.onComplete(mockTask); ArgumentCaptor<Intent> intentCaptor = ArgumentCaptor.forClass(Intent.class); ArgumentCaptor<Integer> intCaptor = ArgumentCaptor.forClass(Integer.class); verify(mockActivty).startActivityForResult(intentCaptor.capture(), intCaptor.capture()); Intent capturedIntent = intentCaptor.getValue(); assertEquals(RC_SAVE_CREDENTIALS, (int) intCaptor.getValue()); assertEquals( SaveCredentialsActivity.class.getName(), capturedIntent.getComponent().getClassName()); assertEquals( TestConstants.EMAIL, capturedIntent.getExtras().getString(ExtraConstants.EXTRA_EMAIL)); assertEquals( TestConstants.NAME, capturedIntent.getExtras().getString(ExtraConstants.EXTRA_NAME)); assertEquals( TestConstants.PHOTO_URL, capturedIntent.getExtras().getString(ExtraConstants.EXTRA_PROFILE_PICTURE_URI)); }	I think you should be able to use Tasks.forResult(new FakeAuthResult(mockFirebaseUser)) instead of a mock object without consequence here, it should be more readable.
public void testRecover() throws Exception { CountDownLatch countDownLatch = new CountDownLatch(2); final AtomicReference<Boolean> notified = new AtomicReference<Boolean>(false); NotifyListener listner = new NotifyListener() { @Override public void notify(List<URL> urls) { notified.set(Boolean.TRUE); } }; MockRegistry mockRegistry = new MockRegistry(registryUrl, countDownLatch); mockRegistry.register(serviceUrl); mockRegistry.subscribe(serviceUrl, listner); Assert.assertEquals(mockRegistry.getRegistered().size(), 1); Assert.assertEquals(mockRegistry.getSubscribed().size(), 1); mockRegistry.recover(); Assert.assertEquals(mockRegistry.getFailedSubscribed().size(), 1); Assert.assertEquals(countDownLatch.getCount(), 0); }	please fix typo listner, should be listener ?
public int compare(final Account account1, final Account account2) { if (account1.getPreferredEmail() != null && account2.getPreferredEmail() != null) { return account1.getPreferredEmail().compareTo( account2.getPreferredEmail()); } if (account1.getFullName() != null && account2.getFullName() != null) { return account1.getFullName().compareTo(account2.getFullName()); } return Integer.valueOf(account1.getId().get()).compareTo( Integer.valueOf(account2.getId().get())); }	This isn't stable, is it? We should compare email to "" , and the same with full name.
public void onNext(final AggregationMessage aggregationMessage) { final String workerId = aggregationMessage.getSourceId().toString(); final String localState = codec.decode(aggregationMessage.getData().array()); final String globalState = globalStateMachine.getCurrentState(); switch (globalState) { case STATE_INIT: break; case STATE_RUN: if (localState.equals(STATE_INIT)) { sendResponseMessage(workerId, new byte[0]); return; } break; case STATE_CLEANUP: default: throw new RuntimeException("Invalid state"); } blockedWorkerIds.add(workerId); LOG.log(Level.FINE, "Receive a synchronization message from {0}. {1} messages have been received out of {2}.", new Object[]{workerId, blockedWorkerIds.size(), numWorkersToSync}); tryReleaseWorkers(); }	It'd be helpful to remind what's going on here, especially mentioning that _In case when a worker's local state is behind the globally synchronized state, this implies the worker is added by EM. If so, the worker is replied to continue until it reaches the global state_.
public HttpMessage setProtocolVersion(HttpVersion version) { ObjectUtil.checkNotNull(version, "version"); this.version = version; return this; }	nit: you can merge both lines above as checkNotNull will return the given argument
private void validate() { assertThat(localSegment, Objects::nonNull, () -> new AxonConfigurationException("The localSegment may not be null")); assertThat(channel, Objects::nonNull, () -> new AxonConfigurationException("JChannel may not be null")); assertThat(clusterName, Objects::nonNull, () -> new AxonConfigurationException("The clusterName may not be null")); assertThat(serializer, Objects::nonNull, () -> new AxonConfigurationException("Serializer may not be null")); assertThat(routingStrategy, Objects::nonNull, () -> new AxonConfigurationException("RoutingStrategy may not be null")); assertThat(consistentHashChangeListener, Objects::nonNull, () -> new AxonConfigurationException("ConsistentHashChangeListener may not be null")); }	Null values at this point should not be really reported as a property being null, but as a mandatory property for which no value was provided
private Object unwrapBinary(Object obj, BinaryReaderHandles hnds) { if (obj instanceof BinaryObjectImpl) { BinaryObjectImpl obj0 = (BinaryObjectImpl)obj; return marsh.deserialize(BinaryHeapInputStream.create(obj0.array(), obj0.start()), hnds); } else if (obj instanceof BinaryObject ) return ((BinaryObject)obj).deserialize(); else if (BinaryUtils.knownCollection(obj)) return unwrapCollection((Collection<Objects>)obj, hnds); else if (BinaryUtils.knownMap(obj)) return unwrapMap((Map<Object, Object>)obj, hnds); else if (obj instanceof Object[]) return unwrapArray((Object[])obj, hnds); else return obj; }	Cosmetic. Extra space between BinaryObject and ).
public void put(String handle, LocalDateTime lastUsed) { storageLock.lock(); try { if (_storage == null) { throw new RuntimeException(EXCEPTION_STORAGE); } if (lastUsed == null) { _storage.put(LAST_USED.getKey(handle), (String) null); } else { String gsonStr = gson.toJson(lastUsed); _storage.put(LAST_USED.getKey(handle), gsonStr); } } finally { storageLock.unlock(); } }	do not throw RuntimeException
public ArrayList<LinkInfo> getRemoteGoToLinks() throws IOException { if (remoteGoToLinks == null) { loadAndPreflightPdf(); remoteGoToLinks = parseForLinks(PDActionRemoteGoTo.SUB_TYPE); } return remoteGoToLinks; }	List<LinkInfo> (check below for other method signatures)
private void breakModifies(ProgressMonitor pm) throws IOException { if (breakScore <= 0) return; ArrayList<DiffEntry> newEntries = new ArrayList<DiffEntry>(entries.size()); pm.beginTask(JGitText.get().renamesBreakingModifies, entries.size()); for (int i = 0; i < entries.size(); i++) { DiffEntry e = entries.get(i); if (e.getChangeType() == ChangeType.MODIFY) { final int score = calculateModifyScore(e); if (score < breakScore) { List<DiffEntry> tmp = DiffEntry.breakModify(e); DiffEntry del = tmp.get(0); del.score = score; deleted.add(del); added.add(tmp.get(1)); } else { newEntries.add(e); } } pm.update(1); } entries = newEntries; }	Non-modify entries should be added back onto newEntries.
public void sendJsonMessage(String json) throws OperationFailedException { try { assertConnected(); org.jivesoftware.smack.packet.Message msg = new org.jivesoftware.smack.packet.Message(); msg.setType(org.jivesoftware.smack.packet.Message.Type.groupchat); msg.addExtension(new JsonMessageExtension(json)); MessageEventManager. addNotificationsRequests(msg, true, false, false, true); multiUserChat.sendMessage(msg); } catch (NotConnectedException | InterruptedException ex){ throw new OperationFailedException( "Failed to send JSON message " + json , OperationFailedException.GENERAL_ERROR , ex); } }	brackets don't match coding style
public static void placeSteamOven(World world, BlockPos pos, List<ItemStack> input, List<ItemStack> output) { MultiBlockPattern pattern = TileSteamOven.patterns.get(0); Map<Character, IBlockState> blockMapping = new HashMap<Character, IBlockState>(); IBlockState base = RailcraftBlocks.getBlockMachineAlpha().getDefaultState(); IBlockState steamOven = base.withProperty(MachineProxyAlpha.VARIANT, EnumMachineAlpha.STEAM_OVEN); blockMapping.put('B', steamOven); TileEntity tile = pattern.placeStructure(world, pos, blockMapping); if (tile instanceof TileSteamOven) { TileSteamOven master = (TileSteamOven) tile; for (int slot = 0; slot < 9; slot++) { if (input != null && slot < input.size()) master.inv.setInventorySlotContents(TileSteamOven.SLOT_INPUT + slot, input.get(slot)); if (output != null && slot < output.size()) master.inv.setInventorySlotContents(TileSteamOven.SLOT_OUTPUT + slot, output.get(slot)); } } }	EnumMachineAlpha.STEAM_OVEN.getState()?
public boolean equals(Object obj) { if (this == obj) { return true; } if (obj == null) { return false; } if (obj instanceof ErrorPage) { ErrorPage other = (ErrorPage) obj; boolean rtn = true; rtn = ObjectUtils.nullSafeEquals(getExceptionName(), other.getExceptionName()); rtn = rtn && ObjectUtils.nullSafeEquals(this.path, other.path); rtn = rtn && this.status == other.status; return rtn; } return false; }	Thanks for the suggestion. Rather than assigning rtn on 117 and then again on line 118, the two could be combined:  boolean rtn = ObjectUtils.nullSafeEquals(getExceptionName(), other.getExceptionName());
protected boolean shouldNotFilter(HttpServletRequest request) { final HttpSession session = request.getSession(false); if (session != null && !session.isNew()) { log.debug("User {} has a session: {}", request.getRemoteUser(), session.getId()); log.debug("Max inactive interval: {}", session.getMaxInactiveInterval()); final Instant ctime = Instant.ofEpochMilli(session.getCreationTime()); final Instant atime = Instant.ofEpochMilli(session.getLastAccessedTime()); log.debug("Session creation time: {}, last access time: {}", ctime, atime); return true; } else { log.debug("User {} does not have a session", request.getRemoteUser()); } return REST_API_SERVLET_PATH.equalsIgnoreCase(request.getServletPath()); }	Consider wrapping lines 47 - 49 in a log.isDebugEnabled() conditional.
private VolumeType getType() { if (!getStorageDomain().getStorageType().isOpenStackDomain() && getParameters().getVolumeFormat() == VolumeFormat.RAW) { return VolumeType.Preallocated; } return VolumeType.Sparse; }	This is very fragile, and will break when we add new storage type. Better check for the storage types (block or file?). Also, this change is possible only when creating volumes with vdsm supporting deferred preallocation, or it may cause very bad performance regression when creating big raw images. This is probably not the place to do these checks, we probably need to modify the code creating new volumes, or the code creating and copying volumes.
private void addVersionAndBranchTags(String remotePath, CVSTag[] tags) { TagCacheEntry entry = getTagCacheEntryFor(remotePath, true); entry.accessed(); for (int i = 0; i < tags.length; i++) { if (tags[i].getType() != CVSTag.DATE) { if (!getAllKnownTagsForParents(entry).contains(tags[i])) { removeTagFromChildrenCacheEntries(entry, tags[i], false); entry.tags.add(tags[i]); } } } }	It's not safe, because if this was the last tag for this entry, this entry will be removed, but I understand you don't like the boolean in the signature of the method. I changed the method that it always removes tags only from children and where it's necessary I added removing the tag from current entry. Should be more clear now.
public QueryResponse getSpecies() throws IOException { Properties properties = new Properties(); properties.load(DBAdaptorConnector.class.getResourceAsStream("/eva.properties")); return setQueryResponse(archiveEvaproDbAdaptor.getSpecies(properties.getProperty("eva.version"), true)); }	Is there a need to read the prop file for every request?
void messageConsumptionCycle() { while (!killed) { long incrementedClock = 0; UpdateMessage message = null; if (!internalMessageQueue.isEmpty()) message = internalMessageQueue.removeFirst(); else synchronized (externalMessageLock) { if (!externalMessageQueue.isEmpty()) { message = takeExternalMessage(); } else { incrementedClock = ++clock; } } if (message == null) { localUpdateTermination(incrementedClock); while (message == null) { synchronized (externalMessageLock) { while (externalMessageQueue.isEmpty()) { try { externalMessageLock.wait(); } catch (InterruptedException e) { if (killed) return; } } message = takeExternalMessage(); } } } message.receiver.update(message.direction, message.updateElement, null); } }	Marking this as a high-priority functional correctness issue.
public boolean equals(Object o) { if (this == o) { return true; } if (o == null || o.getClass() != getClass()) { return false; } PeriodBroadcastDistributionRule that = (PeriodBroadcastDistributionRule) o; if (!Objects.equals(period, that.period)) { return false; } if (!Objects.equals(includeFuture, that.includeFuture)) { return false; } return Objects.equals(colocatedDataSources, that.colocatedDataSources); }	includeFuture can't be null. if (includeFuture != that.includeFuture)?
protected HttpClient createHttpClient() throws Error { int port = getPort(); Lookup<AuthSchemeProvider> authSchemeProvider = null; CredentialsProvider credsProvider = new BasicCredentialsProvider(); AuthScope authScope = new AuthScope(getHost(), port, AuthScope.ANY_REALM, AuthScope.ANY_SCHEME); if (user != null && user.length() > 0) { credsProvider.setCredentials( authScope, new UsernamePasswordCredentials(user, password) ); } else if (kerberos) { authSchemeProvider = RegistryBuilder.<AuthSchemeProvider>create() .register(AuthSchemes.SPNEGO, new SPNegoSchemeFactory(true)) .build(); credsProvider.setCredentials( authScope, new Credentials() { @Override public Principal getUserPrincipal() { return null; } @Override public String getPassword() { return null; } } ); } RequestConfig globalConfig = RequestConfig.custom() .setCookieSpec(CookieSpecs.IGNORE_COOKIES) .setConnectTimeout(timeout) .build(); HttpClientBuilder clientBuilder = HttpClientBuilder.create() .setConnectionManager(new BasicHttpClientConnectionManager(createConnectionSocketFactoryRegistry())) .setDefaultRequestConfig(globalConfig) .setDefaultCredentialsProvider(credsProvider) .setDefaultAuthSchemeRegistry(authSchemeProvider); if (!compress) { clientBuilder.disableContentCompression(); } return new HttpClient45(clientBuilder.build()); }	Why is this needed?
public void bindPubSubProducer(String name, MessageChannel moduleOutputChannel, Properties properties) { validateProducerProperties(name, properties, SUPPORTED_PUBSUB_PRODUCER_PROPERTIES); RabbitPropertiesAccessor accessor = new RabbitPropertiesAccessor(properties); String exchangeName = applyPrefix(accessor.getPrefix(this.defaultPrefix), name); declareExchangeIfNotPresent(new FanoutExchange(exchangeName)); AmqpOutboundEndpoint endpoint = new AmqpOutboundEndpoint(determineRabbitTemplate(accessor)); endpoint.setExchangeName(exchangeName); endpoint.setRoutingKey(name); configureOutboundHandler(endpoint, accessor); doRegisterProducer(name, moduleOutputChannel, endpoint, accessor); }	Wouldn't you want this to be a TopicExchange as well, instead of a FanoutExchange?
private List<KeyRange> getRegionRowKeyRanges() throws SQLException { List<HRegionLocation> regionLocations = getRegionBoundaries(scanGrouper); List<KeyRange> regionKeyRanges = Lists.newArrayListWithExpectedSize(regionLocations.size()); for(HRegionLocation regionLocation : regionLocations){ HRegionInfo regionInfo = regionLocation.getRegionInfo(); KeyRange range = KeyRange.getKeyRange(regionInfo.getStartKey(), true, regionInfo.getEndKey(), false); regionKeyRanges.add(range); } return regionKeyRanges; }	Could you change "for(" to "for ("? Other places too.
public void handleDelete(ActionParameters params) throws ActionException { final User user = params.getUser(); final long id = ConversionHelper.getLong(params.getRequiredParam(PARAM_ID), -1); if (!service.canModifyCategory(user, id)) { throw new ActionDeniedException("Tried to delete category: " + id); } try { layerService.delete(new long [] {id}); } catch (ServiceException e) { LOG.warn(e); throw new ActionException("Failed to delete layers"); } AuditLog.user(params.getClientIp(), params.getUser()) .withParam("id", id) .deleted(AuditLog.ResourceType.MYPLACES_LAYER); JSONObject response = new JSONObject(); JSONHelper.putValue(response, KEY_SUCCESS, true); ResponseHelper.writeResponse(params, response); }	Prefer ActionParameters.getRequiredParamLong(PARAM_ID) instead. If the id is not a long we don't want to fail with ActionDeniedException but with a ActionParamsExcepton instead.
private Set<LoadBalancer> createLoadBalancers(StackV4Request source, Stack stack) { Set<LoadBalancer> loadBalancers = new HashSet<>(); Set<TargetGroup> targetGroups = new HashSet<>(); if (StackType.DATALAKE.equals(source.getType())) { LOGGER.info("Setting up load balancers for stack {}", source.getName()); Set<String> knoxGatewayGroupNames = loadBalancerConfigService.getKnoxGatewayGroups(stack); Set<InstanceGroup> knoxGatewayGroups = stack.getInstanceGroups().stream() .filter(ig -> knoxGatewayGroupNames.contains(ig.getGroupName())) .collect(Collectors.toSet()); if (!knoxGatewayGroups.isEmpty()) { LOGGER.info("Knox gateway instance found; enabling Knox load balancer configuration."); TargetGroup targetGroup = new TargetGroup(); targetGroup.setType(TargetGroupType.KNOX.name()); targetGroup.setInstanceGroups(knoxGatewayGroups); targetGroups.add(targetGroup); knoxGatewayGroups.forEach(ig -> ig.addTargetGroup(targetGroup)); } } if (!targetGroups.isEmpty()) { LoadBalancer loadBalancer = new LoadBalancer(); loadBalancer.setStack(stack); loadBalancer.setType(LoadBalancerType.PRIVATE.name()); loadBalancer.setTargetGroups(targetGroups); targetGroups.forEach(tg -> tg.setLoadBalancer(loadBalancer)); loadBalancers.add(loadBalancer); } return loadBalancers; }	Should this be in an entitlement?
public static void sendGeoIntent(@NonNull Activity activity, @NonNull Location location, String placeName) { String geoStr = "geo:0,0?q=" + location.getLatitude() + "," + location.getLongitude(); if (!TextUtils.isEmpty(placeName)) { geoStr += "(" + placeName +")"; } try { activity.startActivity(new Intent(Intent.ACTION_VIEW, Uri.parse(geoStr))); } catch (ActivityNotFoundException e) { FeedbackUtil.showMessage(activity, R.string.error_no_maps_app); } }	If we end up going with this solution, please call Uri.encode on this appended label string (as directed in <LINK_0> Also, please add a space after the second '+' to resolve the checkstyle failure in CI.
protected void delete(Context context, Integer id) throws AuthorizeException { try { MetadataSchema metadataSchema = metadataSchemaService.find(context, id); if (metadataSchema == null) { throw new ResourceNotFoundException("metadata schema with id: " + id + " not found"); } metadataSchemaService.delete(context, metadataSchema); } catch (SQLException e) { throw new RuntimeException(e.getMessage(), e); } }	Again, getMessage() should be replaced with a more informative error
public ScoredCandidates<T> generate( T content, ResultDescription desc, EquivToTelescopeResults equivToTelescopeResults ) { DefaultScoredCandidates.Builder<T> candidates = DefaultScoredCandidates.fromSource("Alias"); desc.startStage("Resolving aliases:"); EquivToTelescopeComponent generatorComponent = EquivToTelescopeComponent.create(); generatorComponent.setComponentName("Alias Equivalence Generator"); for (Alias alias : content.getAliases()) { desc.appendText(alias.toString()); } desc.finishStage(); Set<T> resolvedContentForAliases = content.getAliases().parallelStream() .filter(alias -> namespaceToMatch == null || alias.getNamespace().equals(namespaceToMatch)) .map(this::getLookupEntries) .flatMap(MoreStreams::stream) .map(this::getResolvedContent) .map(ResolvedContent::getAllResolvedResults) .flatMap(MoreStreams::stream) .filter(cls::isInstance) .map(cls::cast) .collect(MoreCollectors.toImmutableSet()); for (T identified : resolvedContentForAliases) { if (java.util.Objects.equals(content.getId(), identified.getId())) { continue; } if (identified.isActivelyPublished()) { candidates.addEquivalent(identified, Score.nullScore()); desc.appendText("Resolved %s", identified.getCanonicalUri()); } } equivToTelescopeResults.addGeneratorResult(generatorComponent); return candidates.build(); }	Shouldn't the description be a bit more specific, e.g. which alias matched, and the stage finished at the end of the process?
private void updateQcowCompat() { if (getImage().getVolumeFormat().equals(VolumeFormat.COW)) { getImage().setQcowCompat(QcowCompat.QCOW2_V2); if (FeatureSupported.qcowCompatSupported(getStoragePool().getCompatibilityVersion())) { QemuImageInfo qemuImageInfo = ImagesHandler.getQemuImageInfoFromVdsm(getStoragePool().getId(), getStorageDomainId(), getImage().getImage().getDiskId(), getImage().getImageId(), false); if (qemuImageInfo != null) { getImage().setQcowCompat(qemuImageInfo.getQcowCompat()); } imageDao.update(getImage().getImage()); } } }	consider extracting to a method as this code is similar to BaseImagesCommand. have a nice day :)
public void testNotEnoughForMultipleDiskAndDomainsFirstDomainFails() { ArrayList<DiskImage> imagesDisks = mockMultipleSourceImagesForDomain(4, STORAGE_DOMAIN_ID, 4); imagesDisks.addAll(mockMultipleSourceImagesForDomain(4, STORAGE_DOMAIN_ID2, 4)); doReturn(imagesDisks).when(cmd).getSourceImages(); mockStorageDomainDAOGetForStoragePool(15, STORAGE_DOMAIN_ID); mockStorageDomainDAOGetForStoragePool(22, STORAGE_DOMAIN_ID2); assertFalse("Validation should fail. First domain should not have enough free space for request.", cmd.isEnoughSpaceToMergeSnapshots()); }	can't this be defined as a List<DiskImage> ?
private boolean executeOnce(final int thisTryNumber, final int totalTriesIntended) { final Connection sshConnection = new Connection(parent.host, parent.port); try { sshConnection.connect(null, sshTimeoutMillis, 0, sshTimeoutMillis); LOGGER.info("SSH port is open on {}:{}", parent.host, parent.port); return true; } catch (IOException e) { LOGGER.error("Failed to connect to {}:{} (try {}/{}) - {}", parent.host, parent.port, thisTryNumber, totalTriesIntended, e.getMessage()); return false; } finally { sshConnection.close(); } }	While I agree that passing a non-zero value as the connectTimeout argument is a good idea, I don't believe that passing 0 as the readTimeout argument is a good idea. I think that passing zero anywhere will _either_ result in "no timeout" or "a timeout of zero" and both outcomes are bad (one results in non-robust code, the other results in the situation you reported & are trying to fix).
private OnHeapValueHolder<V> invalidateInGetorComputeIfAbsent(MapWrapper<K, V> map, final K key, final ValueHolder<V> value, final Fault<V> fault, final long now) { final AtomicReference<OnHeapValueHolder<V>> toInvalidate = new AtomicReference<OnHeapValueHolder<V>>(); map.computeIfPresent(key, new BiFunction<K, OnHeapValueHolder<V>, OnHeapValueHolder<V>>() { @Override public OnHeapValueHolder<V> apply(K mappedKey, final OnHeapValueHolder<V> mappedValue) { if(mappedValue.equals(fault)) { try { toInvalidate.set(cloneValueHolder(key, value, now, Duration.ZERO, true)); } catch (LimitExceededException ex) { throw new AssertionError("Should have already been thrown."); } invalidationListener.onInvalidation(key, toInvalidate.get()); return null; } return mappedValue; } }); return toInvalidate.get(); }	That message is confusing. Just say that it should not be thrown here as sizing is not happening.
public String toResponse() { if (selectionSet instanceof String) { return String.format( "\"%s\":%s", getName(), getSelectionSet().toString().equals("") ? "{\"edges\":[]}" : getSelectionSet().toString() ); } else if (selectionSet instanceof Number) { return String.format( "\"%s\":%s", getName(), getSelectionSet().toString().equals("") ? "{\"edges\":[]}" : getSelectionSet().toString() ); } else { return String.format("\"%s\":%s", getName(), ((SelectionSet) getSelectionSet()).toResponse()); } }	Can we combine this case with the one above? if (selectionSet instanceof String || selectionSet instanceOf Number)
public <A extends Annotation> ConstraintValidator<A, ?> getInitializedValidator(Type validatedValueType, ConstraintDescriptorImpl<A> descriptor, ConstraintValidatorFactory constraintFactory) { Contracts.assertNotNull( validatedValueType ); Contracts.assertNotNull( descriptor ); Contracts.assertNotNull( constraintFactory ); final CacheKey key = new CacheKey( descriptor.getAnnotation(), validatedValueType, constraintFactory ); if ( constraintValidatorCache.containsKey( key ) ) { @SuppressWarnings("unchecked") ConstraintValidator<A, ?> constraintValidator = (ConstraintValidator<A, ?>) constraintValidatorCache.get( key ); if ( DUMMY_CONSTRAINT_VALIDATOR.equals( constraintValidator ) ) { return null; } else { log.tracef( "Constraint validator %s found in cache.", constraintValidator ); return constraintValidator; } } ConstraintValidatorDescriptor<A> validatorTypeDescriptor = findMatchingValidatorClass( descriptor, validatedValueType ); ConstraintValidator<A, ?> constraintValidator = createAndInitializeValidator( constraintFactory, validatorTypeDescriptor, descriptor ); if ( constraintValidator == null ) { putInitializedValidator( validatedValueType, descriptor.getAnnotation(), constraintFactory, DUMMY_CONSTRAINT_VALIDATOR ); return null; } else { putInitializedValidator( validatedValueType, descriptor.getAnnotation(), constraintFactory, constraintValidator ); return constraintValidator; } }	validatorDescriptor would be nice to be consistent with the naming a few lines below.
private static JAXBContext initOnmsEventParameterContext() { try { return JAXBContext.newInstance(EventParms.class); } catch (JAXBException e) { e.printStackTrace(); } return null; }	Lets re-throw this as a RuntimeException instead.
public RemoteCounterManagerTest() { testImpl = new CounterManagerImplTest(this::allTestCounterManagers, this::log, this::cacheManager); }	fyi, you can use @Factory method to replace the actually tested instance (its methods have to be annotated with @Test ofc)
private void tallyAlignmentRecords(final SAMRecord s1, final SAMRecord s2) { if (!s1.getReadName().equals(s2.getReadName())) { throw new PicardException("Read names do not match: " + s1.getReadName() + " : " + s2.getReadName()); } catalogDuplicateDifferences(s1, s2); final AlignmentComparison comp = compareAlignmentRecords(s1, s2); switch (comp) { case UNMAPPED_BOTH: ++comparisonMetric.unmappedBoth; break; case UNMAPPED_LEFT: ++comparisonMetric.unmappedLeft; break; case UNMAPPED_RIGHT: ++comparisonMetric.unmappedRight; break; case MAPPINGS_DIFFER: ++comparisonMetric.mappingsDiffer; break; case MAPPINGS_MATCH: ++comparisonMetric.mappingsMatch; break; default: throw new PicardException("Unhandled comparison type: " + comp); } }	It would be nice to move this switch into SamComparisonMetric. Or, move it into AlignmentComparison so the switch is no longer necessary, e.g. AlignmentComparison.updateMetric(SamComparisonMetric), where updateMetric() is overridden per enum member to increment the correct field.
private Message.Builder getMessageBuilder(Class<?> clazz) { try { assert supports(clazz); Method method = methodCache.get(clazz); if (method == null) { method = clazz.getMethod("newBuilder"); methodCache.put(clazz, method); } return (Message.Builder) method.invoke(clazz); } catch (Exception ex) { throw new MessageConversionException( "Invalid Protobuf Message type: no invocable newBuilder() method on " + clazz, ex); } }	Please check [our guidelines](<LINK_0> on source code style.
static String base64(byte[] data) { byte[] encodedData = Base64.getEncoder().encode(data); return new String(encodedData, StandardCharsets.UTF_8); }	@doom369 just wondering if we should call encodeToString  directly. WDYT ?
public void onAdd(SolApplication solApplication) { IniReader reader = new IniReader(Const.SAVE_FILE_NAME, null); String saveMajorVersion = reader.getString("version", "").split("\\.")[0]; String gameMajorVersion = Const.VERSION.split("\\.")[0]; continueControl.setEnabled(SaveManager.hasPrevShip("prevShip.ini") && saveMajorVersion.equals(gameMajorVersion)); }	"prevShip.ini" shouldn't be used here, now that you have the constant defined. In fact, I don't think the file should be passed to the save manager, as that's more of a save manager concern. I would consider moving all of this logic into the hasPrevShip function.
public boolean execute(int retries, MapOperation mapOperation, ILogger logger) { RecordStore recordStore = mapOperation.recordStore; if (recordStore == null) { return false; } if (recordStore.getInMemoryFormat() != NATIVE || recordStore.getEvictionPolicy() == NONE) { return false; } MapContainer mapContainer = recordStore.getMapContainer(); Evictor evictor = mapContainer.getEvictor(); for (int i = 0; i < retries; i++) { if (logger.isFineEnabled()) { logger.fine(format( "Applying forced eviction on current RecordStore (map %s, partitionId: %d)!", mapOperation.getName(), mapOperation.getPartitionId() )); } try { evictor.forceEvict(recordStore); mapOperation.runInternal(); return true; } catch (NativeOutOfMemoryError e) { ignore(e); } } return false; }	Minor: you can extract this null check and the in-memory format/eviction policy check into a static method and invoke it from here and other implementations of ForcedEviction
public void onFailure(Throwable caught) { if (hasResponse()) { GWT.log("HTTP " + getResponse().getStatusCode() + ": " + getResponse().getStatusText()); } Message message = new Message(translateCauses(caught), MessageStyle.ERROR); DisplayMessageEvent.fire(hasHandlers, message); }	you should remove this log.
public void stop() { coapServer.stop(); if (clientRegistry instanceof Stoppable) { ((Stoppable) clientRegistry).stop(); } if (securityRegistry instanceof Stoppable) { ((Stoppable) securityRegistry).stop(); } if (observationRegistry instanceof Stoppable) { ((Stoppable) observationRegistry).stop(); } LOG.info("LW-M2M server stopped"); }	we should stop the queueRequestSender ?
public void setLogFilePermission(String fileName) throws IOException { File file = new File(logRootDir, fileName).getCanonicalFile(); boolean runAsUser = ObjectReader.getBoolean(stormConf.get(SUPERVISOR_RUN_WORKER_AS_USER), false); File parent = new File(logRootDir, fileName).getParentFile(); Optional<File> mdFile = (parent == null) ? Optional.empty() : getMetadataFileForWorkerLogDir(parent); Optional<String> topoOwner = mdFile.isPresent() ? Optional.of(getTopologyOwnerFromMetadataFile(mdFile.get().getCanonicalPath())) : Optional.empty(); if (runAsUser && topoOwner.isPresent() && file.exists() && !Files.isReadable(file.toPath())) { LOG.debug("Setting permissions on file {} with topo-owner {}", fileName, topoOwner); try { ClientSupervisorUtils.processLauncherAndWait(stormConf, topoOwner.get(), Lists.newArrayList("blob", file.getCanonicalPath()), null, "setup group read permissions for file: " + fileName); } catch (IOException e) { ExceptionMeters.NUM_PERMISSION_EXCEPTIONS.mark(); throw e; } } }	The exception name is not clear
private void estimateCommandsMachineName( Devfile devfile, Tool tool, KubernetesList recipeObjects) { List<Command> toolsCommands = devfile .getCommands() .stream() .filter(c -> c.getActions().get(0).getTool().equals(tool.getName())) .collect(toList()); if (toolsCommands.isEmpty()) { return; } List<Pod> pods = recipeObjects .getItems() .stream() .filter(hasMetadata -> hasMetadata instanceof Pod) .map(hasMetadata -> (Pod) hasMetadata) .collect(toList()); if (pods.size() != 1) { return; } Pod pod = pods.get(0); List<Container> containers = pod.getSpec().getContainers(); if (containers.size() != 1) { return; } Container container = containers.get(0); String machineName = Names.machineName(pod, container); toolsCommands.forEach(c -> c.getAttributes().put(MACHINE_NAME_ATTRIBUTE, machineName)); }	Could you describe why, not what?
private String encrypt(String value) { try { return getStorageHelper().encrypt(mContext, value); } catch (GeneralSecurityException | IOException e) { Logger.e(TAG, "Encryption failure", "", ADALError.ENCRYPTION_FAILED, e); } return null; }	nit: space
public String getBackupIdentifier() { return Const.SystemParams.ACCOUNT_ATTRIBUTES_BACKUP_LOG_MSG + this.googleId; }	Beside AccountAttributes.java, there are more *Atrributes.java need to be changed.
protected static WebDriver getCurrentBrowser() { return b.getCurrentWebDriver(); }	Are you sure that "protected static" is ok? To me it doesn't make sense as you can't override static methods.
public void onlineUseCase() { Assume.assumeTrue(mCameraId != null); mCamera.open(); mCamera.addOnlineUseCase(Collections.<UseCase>singletonList(mFakeUseCase)); verify(mMockOnImageAvailableListener, never()).onImageAvailable(any(ImageReader.class)); mCamera.release(); }	Rather than put this in every test, you can just put it once in the setup() method.
protected String buildPOFipsCountryCode(PaymentWorksVendor pmwVendor, Map<String, List<PaymentWorksIsoFipsCountryItem>> paymentWorksIsoToFipsCountryMap) { String fipsCountryCode = StringUtils.EMPTY; if (paymentWorksFormModeService.shouldUseLegacyFormProcessingMode()) { String paymentWorksVendorCountryCode = findPoCountryToUse(pmwVendor); fipsCountryCode = convertFipsPoCountryOptionToFipsCountryCode(paymentWorksVendorCountryCode); if (StringUtils.isBlank(fipsCountryCode)) { LOG.error("buildPOFipsCountryCode, unable to find LEGACY FIPS country code for " + paymentWorksVendorCountryCode); } } else if (paymentWorksFormModeService.shouldUseForeignFormProcessingMode()) { PaymentWorksPurchaseOrderCountryFipsOption option = PaymentWorksPurchaseOrderCountryFipsOption.findPaymentWorksPurchaseOrderCountryFipsOption(pmwVendor.getPoCountryUsCanadaAustraliaOther()); if (LOG.isDebugEnabled()) { LOG.debug("buildPOFipsCountryCode, new foreign form FIPS country code option: " + option.toString()); } if (StringUtils.isNotBlank(option.fipsCountryCode)) { fipsCountryCode = option.fipsCountryCode; } else { try { fipsCountryCode = convertIsoCountryCodeToFipsCountryCode(pmwVendor.getPoCountry(), paymentWorksIsoToFipsCountryMap); } catch (NullPointerException npe) { LOG.error("buildPOFipsCountryCode, had and error converting '" + pmwVendor.getPoCountry() + "' to a FIPS code.", npe); fipsCountryCode = StringUtils.EMPTY; } } if (StringUtils.isBlank(fipsCountryCode)) { LOG.error("buildPOFipsCountryCode, unable to find new foreign form FIPS country code for country code " + pmwVendor.getPoCountry()); } } return fipsCountryCode; }	Minor typo in error message, should change from "...had and error..." to "...had an error..."
public Boolean isWakeupEvent(ITmfEvent event) { String eventName = event.getName(); ITmfTrace trace = event.getTrace(); LttngEventLayout eventLayout = getProvider().getEventLayout(); String wakeupEventName = NonNullUtils.nullToEmptyString(fWakeupEventMap.get(trace)); if (wakeupEventName.equals(eventLayout.eventSchedProcessWaking()) && (eventName.equals(eventLayout.eventSchedProcessWaking()) || eventName.equals(eventLayout.eventSchedProcessWakeupNew()))) { return NonNullUtils.checkNotNull(Boolean.TRUE); } else if (wakeupEventName.equals(eventLayout.eventSchedProcessTTWU()) && eventName.equals(eventLayout.eventSchedProcessTTWU())) { return NonNullUtils.checkNotNull(Boolean.TRUE); } return NonNullUtils.checkNotNull(Boolean.FALSE); }	why not boolean? (lowercase?)
private void triggerDeveloperBan(final CertifiedProductSearchDetails updatedListing) { Scheduler scheduler; try { scheduler = getScheduler(); TriggerKey triggerId = triggerKey("triggerBanNow_" + new Date().getTime(), "triggerDeveloperBanTrigger"); JobKey jobId = jobKey("Trigger Developer Ban Notification", "chplJobs"); Trigger qzTrigger = newTrigger() .withIdentity(triggerId) .startNow() .forJob(jobId) .usingJobData("status", updatedListing.getCurrentStatus().getStatus().getName()) .usingJobData("dbId", updatedListing.getId()) .usingJobData("chplId", updatedListing.getChplProductNumber()) .usingJobData("developer", updatedListing.getDeveloper().getName()) .usingJobData("acb", updatedListing.getCertifyingBody().get("name").toString()) .usingJobData("changeDate", new Date().getTime()) .usingJobData("firstName", Util.getCurrentUser().getFullName()) .usingJobData("lastName", Util.getCurrentUser().getFriendlyName()) .usingJobData("effectiveDate", updatedListing.getCurrentStatus().getEventDate()) .usingJobData("openNcs", updatedListing.getCountOpenNonconformities()) .usingJobData("closedNcs", updatedListing.getCountClosedNonconformities()) .build(); scheduler.scheduleJob(qzTrigger); } catch (SchedulerException e) { LOGGER.error("Could not start Trigger Developer Ban", e); } }	Does it matter that "firstName" and "lastName" are still the keys here? Probably should be full and friendly anyway?
protected boolean updateSelection(IStructuredSelection selection) { if (!super.updateSelection(selection)) { return false; } final IResource[][] clipboardData = new IResource[1][]; shell.getDisplay().syncExec(new Runnable() { @Override public void run() { ResourceTransfer resTransfer = ResourceTransfer.getInstance(); clipboardData[0] = (IResource[]) clipboard.getContents(resTransfer); } }); IResource[] resourceData = clipboardData[0]; boolean isProjectRes = resourceData != null && resourceData.length > 0 && resourceData[0].getType() == IResource.PROJECT; if (isProjectRes) { for (IResource element : resourceData) { if (element.getType() != IResource.PROJECT || ((IProject) element).isOpen() == false) { return false; } } return true; } if (getSelectedNonResources().size() > 0) { return false; } IResource targetResource = getTarget(); if (targetResource == null) { return false; } List<? extends IResource> selectedResources = getSelectedResources(); if (selectedResources.size() > 1) { for (IResource resource : selectedResources) { if (resource.getType() != IResource.FILE) { return false; } if (!targetResource.equals(resource.getParent())) { return false; } } } if (resourceData != null) { if (isLinked(resourceData) && targetResource.getType() != IResource.PROJECT && targetResource.getType() != IResource.FOLDER) { return false; } if (targetResource.getType() == IResource.FOLDER) { for (IResource element : resourceData) { if (targetResource.equals(element)) { return false; } } } return true; } TransferData[] transfers = clipboard.getAvailableTypes(); FileTransfer fileTransfer = FileTransfer.getInstance(); for (TransferData transfer : transfers) { if (fileTransfer.isSupportedType(transfer)) { return true; } } return false; }	rename 'resource'
public void destroyTelephonyConference() { for (Connection c : getConnections()) { notifyConferenceMembershipChanged(c); } destroy(); }	It doesn;t look like the membership of these connections have been changed yet.. Should removeTelephonyConnection be called for all of the connections first?
private long getWatermarkMs(String realtimeTableName, List<LLCRealtimeSegmentZKMetadata> completedSegmentsMetadata, long bucketMs) { RealtimeToOfflineSegmentsTaskMetadata realtimeToOfflineSegmentsTaskMetadata = _clusterInfoAccessor.getMinionRealtimeToOfflineSegmentsTaskMetadata(realtimeTableName); if (realtimeToOfflineSegmentsTaskMetadata == null) { long watermarkMs; long minStartTimeMs = Long.MAX_VALUE; for (LLCRealtimeSegmentZKMetadata realtimeSegmentZKMetadata : completedSegmentsMetadata) { minStartTimeMs = Math.min(minStartTimeMs, realtimeSegmentZKMetadata.getStartTimeMs()); } watermarkMs = (minStartTimeMs / bucketMs) * bucketMs; realtimeToOfflineSegmentsTaskMetadata = new RealtimeToOfflineSegmentsTaskMetadata(realtimeTableName, watermarkMs); _clusterInfoAccessor.setRealtimeToOfflineSegmentsTaskMetadata(realtimeToOfflineSegmentsTaskMetadata); } return realtimeToOfflineSegmentsTaskMetadata.getWatermarkMs(); }	Do we want to add  Preconditions.checkState(minStartTimeMs != Long.MAX_VALUE);  to throw the exception at the same condition?
private static void printTumorTypeSummary(Set<Evidence> evidences, SpreadsheetService service, WorksheetEntry entry) throws IOException, ServiceException { URL feedUrl = entry.getListFeedUrl(); if (evidences != null && service != null && entry != null) { for (Evidence evidence : evidences) { ListEntry row = new ListEntry(); setValue(row, "Gene", evidence.getGene().getHugoSymbol()); List<String> alterationNames = new ArrayList<>(); for (Alteration alteration : evidence.getAlterations()) { if (StringUtils.isNullOrEmpty(alteration.getName())) { alterationNames.add(alteration.getAlteration()); } else { alterationNames.add(alteration.getName()); } } setValue(row, "Variants", MainUtils.listToString(alterationNames, ", ")); setValue(row, "CancerType", getCancerType(evidence.getOncoTreeType())); setValue(row, "Summary", evidence.getDescription()); service.insert(feedUrl, row); } } }	Put this snippet of getting alterationNames into a function. Since the same code is used in printEvidences()
public static void createProjects( final Set<ProjectRecord> projectsToCreate, final boolean open, final IWorkingSet[] selectedWorkingSets, IProgressMonitor monitor) throws InvocationTargetException, InterruptedException { IWorkspaceRunnable wsr = new IWorkspaceRunnable() { @Override public void run(IProgressMonitor actMonitor) throws CoreException { IWorkingSetManager workingSetManager = PlatformUI .getWorkbench().getWorkingSetManager(); try { actMonitor.beginTask("", projectsToCreate.size() * 2 + 1); if (actMonitor.isCanceled()) throw new OperationCanceledException(); Map<IProject, File> projectsToConnect = new HashMap<>(); for (ProjectRecord projectRecord : projectsToCreate) { if (actMonitor.isCanceled()) throw new OperationCanceledException(); actMonitor.subTask(projectRecord.getProjectLabel()); IProject project = createExistingProject(projectRecord, open, SubMonitor.convert(actMonitor, 1)); if (project == null) continue; RepositoryFinder finder = new RepositoryFinder(project); finder.setFindInChildren(false); Collection<RepositoryMapping> mappings = finder .find(SubMonitor.convert(actMonitor, 1)); if (!mappings.isEmpty()) { RepositoryMapping mapping = mappings.iterator() .next(); IPath absolutePath = mapping .getGitDirAbsolutePath(); if (absolutePath != null) { projectsToConnect.put(project, absolutePath.toFile()); } } if (selectedWorkingSets != null && selectedWorkingSets.length > 0) workingSetManager.addToWorkingSets(project, selectedWorkingSets); } if (!projectsToConnect.isEmpty()) { ConnectProviderOperation connect = new ConnectProviderOperation( projectsToConnect); connect.execute(SubMonitor.convert(actMonitor, 1)); } } finally { actMonitor.done(); } } }; try { ResourcesPlugin.getWorkspace().run(wsr, monitor); } catch (OperationCanceledException e) { throw new InterruptedException(); } catch (CoreException e) { throw new InvocationTargetException(e); } }	I don't think one should convert the same monitor multiple times. Use SubMonitor progress = SubMonitor.convert(actMonitor, projectsToCreate.size() * 2 + 1); at the top and then use only progress, not actMonitor, and use progress.newChild(1) here and below.
private void runTearDown(Throwable exception) throws DeviceNotAvailableException { List<IMultiTargetPreparer> cleanerList = new ArrayList<>(mMultiPreparers); Collections.reverse(cleanerList); for (IMultiTargetPreparer multiCleaner : cleanerList) { if (multiCleaner.isDisabled() || multiCleaner.isTearDownDisabled()) { continue; } CLog.d("Running teardown Multi cleaner: %s", multiCleaner.getClass().getSimpleName()); multiCleaner.tearDown(mModuleInvocationContext, exception); } for (int i = 0; i < mModuleInvocationContext.getDeviceConfigNames().size(); i++) { String deviceName = mModuleInvocationContext.getDeviceConfigNames().get(i); ITestDevice device = mModuleInvocationContext.getDevice(deviceName); if (i >= mPreparersPerDevice.size()) { CLog.d( "Main configuration has more devices than the module configuration. '%s' " + "will not run any tear down.", deviceName); continue; } List<ITargetPreparer> preparers = mPreparersPerDevice.get(deviceName); if (preparers == null) { CLog.w( "Module configuration devices mismatch the main configuration " + "(Missing device '%s'), resolving preparers by index.", deviceName); String key = new ArrayList<>(mPreparersPerDevice.keySet()).get(i); preparers = mPreparersPerDevice.get(key); } ListIterator<ITargetPreparer> itr = preparers.listIterator(preparers.size()); while (itr.hasPrevious()) { ITargetPreparer preparer = itr.previous(); if (preparer instanceof ITargetCleaner) { ITargetCleaner cleaner = (ITargetCleaner) preparer; if (cleaner.isDisabled() || cleaner.isTearDownDisabled()) { CLog.d("%s has been disabled. skipping.", cleaner); continue; } RecoveryMode origMode = null; try { if (exception != null && exception instanceof DeviceNotAvailableException) { origMode = device.getRecoveryMode(); device.setRecoveryMode(RecoveryMode.NONE); } cleaner.tearDown( device, mModuleInvocationContext.getBuildInfo(deviceName), exception); } finally { if (origMode != null) { device.setRecoveryMode(origMode); } } } } } }	m
public static String md5(String str) { MessageDigest m = null; try { m = MessageDigest.getInstance("MD5"); } catch (NoSuchAlgorithmException e) { e.printStackTrace(); } m.update(str.getBytes(),0,str.length()); return new BigInteger(1,m.digest()).toString(16); }	It it better to throw unchecked exception than simply print error because if error occurs then variable 'm' will be null and NullPointerException will be thrown later (line 16). try { m = MessageDigest.getInstance("MD5"); } catch (NoSuchAlgorithmException e) { e.printStackTrace(); //use logger instead throw new RuntimeException("No Such Algorithm: MD5"); }
public Map<K, V> removeAll(BiPredicate<? super K, ? super V> predicate) { Objects.requireNonNull(predicate, "predicate is null"); return filter(predicate.negate()); }	the return type should be M
static Path getCMPath(Configuration conf, String checkSum) throws IOException, MetaException { String newFileName = checkSum; int maxLength = conf.getInt(DFSConfigKeys.DFS_NAMENODE_MAX_COMPONENT_LENGTH_KEY, DFSConfigKeys.DFS_NAMENODE_MAX_COMPONENT_LENGTH_DEFAULT); if (newFileName.length() > maxLength) { newFileName = newFileName.substring(0, maxLength-1); } return new Path(cmroot, newFileName); }	Looks like getCMPath never throw IOException or MetaException. Shall check and remove it.
public void onApplicationEvent(ApplicationEvent event) { if (event instanceof ApplicationEnvironmentPreparedEvent) { ApplicationEnvironmentPreparedEvent castEvent = (ApplicationEnvironmentPreparedEvent) event; String componentName = castEvent.getEnvironment().getProperty("info.component"); LOG.info("Setting service name to {}", componentName); CommonLogHolder.setServiceType(componentName); } if (event instanceof ApplicationFailedEvent) { LOG.info("Terminating default logging context"); ((LoggerContext) LoggerFactory.getILoggerFactory()).reset(); BasicConfigurator.configureDefaultContext(); } }	Can this be overloaded to avoid the casts?
private String getBundleVersion() { ClassLoader cl = getClass().getClassLoader(); if (cl instanceof URLClassLoader) { URL url = ((URLClassLoader) cl).findResource(JarFile.MANIFEST_NAME); try { Manifest manifest = new Manifest(url.openStream()); return manifest.getMainAttributes().getValue("Bundle-Version"); } catch (IOException e) { } } return null; }	url should be checked for null.
public Response ackAlert( @ApiParam(required = true, value = "The alertId to Ack.", allowableValues = "An existing alertId.") @PathParam("alertId") final String alertId, @ApiParam(required = false, value = "User acknowledging the alerts.") @QueryParam("ackBy") final String ackBy, @ApiParam(required = false, value = "Additional notes associated with the acknowledgement.") @QueryParam("ackNotes") final String ackNotes) { try { if (!isEmpty(alertId)) { alertsService.ackAlerts(tenantId, Arrays.asList(alertId), ackBy, ackNotes); if (log.isDebugEnabled()) { log.debug("AlertId: " + alertId); } return ResponseUtil.ok(); } else { return ResponseUtil.badRequest("AlertId required for ack"); } } catch (Exception e) { log.debug(e.getMessage(), e); if (e.getCause() != null && e.getCause() instanceof IllegalArgumentException) { return ResponseUtil.badRequest("Bad arguments: " + e.getMessage()); } return ResponseUtil.internalError(e); } }	Let's not break/change the format here. I think each annotation should go in a different line for consistency and readability. Perhaps some automatic formatting from the IDE here.
public static String humanReadable(float bytes) { if (bytes > GB) { return String.format("%.03f GB", bytes / GB); } else if (bytes > MB) { return String.format("%.03f MB", bytes / MB); } else if (bytes > KB) { return String.format("%.03f kB", bytes / KB); } else { return String.format("%.02f B", bytes); } }	TB too?
private void reset() { if (chunk != null) { chunkedInput = new HttpChunkedInput(new RepeatedBytesInput()); request = new DefaultHttpRequest(HttpVersion.HTTP_1_1, HttpMethod.POST, path); HttpUtil.setContentLength(request, totalSize); request.headers().add(RestUtils.Headers.BLOB_SIZE, totalSize); request.headers().add(RestUtils.Headers.SERVICE_ID, serviceId); request.headers().add(RestUtils.Headers.AMBRY_CONTENT_TYPE, "application/octet-stream"); if (targetAccountName != null) { request.headers().add(RestUtils.Headers.TARGET_ACCOUNT_NAME, targetAccountName); } if (targetContainerName != null) { request.headers().add(RestUtils.Headers.TARGET_CONTAINER_NAME, targetContainerName); } } else { if (pathList == null) { request = new DefaultFullHttpRequest(HttpVersion.HTTP_1_1, HttpMethod.GET, path); } else { request = new DefaultFullHttpRequest(HttpVersion.HTTP_1_1, HttpMethod.GET, pathList.get(counter.getAndIncrement() % pathList.size())); } } for (Pair<String, String> headerNameValue : customHeaders) { request.headers().add(headerNameValue.getFirst(), headerNameValue.getSecond()); } chunksReceived = 0; sizeReceived = 0; lastChunkReceiveTime = 0; requestStartTime = System.currentTimeMillis(); response = null; }	Do you think it's worthwhile to check !targetAccountName.isEmpty() as well? Same for container's check.
private void load() { List<OnmsNode> nodes = nodeDao.findAll(); this.sparseGraph = new DirectedSparseGraph(); int counter = 0; for (OnmsNode node : nodes) { CustomVertex vertexChild = new CustomVertex(NAMESPACE, node); if (node.getParent() == null) { this.sparseGraph.addVertex(vertexChild); } else { CustomVertex vertexParent = new CustomVertex(NAMESPACE, node.getParent()); vertexChild.setParent(vertexParent); this.sparseGraph.addVertex(vertexChild); this.sparseGraph.addVertex(vertexParent); this.sparseGraph.addEdge(new AbstractEdge(NAMESPACE, String.valueOf(counter), vertexParent, vertexChild), vertexParent, vertexChild, EdgeType.DIRECTED); counter++; } } List<CustomVertex> tempVertices = new ArrayList<>(); for (CustomVertex vertex : this.sparseGraph.getVertices()) { Collection<CustomVertex> predecessors = this.sparseGraph.getPredecessors(vertex); if (predecessors.isEmpty()) { vertex.setLevel(0); tempVertices.add(vertex); tempVertices.addAll(setLevel(this.sparseGraph, vertex, 1)); } } for (CustomVertex customVertex : tempVertices) { this.addVertices(customVertex); } for (AbstractEdge abstractEdge : this.sparseGraph.getEdges()) { this.addEdges(abstractEdge); } }	Please rename to edgeId.
public ResponseDefinition execute(Admin admin, Request request, PathParams pathParams) { BrowserProxySettings browserProxySettings = admin.getOptions().browserProxySettings(); KeyStoreSettings caKeyStore = browserProxySettings.caKeyStore(); try { X509KeyStore x509KeyStore = new X509KeyStore(caKeyStore.loadStore(), caKeyStore.password().toCharArray()); X509Certificate certificate = x509KeyStore.getCertificateAuthority().certificateChain()[0]; return new ResponseDefinitionBuilder() .withStatus(HTTP_OK) .withHeader("Content-Type", "application/x-pem-file") .withBody( "-----BEGIN CERTIFICATE-----\r\n" + BASE64_ENCODER.encodeToString(certificate.getEncoded()) + "\r\n" + "-----END CERTIFICATE-----" ) .build(); } catch (Exception e) { StringWriter stacktrace = new StringWriter(); e.printStackTrace(new PrintWriter(stacktrace)); return new ResponseDefinition( HTTP_INTERNAL_ERROR, "Failed to export certificate authority cert from " + caKeyStore.path() + "\r\n" + stacktrace ); } }	Could we just log the stacktrace, rather than sending it on the response?
public Function<Element, LeaseElement> parser() { return (element -> { NodeList childElements = element.getElementsByTagNameNS(NAMESPACE_STRING, LEASE_LENGTH_ELEMENT_NAME); if (childElements.getLength() != 1) { LOGGER.error("Found " + childElements.getLength() + " lease-length elements. The XSD should have prevented this."); throw new AssertionError("The schema for connection-leasing element requires one and only one lease-length element"); } Element leaseLengthElement = (Element)childElements.item(0); String leaseLengthString = leaseLengthElement.getTextContent(); LOGGER.info("Found lease length XML text: " + leaseLengthString); String timeUnitString = leaseLengthElement.getAttribute(TIME_UNIT_ATTRIBUTE_NAME); LOGGER.info("Found lease length time unit: " + timeUnitString); LeaseElement leaseElement = new LeaseElement(); leaseElement.setLeaseValue(leaseLengthString); leaseElement.setTimeUnit(timeUnitString); return leaseElement; }); }	can't we set these values in the constructor?
XAResourceRegistryFile(Xid xid) throws SystemException { final String xidString = SimpleXid.of(xid).toHexString('_'); this.filePath = xaRecoveryPath.resolve(xidString); try { fileChannel = doPrivileged((PrivilegedExceptionAction<FileChannel>) () -> { final SecurityManager sm = System.getSecurityManager(); if (sm != null) { sm.checkPermission(new FilePermission(xaRecoveryPath.toString() + File.separatorChar + '*', "read,write")); } xaRecoveryPath.toFile().mkdir(); return FileChannel.open(filePath, StandardOpenOption.APPEND, StandardOpenOption.CREATE_NEW); }); openFilePaths.add(xidString); fileChannel.lock(); Log.log.xaResourceRecoveryFileCreated(filePath); } catch (PrivilegedActionException e) { throw Log.log.createXAResourceRecoveryFileFailed(filePath, (IOException)e.getCause()); } catch (IOException e) { throw Log.log.createXAResourceRecoveryFileFailed(filePath, e); } }	@tadamski If you cache this FilePermission in the containing FileSystemXAResourceRecoveryRegistry object you will save a per-transaction objection creation/gc.
public void fromRunnable() { Completable.fromRunnable(new Runnable() { @Override public void run() { } }) .test() .assertResult(); }	I'd increment a counter and assert its 1.
public void messageReceived(ChannelHandlerContext ctx, MessageEvent e) throws Exception { HttpRequest request = (HttpRequest) e.getMessage(); ChannelBuffer content = request.getContent(); if (content.readable()) { sendMessage(MessageBuilder.withPayload(content.toString(Charset.forName("UTF-8"))).build()); } writeResponse(request, e.getChannel()); }	I realize it's a first cut, but I wonder if we should map some basic headers (method, path (uri), Accept) ??
public BaseResourceReferenceDt setResource(IBaseResource theResource) { myResource = theResource; return null; }	null?
@Override public Frame fetch(StatementHandle h, long offset, int fetchMaxRowCount) throws NoSuchStatementException { final CalciteConnectionImpl calciteConnection = getConnection(); CalciteServerStatement stmt = calciteConnection.server.getStatement(h); final Signature signature = stmt.getSignature(); final Iterator<Object> iterator; if (stmt.getResultSet() == null) { final Iterable<Object> iterable = _createIterable(h, signature, null, null); iterator = iterable.iterator(); stmt.setResultSet(iterator); } else { iterator = stmt.getResultSet(); } final List rows = MetaImpl.collect(signature.cursorFactory, LimitIterator.of(iterator, fetchMaxRowCount), new ArrayList<List<Object>>()); boolean done = fetchMaxRowCount == 0 || rows.size() < fetchMaxRowCount; @SuppressWarnings("unchecked") List<Object> rows1 = (List<Object>) rows; stmt.setResultSet(null); return new Meta.Frame(offset, done, rows1); }	This is too aggressive :( The iterator is not released after a call ended because it might not be fully read. If I'm not wrong, setting it to null would cause infinite loop when result row count is large enough.
public String getDeviceName() { String manufacturer = Build.MANUFACTURER; String model = Build.MODEL; String deviceName; if (model.startsWith(manufacturer)) { deviceName = StringUtils.capitalize(model); } else { deviceName = StringUtils.capitalize(manufacturer) + " " + model; } return deviceName == null ? "Unknown Device" : deviceName; }	final
public BsmAdminPageEditWindow editAttribute(String key, String value) throws InterruptedException { getSelectWebElement("attributeList").selectByVisibleText(key); editAttributeWindow() .value(value) .confirm(); wait.until(ExpectedConditions.elementToBeClickable(By.id("addAttributeButton"))); return this; }	This is kinda a duplicate, as we already wait in the confirm() method or is there a particular reason to wait again for another element?
@Test @Config(reportSdk=9) public void useOkHttpByDefault() throws Exception { Downloader downloader = Utils.createDefaultDownloader(Robolectric.application); assertThat(downloader instanceof OkHttpDownloader).isTrue(); }	Maybe change this to assertThat(downloader).isInstanceOf(OkHttpDownloader.class) ?
public void load(@NonNull Picasso picasso, @NonNull Request request, @NonNull Callback callback) { initializeIfFirstTime(); boolean signaledCallback = false; try { BufferedSource source = Okio.buffer(Okio.source(assetManager.open(getFilePath(request)))); try { Bitmap bitmap = decodeStream(source, request); signaledCallback = true; callback.onSuccess(new Result(bitmap, DISK)); } finally { try { source.close(); } catch (IOException ignored) { } } } catch (Exception e) { if (!signaledCallback) { callback.onError(e); } } }	You have a few more of these to update
public void onLiveInstanceChange(List<LiveInstance> liveInstances, NotificationContext changeContext) { try { logger.trace("Live instance change triggered from {} with: {}", dcName, liveInstances); updateInstanceLiveness(liveInstances); if (!liveStateInitialized.get()) { logger.info("Received initial notification for live instance change from {}", dcName); liveStateInitialized.set(true); } helixClusterManagerMetrics.liveInstanceChangeTriggerCount.inc(); } catch (Throwable t) { errorCount.incrementAndGet(); throw t; } }	trace seems too low, how often will this happen?
public EncryptionServiceImpl() { String passwordDirectory = System.getProperty("ddf.etc").concat("/certs"); String keysetLocation = Paths.get(passwordDirectory, KEYSET_FILE_NAME).toString(); synchronized (EncryptionServiceImpl.class) { File keysetFile = new File(keysetLocation); InputStream keysetFileInputStream = null; OutputStream keysetFileOutputStream = null; try { AeadConfig.register(); if (!keysetFile.exists()) { keysetHandle = KeysetHandle.generateNew(AeadKeyTemplates.AES128_GCM); keysetFileOutputStream = Files.newOutputStream(Paths.get(keysetLocation)); CleartextKeysetHandle.write( keysetHandle, JsonKeysetWriter.withOutputStream(keysetFileOutputStream)); } else { keysetFileInputStream = Files.newInputStream(Paths.get(keysetLocation)); keysetHandle = CleartextKeysetHandle.read(JsonKeysetReader.withInputStream(keysetFileInputStream)); } aead = AeadFactory.getPrimitive(keysetHandle); } catch (GeneralSecurityException | IOException e) { LOGGER.warn("Problem initializing Tink. Enable debug logging for more information."); LOGGER.debug("", e); } finally { try { keysetFileInputStream.close(); } catch (IOException | NullPointerException ignore) { } try { keysetFileOutputStream.close(); } catch (IOException | NullPointerException ignore) { } } } }	Do a null check instead of catching the NPE. Can a try with resources be used?
public static String updateOldDescription(String description) { String newDescription = ""; newDescription = updatePrisonerDescription(description); if (!newDescription.isEmpty()) { return newDescription; } newDescription = updateBondsmanDescription(description); if (!newDescription.isEmpty()) { return newDescription; } return ""; }	We can also move this up to the declaration and remove the meaningless initialization.
public void testCacheBehaviour(){ IgniteUtils.setCurrentIgniteName(ignite.configuration().getIgniteInstanceName()); int size = rows; cacheBehaviorLogic(size); }	We dont need size variable here.
private void runOneIteration() { try { LockWatchTestRuntimeConfig config = runtime.get(); if (config.namespaceToWatch().isPresent()) { LockWatchingResource lockWatcher = resource.apply(config.namespaceToWatch().get()); LockWatchRequest request = LockWatchRequest.of(config.tablesToWatch().stream() .map(TableReference::getQualifiedName) .map(LockWatchReferences::entireTable) .collect(Collectors.toSet())); LockWatchStateUpdate versionBefore = lockWatcher.getWatchState( OptionalLong.empty()); long startRegistering = System.currentTimeMillis(); lockWatcher.startWatching(request); log.info("Registered lock watches for keyspace {} and tables {} in {} seconds.", SafeArg.of("keyspace", config.namespaceToWatch().get()), SafeArg.of("tables", config.tablesToWatch()), SafeArg.of("seconds", System.currentTimeMillis() - startRegistering)); long startUpdate = System.currentTimeMillis(); LockWatchStateUpdate versionAfter = lockWatcher.getWatchState(versionBefore.lastKnownVersion()); long duration = System.currentTimeMillis() - startUpdate; if (versionAfter.success()) { Optional<LockWatchEvent> result = versionAfter.events().stream() .map(event -> event.accept(filter)) .filter(Optional::isPresent) .map(Optional::get) .findFirst(); if (!result.isPresent()) { log.info("Registered lock watches, but did not find any open locks. Took {} seconds", SafeArg.of("duration", duration)); } else { log.info("Registered lock watches, found {} open locks. Took {} seconds.", SafeArg.of("numberOfWatches", ((LockWatchOpenLocksEvent) result.get()).lockDescriptors().size()), SafeArg.of("duration", duration)); } } else { log.info("Registered lock watches, but was unable to get an update. Last known version is {}", SafeArg.of("lastKnownVersion", versionAfter.lastKnownVersion())); } } } catch (Throwable th) { log.info("Failed to run a test iteration of registering lock watches", th); } }	nit: The metric is millis, not seconds
void preInit( FMLPreInitializationEvent event ) { if ( !Loader.isModLoaded( "appliedenergistics2-core" ) ) { CommonHelper.proxy.missingCoreMod(); } Stopwatch star = Stopwatch.createStarted(); this.configPath = event.getModConfigurationDirectory().getPath() + File.separator + "AppliedEnergistics2" + File.separator; AEConfig.instance = new AEConfig( this.configPath ); FacadeConfig.instance = new FacadeConfig( this.configPath ); AELog.info( "Starting Pre Initialization" ); CreativeTab.init(); if ( AEConfig.instance.isFeatureEnabled( AEFeature.Facades ) ) CreativeTabFacade.init(); if ( Platform.isClient() ) CommonHelper.proxy.init(); Registration.instance.PreInit( event ); if ( AEConfig.instance.isFeatureEnabled( AEFeature.VersionChecker ) ) { AELog.info( "Starting VersionChecker" ); this.startService( "AE2 VersionChecker", new Thread( new VersionChecker() ) ); } AELog.info( "Pre Initialization ( ended after " + star.elapsed( TimeUnit.MILLISECONDS ) + "ms )" ); }	you removed the ones on top but kept the brackets here?
public static void checkValidPath(String path) throws InvalidPathException { ObjectChecker chk = new ObjectChecker() .setSafeForWindows(SystemReader.getInstance().isWindows()); byte[] bytes = Constants.encode(path); int segmentStart = 0; try { for (int i = 0; i < bytes.length; i++) { if (bytes[i] == '/') { chk.checkPathSegment(bytes, segmentStart, i); segmentStart = i + 1; } } chk.checkPathSegment(bytes, segmentStart, bytes.length); } catch (CorruptObjectException e) { throw new InvalidPathException(e.getMessage()); } }	Likewise.
public static float convertLightCountsToLux(final int rawCount) { final float maxLux = 125.0f; final float maxCount = 65536.0f; final float whiteMultiplier = 2.0f; final float internalIntensity = ((float) rawCount / maxCount) * maxLux; return (whiteMultiplier * internalIntensity); }	this is possibly a breaking change for timelines. Was it tested?
private boolean getNodeMemberships(Element subscriptions) throws NodeStoreException, InterruptedException { ResultSet<NodeMembership> cur = channelManager.getNodeMemberships(node); if (channelManager.isLocalNode(node)) { subscriptions.addAttribute(XMLConstants.NODE_ATTR, node); for (NodeMembership ns : cur) { if (actorJid.toBareJID().equals(ns.getUser().toBareJID())) { Element subscription = subscriptions.addElement(XMLConstants.SUBSCRIPTION_ELEM); subscription.addAttribute(XMLConstants.NODE_ATTR, ns.getNodeId()) .addAttribute(XMLConstants.SUBSCRIPTION_ELEM, ns.getSubscription().toString()) .addAttribute(XMLConstants.JID_ATTR, ns.getUser().toBareJID()); if (null != ns.getInvitedBy() && isOwnerModerator()) { subscription.addAttribute(XMLConstants.INVITED_BY_ELEM, ns.getInvitedBy().toBareJID()); } } } } else { if (!channelManager.isCachedNode(node) || (null != requestIq.getElement().element(XMLConstants.PUBSUB_ELEM).element(XMLConstants.SET_ELEM)) && !cur.isEmpty()) { makeRemoteRequest(new JID(node.split("/")[2]).getDomain()); } return false; } return true; }	This should be a not comparison, original line:  java if (false == actorJid.toBareJID().equals(ns.getUser())) {  Basically we don't want to show a subscription != 'subscribed' to anyone but the owner/admin or the user themselves.
public void testRestart() throws RunScriptOnNodesException { final String groupName = String.format(NAME_PREFIX, System.getProperty("user.name").substring(0, 3)); Set<? extends NodeMetadata> nodes = view.getComputeService().rebootNodesMatching(inGroup(groupName)); assertTrue(nodes.size() > 0); boolean allRestarted = false; while (!allRestarted) { nodes = view.getComputeService().listNodesDetailsMatching(nameStartsWith(groupName)); for (NodeMetadata node : nodes) { if (node.getStatus() != NodeMetadata.Status.RUNNING) { allRestarted = false; try { Thread.sleep(30 * 1000); } catch (InterruptedException e) { } continue; } else { allRestarted = true; } } } assertTrue(allRestarted); view.getComputeService().destroyNodesMatching(inGroup(groupName)); }	All the above tests are already covered by the BaseComputeServiceLiveTest. You should subclass that one and try to make all tests pass without overriding its methods (as that is our compute service implementation contract). Take the [DigitalOcean](<LINK_0> one as an example.
private void registerExternalProvidersTrustStore(DefaultHttpClient httpClient) { try { KeyStore trustStore = KeyStore.getInstance(KeyStore.getDefaultType()); FileInputStream inputStream = new FileInputStream( new File(EngineLocalConfig.getInstance().getExternalProvidersTrustStore().getAbsolutePath())); try { trustStore.load(inputStream, EngineLocalConfig.getInstance().getExternalProvidersTrustStorePassword().toCharArray()); } finally { inputStream.close(); } SSLSocketFactory socketFactory = new SSLSocketFactory(trustStore); Scheme sch = new Scheme("https", 443, socketFactory); httpClient.getConnectionManager().getSchemeRegistry().register(sch); } catch (Exception ex) { log.warn("Cannot register external providers trust store: {}", ex.getMessage()); } }	instead you could use the try-with-resource paradigm
public void onViewCreated(View view, Bundle savedInstanceState) { super.onViewCreated(view, savedInstanceState); TextView filesText = (TextView) view.findViewById(R.id.files_text); view.findViewById(R.id.finish_button).setOnClickListener(new View.OnClickListener() { @Override public void onClick(View v) { if (activity != null) { activity.finish(); } } }); filesText.setOnClickListener(new View.OnClickListener() { @Override public void onClick(View v) { if (parent != null) { Intent intent = new Intent(Intent.ACTION_GET_CONTENT); Uri uri = Uri.parse(parent); intent.setDataAndType(uri, "resource/folder"); startActivity(Intent.createChooser(intent, "Open folder")); } } }); int numFiles = 0; Bundle args = getArguments(); if (args != null) { ArrayList<File> files = (ArrayList<File>) args.getSerializable(GeoTagImagesService.EXTRA_GEOTAGGED_FILES); numFiles = files.size(); if (files != null && numFiles > 0) { parent = files.get(0).getParent(); } } if (parent != null) { filesText.setText(String.format(getString(R.string.photos_geotagged), String.valueOf(numFiles), parent)); } else { filesText.setText(getString(R.string.no_files_geotagged)); } }	@chaviw no point checking for files being null here since you already call files.size() above.
public Boolean attachStdin() { return (attachStdin != null) ? attachStdin : Boolean.FALSE; }	if these Boolean methods can never be null why not have the return type be boolean instead of Boolean ?
public NonTerminal(String name) { this.name = name; this.entryState = new EntryState(name + "-entry", this); this.exitState = new ExitState(name + "-exit", this); }	I still think you should throw an exception if name is null
public void determineNextResync(ZonedDateTime now) { this.nextResync = now.plusNanos(this.resyncPeriodInMillis * 1000000); }	Can't really understand what's going on here. We multiply by 1,000,000 a millisecond unit and add it as a nanosecond? (it would _probably_ make sense if we divided instead of multiply, but then why not just do now.plus(resyncPeriodInMillis, ChronoUnit.MILLIS))
@Test public void testArrayGetCloneRefCouples() throws Exception { Run("@a = array('Meow'); @b = array(@a, @a, array(@a)); @c = @b[]; msg((ref_equals(@b[0], @b[1]) && ref_equals(@b[0], @b[2][0])));", fakePlayer); verify(fakePlayer).sendMessage("true"); }	@c is not used here, I think you meant for it to be.
void resizeArray(int newArraySize) { long[] newArray = new long[newArraySize]; System.arraycopy(this.array, 0, newArray, 0, this.array.length); this.array = newArray; }	I think this will fail if the new size is smaller than the current one. Could be checked with an assert (private methods).
public void onResume() { super.onResume(); if (mSelectRoleShareVM.isRemoveSeleted()) { showSpinner(); mCollaborationsShareVM.deleteCollaboration(mSelectRoleShareVM.getCollaboration()); mSelectRoleShareVM.setRemoveSelected(false); } else { if (mSelectRoleShareVM.getSelectedRole().getValue() != null && mSelectRoleShareVM.getCollaboration() != null) { if (mSelectRoleShareVM.getSelectedRole().getValue() != mSelectRoleShareVM.getCollaboration().getRole()) { if (mSelectRoleShareVM.getSelectedRole().getValue() == BoxCollaboration.Role.OWNER) { AlertDialog dialog = new AlertDialog.Builder(getActivity()).setTitle(R.string.box_sharesdk_change_owner_alert_title) .setMessage(R.string.box_sharesdk_change_owner_alert_message) .setPositiveButton(android.R.string.yes, (d, which) -> { showSpinner(R.string.box_sharesdk_fetching_collaborators, R.string.boxsdk_Please_wait); mCollaborationsShareVM.updateOwner(mSelectRoleShareVM.getCollaboration()); }).setNegativeButton(android.R.string.no, (d, which) -> {}).setIcon(android.R.drawable.ic_dialog_alert).create(); dialog.show(); } else { showSpinner(); mCollaborationsShareVM.updateCollaboration(mSelectRoleShareVM.getCollaboration(), mSelectRoleShareVM.getSelectedRole().getValue()); } mSelectRoleShareVM.setSelectedRole(null); } } } if (mCollaborationsShareVM.getCollaborations().getValue() == null) { mCollaborationsShareVM.fetchItemInfo(mCollaborationsShareVM.getShareItem()); } }	removeSelected?
void stop() { allocatorExecutor.shutdown(); try { if (!allocatorExecutor.awaitTermination(3, TimeUnit.SECONDS)) { log.warn("Timedout while awaiting for allocatorExecutor's termination, so force shuttingdown"); } } catch (InterruptedException e) { log.warn("Got InterruptedException while awaiting termination of allocatorExecutor, so force shuttingdown"); } allocatorExecutor.shutdownNow(); log.info("Stopped entry logger preallocator."); }	We can give some more time, like 30 seconds.
public AbstractLunAvailableSizeColumn() { super(new AbstractToggleButtonCell<LunModel>() { @Override public void onClickEvent(LunModel lunModel) { if (lunModel !=null) { lunModel.setAdditionalAvailableSizeSelected(!lunModel.isAdditionalAvailableSizeSelected()); } } @Override public void render(Context context, LunModel value, SafeHtmlBuilder sb, String id) { boolean isGrayedOut = value.getIsGrayedOut(); String inputId = id + "_input"; SafeHtml input = null; int additionalAvailableSizeSize = value.getAdditionalAvailableSize(); String additionalAvailableSizeSizeString = "+ " + additionalAvailableSizeSize + " GB"; if (additionalAvailableSizeSize == 0 || !value.getIsIncluded()) { input = templates.disabled("", "color:gray", inputId); } else if (!isGrayedOut) { input = templates.disabled("", "color:black", inputId); } else if (value.isAdditionalAvailableSizeSelected()) { input = templates.toggledDown(inputId, additionalAvailableSizeSizeString); } else { input = templates.toggledUp(inputId, additionalAvailableSizeSizeString); } sb.append(templates.span(id, input)); } }); }	redundant black line
public String getPendingViewAsString() { CacheTopology cacheTopology = stateTransferManager.getCacheTopology(); return (!(cacheTopology != null && cacheTopology.getPendingCH() != null)) ? "N/A" : cacheTopology.getPendingCH().getMembers().toString(); }	Reverse the operands to avoid negation maybe? Would look nicer.
public void scrutinize(ItemUpdate update) { Map<PropertyIdValue, Value> propertyIdValueValueMap = new HashMap<>(); for (Statement statement : update.getAddedStatements()){ PropertyIdValue pid = statement.getClaim().getMainSnak().getPropertyId(); Value value = statement.getClaim().getMainSnak().getValue(); propertyIdValueValueMap.put(pid, value); } for(PropertyIdValue propertyId : propertyIdValueValueMap.keySet()){ List<PropertyIdValue> conflictingProperties = _fetcher.getConflictsWithProperties(propertyId); if (conflictingProperties != null){ for (PropertyIdValue conflictingPid : conflictingProperties) { if (propertyIdValueValueMap.containsKey(conflictingPid) && raiseWarning(propertyId, propertyIdValueValueMap, conflictingPid)) { QAWarning issue = new QAWarning(type, propertyId.getId(), QAWarning.Severity.WARNING, 1); issue.setProperty("property_entity", propertyId); issue.setProperty("added_property_entity", conflictingPid); issue.setProperty("example_entity", update.getItemId()); addIssue(issue); } } } } }	We need to check to check what happens with no value and some value snaks.
public SSLContext get() { Credentials currentCreds = checkNotNull(creds.get(), "credential supplier returned null"); String keyStorePassword = checkNotNull(currentCreds.credential, "credential supplier returned null credential (should be keyStorePassword)"); KeyManagerFactory kmf; try { kmf = KeyManagerFactory.getInstance("SunX509"); kmf.init(keyStore.get(), keyStorePassword.toCharArray()); SSLContext sc = SSLContext.getInstance("TLS"); sc.init(kmf.getKeyManagers(), trustManager, new SecureRandom()); System.setProperty("https.protocols", "TLSv1"); return sc; } catch (NoSuchAlgorithmException e) { throw propagate(e); } catch (UnrecoverableKeyException e) { throw propagate(e); } catch (KeyStoreException e) { throw propagate(e); } catch (KeyManagementException e) { throw propagate(e); } }	find a better way, this is super dodgy
public void fromStream_user_providesToken() throws IOException { MockTokenServerTransportFactory transportFactory = new MockTokenServerTransportFactory(); transportFactory.transport.addClient(CLIENT_ID, CLIENT_SECRET); transportFactory.transport.addRefreshToken(REFRESH_TOKEN, ACCESS_TOKEN); InputStream userStream = UserCredentialsTest.writeUserStream(CLIENT_ID, CLIENT_SECRET, REFRESH_TOKEN); UserCredentials credentials = UserCredentials.fromStream(userStream, transportFactory); assertNotNull(credentials); Map<String, List<String>> metadata = credentials.getRequestMetadata(CALL_URI); TestUtils.assertContainsBearerToken(metadata, ACCESS_TOKEN); }	Fully-qualified class name not needed.
public void scan(HttpMessage msg, String param, String value) { if (this.inScope(Tech.Linux) || this.inScope(Tech.MacOS)) { if (matchBodyPattern(getBaseMsg(), patternSSIUnix, new StringBuilder())) { return; } if (testServerSideInclude(param, SSI_UNIX, patternSSIUnix)) { return; } if (testServerSideInclude(param, SSI_UNIX2, patternSSIUnix)) { return; } } if (this.inScope(Tech.Windows)) { if (matchBodyPattern(getBaseMsg(), patternSSIWin, new StringBuilder())) { return; } if (testServerSideInclude(param, SSI_WIN, patternSSIWin)) { return; } if (testServerSideInclude(param, SSI_WIN2, patternSSIWin)) { return; } } }	- This should be done in the previous if statement (after tech checks), to not return earlier (Windows test could still be done). Also, worth extracting a method to reduce code duplication (boolean isEvidencePresent(Pattern)?). - Since the result is not required the StringBuilder can be null.
public void installServices(OperationContext context, ModelNode model) throws OperationFailedException { if (!context.isBooting()) return; ModelNode subsystemModel = Resource.Tools.readModel(context.readResource(PathAddress.EMPTY_ADDRESS)); if (subsystemModel.hasDefined(ProxyConfigurationResourceDefinition.WILDCARD_PATH.getKey())) { Set<String> adapterNames = new HashSet<>(); Set<LoadMetric> enabledMetrics = new HashSet<>(); for (Property property : subsystemModel.get(ProxyConfigurationResourceDefinition.WILDCARD_PATH.getKey()).asPropertyList()) { String proxyName = property.getName(); adapterNames.add(proxyName); ModelNode proxyModel = property.getValue(); ServiceTarget target = context.getServiceTarget(); ProxyConfigurationServiceConfigurator configurationBuilder = new ProxyConfigurationServiceConfigurator(proxyName); configurationBuilder.configure(context, proxyModel).build(target).install(); Set<LoadMetric> metrics = new HashSet<>(); LoadBalanceFactorProvider loadProvider = this.getLoadProvider(proxyName, metrics, context, proxyModel); enabledMetrics.addAll(metrics); String connector = CONNECTOR.resolveModelAttribute(context, proxyModel).asString(); int statusInterval = STATUS_INTERVAL.resolveModelAttribute(context, proxyModel).asInt(); new ContainerEventHandlerServiceConfigurator(proxyName, loadProvider).build(target).install(); for (ContainerEventHandlerAdapterServiceConfiguratorProvider provider : ServiceLoader.load(ContainerEventHandlerAdapterServiceConfiguratorProvider.class, ContainerEventHandlerAdapterServiceConfiguratorProvider.class.getClassLoader())) { provider.getServiceConfigurator(proxyName, connector, Duration.ofSeconds(statusInterval)).configure(context).build(target).setInitialMode(Mode.PASSIVE).install(); } } for (BoottimeHandlerProvider handler : ServiceLoader.load(BoottimeHandlerProvider.class, BoottimeHandlerProvider.class.getClassLoader())) { handler.performBoottime(context, adapterNames, enabledMetrics); } } }	Rather than iterate over the whole model twice, just use the Resource interface to nagivate through child resources once.
public void onHelpClick() { UriUtil.visitInExternalBrowser(getContext(), Uri.parse(requireContext().getString(R.string.android_app_edit_help_url))); }	Hint: FeedbackUtil.java contains numerous convenience functions for visiting specific external pages, e.g. the FAQ page, the privacy policy, etc. We can simply add another function there that goes to this page.
public static Block read(final int major, InputStream inputStream) { final boolean v3OrHigher = major >= CramVersions.CRAM_v3.major; if (v3OrHigher) { inputStream = new CRC32InputStream(inputStream); } try { final BlockCompressionMethod method = BlockCompressionMethod.byId(inputStream.read()); final BlockContentType type = BlockContentType.byId(inputStream.read()); final int contentId = ITF8.readUnsignedITF8(inputStream); final int compressedSize = ITF8.readUnsignedITF8(inputStream); final int rawSize = ITF8.readUnsignedITF8(inputStream); final byte[] compressedContent = new byte[compressedSize]; InputStreamUtils.readFully(inputStream, compressedContent, 0, compressedSize); if (v3OrHigher) { final int actualChecksum = ((CRC32InputStream) inputStream).getCRC32(); final int checksum = CramInt.readInt32(inputStream); if (checksum != actualChecksum) { throw new RuntimeException(String.format("Block CRC32 mismatch: %04x vs %04x", checksum, actualChecksum)); } } final byte[] uncompressedContent = ExternalCompression.uncompress(method, compressedContent); if (uncompressedContent.length != rawSize) { throw new CRAMException(String.format("Block uncompressed size did not match expected size: %04x vs %04x", rawSize, uncompressedContent.length)); } switch (type) { case FILE_HEADER: return new FileHeaderBlock(method, compressedContent); case COMPRESSION_HEADER: return new CompressionHeaderBlock(method, compressedContent); case MAPPED_SLICE: return new SliceHeaderBlock(method, compressedContent); case EXTERNAL: return new ExternalDataBlock(method, compressedContent, contentId); case CORE: return new CoreDataBlock(method, compressedContent); default: throw new CRAMException("Unknown BlockContentType " + type.name()); } } catch (final IOException e) { throw new RuntimeIOException(e); } }	The validation seems like a good idea, but it does seem like it would be expensive to do speculatively. Maybe we should do it lazily on "un-compression" instead. We'd have to retain the original size from the stream, but thats cheap.
protected boolean validateSourceDomainsSpaceRequirements() { Map<Guid, List<DiskImage>> storageDomainsActiveImagesMap = new HashMap<>(); for (LiveMigrateDiskParameters parameters : getParameters().getParametersList()) { DiskImage diskImage = getDiskImageByImageId(parameters.getImageId()); if (diskImage.getActive()) { diskImage.getSnapshots().add(diskImage); MultiValueMapUtils.addToMap(parameters.getSourceStorageDomainId(), diskImage, storageDomainsActiveImagesMap); } } for (Map.Entry<Guid, List<DiskImage>> entry : storageDomainsActiveImagesMap.entrySet()) { Guid sourceDomainId = entry.getKey(); List<DiskImage> disksList = entry.getValue(); Guid storagePoolId = disksList.get(0).getStoragePoolId(); StorageDomain sourceDomain = getStorageDomainById(sourceDomainId, storagePoolId); if (!doesStorageDomainHasSpaceForRequest(sourceDomain, disksList)) { return false; } } return true; }	Maybe I'm being daft, but where are the CDA message being added?
int binarySearch(K key) { int res = map.getKeyType().binarySearch(key, keys, getKeyCount(), cachedCompare); cachedCompare = (res < 0 ? -res : res) - 1; return res; }	Both old an new logic expect cachedCompare to be within the range [1, size] for cached path. The previous logic generated the cachedCompare like Java cachedCompare = res < 0 ? ~res : res + 1;  Here the Java cachedCompare = res < 0 ? ~res : res - 1;  is used. When entry isn't found ~res produces values within the range [0, size], this range is wider than the expected range, so the fallback to default may be unexpectedly used by both old and new code. When an entry is found, old res + 1 produced values within the range [1, size], it was correct. This range is expected and cachedCompare - 1 is actually used, so res + 1 - 1 = res (previous entry) was used as the starting point. When an entry is found, new res - 1 produces the values within the range [-1, size - 2], it looks like off-by-two error. So one of two paths was buggy and now both paths are buggy (suboptimal). Maybe I'm missing something, please re-check. (~something == -something - 1)
public FluidStack drain(ForgeDirection from, FluidStack resource, boolean doDrain) { if (resource != null) { Fluid f = resource.getFluid(); if (f != null) { Fluid fluid = tank.getFluidType(); if (fluid != null && f.getID() == fluid.getID()) return tank.drain(resource.amount, doDrain); } } return null; }	wouldn't it be easier if you do this in the tank? also you can just return null here as nobody uses this as far as i know
public static <K, V> List<ConsumerRecord<K, V>> waitUntilMinRecordsReceived(final Properties consumerConfig, final String topic, final int expectedNumRecords, final long waitTime) throws InterruptedException { final List<ConsumerRecord<K, V>> accumData = new ArrayList<>(); final String reason = String.format("Did not receive all %d records from topic %s within %d ms", expectedNumRecords, topic, waitTime); try (final Consumer<K, V> consumer = createConsumer(consumerConfig)) { TestUtils.retryOnExceptionWithTimeout(waitTime, () -> { final List<ConsumerRecord<K, V>> readData = readRecords(topic, consumer, waitTime, expectedNumRecords); accumData.addAll(readData); assertThat(reason, accumData.size(), is(greaterThanOrEqualTo(expectedNumRecords))); }); } return accumData; }	nit: add static import? (similar elsewhere)
public void setImage (Image image) { checkWidget (); if ((style & SWT.SEPARATOR) != 0) return; if (image != null && image.isDisposed()) error(SWT.ERROR_INVALID_ARGUMENT); this.image = image; updateStyleBits(false); OS.InvalidateRect (handle, null, true); }	With the proposed change: updateStyleBits(image == null)
public static void setupEnvironment() throws Exception { IWorkspace workspace = ResourcesPlugin.getWorkspace(); IWorkspaceDescription description = workspace.getDescription(); description.setAutoBuilding(false); workspace.setDescription(description); GitImportRepoWizard importWizard = new GitImportRepoWizard(); importWizard.openWizard(); String repoName = "egit"; String repoUrl = "git://egit.eclipse.org/egit.git"; if (!importWizard.containsRepo(repoName)) { addRepository(importWizard, repoUrl); } importWizard.selectAndCloneRepository(repoName); importWizard.waitForCreate(); waitForWorkspaceRefresh(); }	style nit: no braces around single line
protected void configure() { bind(String.class).annotatedWith(PluginName.class).toInstance(pluginName); bind(WebUiPlugin.class).annotatedWith(UniqueAnnotations.create()) .toInstance(new JavaScriptPlugin(fileName)); }	DynamicSet.bind(binder(), WebUiPlugin.class).toInstance(...)
public List<QuickFilter> getQuickFilters() { return this.quickFilters; }	return quickFilters
public void startContainerWithVolumes() throws DockerException { Volume volume1 = new Volume("/opt/webapp1"); Volume volume2 = new Volume("/opt/webapp2"); CreateContainerResponse container = dockerClient.createContainerCmd("busybox").withVolumes(volume1, volume2) .withCmd("true").withBinds(new Bind("/src/webapp1", volume1, ro), new Bind("/src/webapp2", volume2)) .exec(); LOG.info("Created container {}", container.toString()); assertThat(container.getId(), not(isEmptyString())); InspectContainerResponse inspectContainerResponse = dockerClient.inspectContainerCmd(container.getId()).exec(); assertThat(inspectContainerResponse.getConfig().getVolumes().keySet(), contains("/opt/webapp1", "/opt/webapp2")); dockerClient.startContainerCmd(container.getId()).exec(); dockerClient.waitContainerCmd(container.getId()).exec(new WaitContainerResultCallback()).awaitStatusCode(); inspectContainerResponse = dockerClient.inspectContainerCmd(container.getId()).exec(); assertContainerHasVolumes(inspectContainerResponse, volume1, volume2); assertEquals(inspectContainerResponse.getMounts().size(), 2); assertEquals(inspectContainerResponse.getMounts().get(0).getDestination(), volume1); assertEquals(inspectContainerResponse.getMounts().get(0).getMode(), "ro"); assertEquals(inspectContainerResponse.getMounts().get(0).getRW(), Boolean.FALSE); assertEquals(inspectContainerResponse.getMounts().get(1).getDestination(), volume2); assertEquals(inspectContainerResponse.getMounts().get(1).getMode(), "rw"); assertEquals(inspectContainerResponse.getMounts().get(1).getRW(), Boolean.TRUE); }	you've change order of expected and actual (error string will be wrong in case of fail) to not repeat this mistake simply use assertThat(actual, matcherForIt()) - thats more friendly to any reviewer or maintaineer
public ListenableFuture<?> isBlocked() { if (!finishing || !joinPagesNotNeeded.isPresent()) { return NOT_BLOCKED; } return joinPagesNotNeeded.get(); }	isn't finishing tied to joinPagesNotNeeded not being empty? Maybe just get rid of it and then then becomes return joinPagesNotNeeded.orElse(NOT_BLOCKED)
public ConsumerTestRuntimeEnvironment(Supplier<CuratorFramework> curatorSupplier) { this.paths = new ZookeeperPaths("/hermes"); this.curatorSupplier = curatorSupplier; this.curator = curatorSupplier.get(); this.groupRepository = new ZookeeperGroupRepository(curator, objectMapper, paths); this.topicRepository = new ZookeeperTopicRepository(curator, objectMapper, paths, groupRepository); this.subscriptionRepository = new ZookeeperSubscriptionRepository(curator, objectMapper, paths, topicRepository); this.configFactory = new MutableConfigFactory().overrideProperty(CONSUMER_WORKLOAD_REBALANCE_INTERVAL, 1); this.consumersRegistry = new ConsumerNodesRegistry(curator, executorService, paths.consumersRegistryPath(), "id"); this.metrics = mock(HermesMetrics.class); when(metrics.timer(anyString())).thenReturn(new Timer()); try { curator.create().creatingParentsIfNeeded().forPath("/hermes/groups"); consumersRegistry.start(); } catch (Exception e) { e.printStackTrace(); } }	There's a lot going on in this class, it creates subscriptions, spawns SelectiveSupervisorControllers, makes assertions. Maybe we could separate this work to different classes.
public void testDefaults() { ConfigAssertions.assertRecordedDefaults(ConfigAssertions.recordDefaults(JsonWebTokenConfig.class) .setKey(null) .setRequiredAudience(null) .setRequiredIssuer(null)); }	Static import the assertion methods
public Message[] getErrors() { Message[] messages = new Message[fErrors.size()]; int i = 0; for (String string : fErrors) { messages[i++] = new Message(string, -1); } return messages; }	rename to message
public void publishJobModelVersion(String oldVersion, String newVersion) { Stat stat = new Stat(); String currentVersion = zkClient.<String>readData(keyBuilder.getJobModelVersionPath(), stat); LOG.info("publishing new version: " + newVersion + "; oldVersion = " + oldVersion + "(" + stat .getVersion() + ")"); if (currentVersion != null && !currentVersion.equals(oldVersion)) { throw new SamzaException( "Someone changed JobModelVersion while the leader was generating one: expected" + oldVersion + ", got " + currentVersion); } int dataVersion = stat.getVersion(); try { stat = zkClient.writeDataReturnStat(keyBuilder.getJobModelVersionPath(), newVersion, dataVersion); } catch (Exception e) { String msg = "publish job model version failed for new version = " + newVersion + "; old version = " + oldVersion; LOG.error(msg, e); throw new SamzaException(e); } LOG.info("published new version: " + newVersion + "; expected data version = " + (dataVersion + 1) + "(actual data version after update = " + stat.getVersion() + ")"); }	Please leave msg.
private String generateExcludes(final Iterable<String> excludes) { final StringBuilder xml = new StringBuilder(75); xml.append("<FindBugsFilter><Match><Or>"); for (final String exclude : excludes) { xml.append("<Class name=\"").append(exclude).append("\"/>"); } xml.append("</Or></Match></FindBugsFilter>"); return xml.toString(); }	yeah, this is definitely a bad idea, since exclude may be equal to, say, "hey" and the entire code will crash. Let's find a way to use Xembly
public Registration deserialize(JsonParser p, DeserializationContext ctxt) throws IOException { JsonNode node = p.readValueAsTree(); Registration.Builder builder = Registration.builder(); if (node.hasNonNull("name")) { builder.name(node.get("name").asText()); } if (node.hasNonNull("url")) { String url = node.get("url").asText(); builder.healthUrl(url.replaceFirst("/+$", "") + "/health").managementUrl(url); } else { if (node.hasNonNull("healthUrl")) { builder.healthUrl(node.get("healthUrl").asText()); } if (node.hasNonNull("managementUrl")) { builder.managementUrl(node.get("managementUrl").asText()); } if (node.hasNonNull("serviceUrl")) { builder.serviceUrl(node.get("serviceUrl").asText()); } } if (node.hasNonNull("metadata")) { Iterator<Map.Entry<String, JsonNode>> it = node.get("metadata").fields(); while (it.hasNext()) { Map.Entry<String, JsonNode> entry = it.next(); builder.metadata(entry.getKey(), entry.getValue().asText()); } } return builder.build(); }	iirc the source is added later in the controller and not part of the request.
private Map<Long, Pair<String, Long>> recoverPendingLargeMessages() throws Exception { Map<Long, Pair<String, Long>> largeMessages = new HashMap<>(); List<String> filenames = largeMessagesFactory.listFiles("msg"); List<Long> idList = new ArrayList<>(); for (String filename : filenames) { Long id = getLargeMessageIdFromFilename(filename); if (!largeMessagesToDelete.containsKey(id)) { idList.add(id); SequentialFile seqFile = largeMessagesFactory.createSequentialFile(filename); long size = seqFile.size(); largeMessages.put(id, new Pair<>(filename, size)); } } return largeMessages; }	you can just use a primitive long here
public void setComponent(T component) { this.component = component; }	I don't see why you introduced mutability here? Local variables would have worked just as well. If you really want that, please at least make the setters package-private.
private void activeDetailModelChanging(HasEntity<D> newValue, boolean stopRefresh) { for (HasEntity<D> oldValue : activeDetailModels) { if (oldValue != null && stopRefresh) { oldValue.setEntity(null); if (oldValue instanceof SearchableListModel) { ((SearchableListModel) oldValue).stopRefresh(); } } } if (newValue != null) { newValue.setEntity(provideDetailModelEntity(getSelectedItem())); } }	Wouldn't a top-level if (stopRefresh) guard condition be better, instead of checking it within the loop?
public void findAllPaginationTest() throws Exception { context.turnOffAuthorisationSystem(); EPerson ePerson = EPersonBuilder.createEPerson(context) .withNameInMetadata("John", "Doe") .withEmail("Johndoe@gmail.com") .build(); String token = getAuthToken(admin.getEmail(), password); getClient(token).perform(get("/api/eperson/epersons") .param("size", "1")) .andExpect(status().isOk()) .andExpect(content().contentType(contentType)) .andExpect(jsonPath("$._embedded.epersons", Matchers.contains(Matchers.anyOf( EPersonMatcher.matchEPersonOnEmail(eperson.getEmail()), EPersonMatcher.matchEPersonOnEmail(admin.getEmail()), EPersonMatcher.matchEPersonOnEmail(ePerson.getEmail()) )))) .andExpect(jsonPath("$._embedded.epersons", Matchers.hasSize(1))) .andExpect(jsonPath("$.page.size", is(1))) .andExpect(jsonPath("$.page.totalElements", is(3))) ; getClient(token).perform(get("/api/eperson/epersons") .param("size", "1") .param("page", "1")) .andExpect(status().isOk()) .andExpect(content().contentType(contentType)) .andExpect(jsonPath("$._embedded.epersons", Matchers.contains(Matchers.anyOf( EPersonMatcher.matchEPersonOnEmail(eperson.getEmail()), EPersonMatcher.matchEPersonOnEmail(admin.getEmail()), EPersonMatcher.matchEPersonOnEmail(ePerson.getEmail()) )))) .andExpect(jsonPath("$._embedded.epersons", Matchers.hasSize(1))) .andExpect(jsonPath("$.page.size", is(1))) .andExpect(jsonPath("$.page.totalElements", is(3))) ; getClient().perform(get("/api/eperson/epersons")) .andExpect(status().isForbidden()) ; }	The variables eperson and ePerson are confusing in the same block. Could more specific names be used?
public void testAccessControl_studentNotExistInCourse_shouldFail() { InstructorAttributes instructor1OfCourse1 = typicalBundle.instructors.get("instructor1OfCourse1"); StudentAttributes student1InCourse2 = typicalBundle.students.get("student1InCourse2"); CourseAttributes typicalCourse1 = typicalBundle.courses.get("typicalCourse1"); loginAsInstructor(instructor1OfCourse1.googleId); String[] submissionParams = new String[] { Const.ParamsNames.COURSE_ID, typicalCourse1.getId(), Const.ParamsNames.STUDENT_EMAIL, student1InCourse2.getEmail(), }; verifyCannotAccess(submissionParams); }	You should test for both instructor and student?
public @Nullable String resolveDeviceType(int quark, long timestamp) { return TmfStrings.cpu(); }	Should this be using TmfCpuAspect?
public void run() { logger.info("System Resource: {}", SystemResourceMonitor.create(SystemResourceMonitor.allResources).getFormattedSystemResourceUsage()); }	The create method call should be separate from the logger call.
public RangeResourceEntry remove(ResourceEntry<Long> resourceEntry) { RangeResourceEntry rangeResourceEntry = (RangeResourceEntry) resourceEntry; if (this.begin > rangeResourceEntry.getBegin()) { this.begin = rangeResourceEntry.getBegin(); } if (this.end < rangeResourceEntry.getEnd()) { this.end = rangeResourceEntry.getEnd(); } return this; }	This seems like the opposite of remove to me, since the range goes from beginning to end, if we remove from resourceEntry.begin to resourceEntry.end, then if the original begin is larger than the resourceEntry.begin and we set begin to the resourceEntry.begin, we'd be adding those ports between resourceEntry.begin and begin to the range. Similarly for end.
public void secondary_no_location() throws Exception { thrown.expectMessage("Precise secondary location should contain at least one '^'"); check( "foo(); "x = bar();\n" + " TestIssue.create("msg1", 1).secondary("Secondary message", 3, 5, 8)); }	@vilchik-elena The message should give the line number.
public ASN1DataFormat() { super(); this.usingIterator = false; }	Those 3 implicit super() calls could be removed.
public Long getUuid() { return new Long(artId); }	use Long.valueOf() instead of new Long() - always for performance reasons
public void testCreateProcessWithLogonW() { String winDir = Kernel32Util.getEnvironmentVariable("WINDIR"); if (winDir == null || !(new File(winDir).exists())) { throw new IllegalStateException("WINDIR environment variable did not properly resolve to a directory."); } STARTUPINFO si = new STARTUPINFO(); si.lpDesktop = null; PROCESS_INFORMATION results = new PROCESS_INFORMATION(); boolean result = Advapi32.INSTANCE.CreateProcessWithLogonW("A" + System.currentTimeMillis(), "localhost", "12345", Advapi32.LOGON_WITH_PROFILE, new File(winDir, "notepad.exe").getAbsolutePath(), "", 0, null, "", si, results); assertFalse(result); assertEquals(Native.getLastError(), W32Errors.ERROR_LOGON_FAILURE); }	assertNotNull("No WINDIR value returned", winDir); assertTrue("Specified WINDIR does not exist: " + winDir, new File(winDir).exists());
public void compileSuccessForBundleSparseArray() { CompileResult result = compileFiles(BundleSparseArrayCompileSuccessActivity.class); assertCompilationSuccessful(result); }	Sorry, i think i was not clear. Please add assertGeneratedClassContains() here to actually check the correct method call was generated.
public ExecutionError filter(ExecutionErrorContext errorContext) { Builder errorBuilder = ExecutionError.builder().type("DB").initActivityId(getInitActivityId(errorContext)); String stacktrace = getStackTrace(errorContext.getCause()); Task task = errorContext.getLastExecutedTask(); NodeInstance nodeInstance = errorContext.getLastExecutedNode(); logger.debug("Last executed node instance {}, last executed task {}", nodeInstance, task); if (nodeInstance != null) { logger.debug("Last executed node instance {} will be used to populate error details", nodeInstance); errorBuilder .deploymentId(((ProcessInstanceImpl)nodeInstance.getProcessInstance()).getDeploymentId()) .processInstanceId(nodeInstance.getProcessInstance().getId()) .processId(nodeInstance.getProcessInstance().getProcessId()) .activityId(nodeInstance.getId()) .activityName(nodeName(nodeInstance)); } else if (task != null) { logger.debug("Last executed task {} will be used to populate error details", task); errorBuilder .deploymentId(task.getTaskData().getDeploymentId()) .processInstanceId(task.getTaskData().getProcessInstanceId()) .processId(task.getTaskData().getProcessId()) .activityId(task.getId()) .activityName(task.getName()); } return errorBuilder .message(errorContext.getCause().getMessage()) .error(stacktrace) .errorDate(new Date()) .build(); }	Would be good to have constants for the builder types, right now they are hard-coded strings like "DB", "Task". WDYT?
